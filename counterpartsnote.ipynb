{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Master's Project - Douglas FiÃ³rio Dias - Execution of counterpart scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: tensorboardX in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (2.6.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from tensorboardX) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from tensorboardX) (24.0)\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from tensorboardX) (4.25.3)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (2.2.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (0.17.1+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (2.2.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (0.9.16)\n",
      "Requirement already satisfied: torch in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from timm) (2.2.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from timm) (0.17.1+cu118)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from timm) (6.0.1)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from timm) (0.21.4)\n",
      "Requirement already satisfied: safetensors in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from timm) (0.4.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from huggingface_hub->timm) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from huggingface_hub->timm) (2024.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from huggingface_hub->timm) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from huggingface_hub->timm) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from huggingface_hub->timm) (4.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from huggingface_hub->timm) (24.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch->timm) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch->timm) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torch->timm) (3.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from torchvision->timm) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from torchvision->timm) (10.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub->timm) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from jinja2->torch->timm) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from requests->huggingface_hub->timm) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from requests->huggingface_hub->timm) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuariolocal\\appdata\\roaming\\python\\python310\\site-packages (from requests->huggingface_hub->timm) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from sympy->torch->timm) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (1.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: numpy<1.29.0,>=1.22.4 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from scipy) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ttach in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (0.0.3)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: oauthlib in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cryptography in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (42.0.5)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from cryptography) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages (from cffi>=1.12->cryptography) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorboardX\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "%pip install timm\n",
    "%pip install opencv-python\n",
    "%pip install torchsummary\n",
    "%pip install scipy\n",
    "%pip install ttach\n",
    "%pip install oauthlib\n",
    "%pip install cryptography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counterpart scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ViT network (the ViT without the Shuffle Instance estrategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python Train.py --model_idx ViT_RockModel --edge_size 384 --data_augmentation_mode 2 --batch_size 4 --lr 0.00001 --lrf 0.05 --enable_tensorboard --check_minibatch 5 --dataroot sample_datasets/warwick_CLS --model_path saved_models --draw_root runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ViT network test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python Test.py --model_idx ViT_RockModel --edge_size 384 --data_augmentation_mode 2 --enable_attention_check --check_minibatch 5 --dataroot sample_datasets/warwick_CLS --model_path saved_models --draw_root runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "densenet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names: ['granite-blackswan', 'marble-shadow', 'quartzite-oceanblue', 'quartzite-patagonia']\n",
      "*********************************setting*************************************\n",
      "Namespace(model_idx='densenet_RockModel', drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.0, cls_token_off=False, pos_embedding_off=False, att_module='SimAM', backbone_PT_off=False, gpu_idx=-1, dataroot='sample_datasets/warwick_CLS', model_path='saved_models', draw_root='runs', paint=True, enable_notify=False, enable_tensorboard=True, enable_attention_check=False, enable_visualize_check=False, enable_sam=False, augmentation_name=None, data_augmentation_mode=2, linearprobing=False, Pre_Trained_model_path=None, num_classes=0, edge_size=384, num_workers=2, batch_size=4, check_minibatch=5, num_epochs=10, intake_epochs=0, lr=1e-05, lrf=0.05, opt_name='Adam')\n",
      "we dont have more GPU idx here, try to use gpu_idx=0\n",
      "['densenet121',\n",
      " 'densenet161',\n",
      " 'densenet169',\n",
      " 'densenet201',\n",
      " 'densenet264d',\n",
      " 'densenetblur121d']\n",
      "test model outputï¼ tensor([[ 0.0814,  0.1989, -0.4317, -0.1586]], grad_fn=<AddmmBackward0>)\n",
      "model is ready now!\n",
      "GPU: 0\n",
      "model : densenet_RockModel\n",
      "no valid counterparts augmentation selected\n",
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\usuariolocal\\OneDrive\\Documentos\\Douglas\\Mestrado\\3 - Curso\\Meu projeto\\si_vit_ornamental_rocks\\Train.py\", line 801, in <module>\n",
      "    main(args)\n",
      "  File \"c:\\Users\\usuariolocal\\OneDrive\\Documentos\\Douglas\\Mestrado\\3 - Curso\\Meu projeto\\si_vit_ornamental_rocks\\Train.py\", line 700, in main\n",
      "    model_ft = train_model(model, dataloaders, criterion, optimizer, class_names, dataset_sizes, Augmentation,\n",
      "  File \"c:\\Users\\usuariolocal\\OneDrive\\Documentos\\Douglas\\Mestrado\\3 - Curso\\Meu projeto\\si_vit_ornamental_rocks\\Train.py\", line 175, in train_model\n",
      "    outputs = model(inputs)  # one-hot outputs: [B,CLS]\n",
      "  File \"c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\timm\\models\\densenet.py\", line 302, in forward\n",
      "    x = self.forward_features(x)\n",
      "  File \"c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\timm\\models\\densenet.py\", line 299, in forward_features\n",
      "    return self.features(x)\n",
      "  File \"c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "  File \"c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1561, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "  File \"c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\timm\\models\\densenet.py\", line 124, in forward\n",
      "    new_features = layer(features)\n",
      "  File \"c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1574, in _call_impl\n",
      "    hook_result = hook(self, args, result)\n",
      "  File \"c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torchsummary\\torchsummary.py\", line 19, in hook\n",
      "    summary[m_key][\"input_shape\"] = list(input[0].size())\n",
      "AttributeError: 'list' object has no attribute 'size'\n"
     ]
    }
   ],
   "source": [
    "!python Train.py --model_idx densenet_RockModel --edge_size 384 --data_augmentation_mode 2 --batch_size 4 --lr 0.00001 --lrf 0.05 --enable_tensorboard --check_minibatch 5 --dataroot sample_datasets/warwick_CLS --model_path saved_models --draw_root runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "densenet test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names: ['granite-blackswan', 'marble-shadow', 'quartzite-oceanblue', 'quartzite-patagonia']\n",
      "['densenet121',\n",
      " 'densenet161',\n",
      " 'densenet169',\n",
      " 'densenet201',\n",
      " 'densenet264d',\n",
      " 'densenetblur121d']\n",
      "test model outputï¼ tensor([[-0.0967,  0.1724, -0.2701, -0.0904]], grad_fn=<AddmmBackward0>)\n",
      "model is ready now!\n",
      "model loading erro!!\n"
     ]
    }
   ],
   "source": [
    "!python Test.py --model_idx densenet_RockModel --edge_size 384 --data_augmentation_mode 2 --enable_attention_check --check_minibatch 5 --dataroot sample_datasets/warwick_CLS --model_path saved_models --draw_root runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inceptionv3 network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names: ['granite-blackswan', 'marble-shadow', 'quartzite-oceanblue', 'quartzite-patagonia']\n",
      "*********************************setting*************************************\n",
      "Namespace(model_idx='inceptionv3_RockModel', drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.0, cls_token_off=False, pos_embedding_off=False, att_module='SimAM', backbone_PT_off=False, gpu_idx=-1, dataroot='sample_datasets/warwick_CLS', model_path='saved_models', draw_root='runs', paint=True, enable_notify=False, enable_tensorboard=True, enable_attention_check=False, enable_visualize_check=False, enable_sam=False, augmentation_name=None, data_augmentation_mode=2, linearprobing=False, Pre_Trained_model_path=None, num_classes=0, edge_size=384, num_workers=2, batch_size=4, check_minibatch=5, num_epochs=10, intake_epochs=0, lr=1e-05, lrf=0.05, opt_name='Adam')\n",
      "we dont have more GPU idx here, try to use gpu_idx=0\n",
      "['inception_next_base',\n",
      " 'inception_next_small',\n",
      " 'inception_next_tiny',\n",
      " 'inception_resnet_v2',\n",
      " 'inception_v3',\n",
      " 'inception_v4']\n",
      "test model outputï¼ tensor([[-1.3484,  0.1390, -0.3693,  0.6236]], grad_fn=<AddmmBackward0>)\n",
      "model is ready now!\n",
      "GPU: 0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 191, 191]             864\n",
      "          Identity-2         [-1, 32, 191, 191]               0\n",
      "              ReLU-3         [-1, 32, 191, 191]               0\n",
      "    BatchNormAct2d-4         [-1, 32, 191, 191]              64\n",
      "       ConvNormAct-5         [-1, 32, 191, 191]               0\n",
      "            Conv2d-6         [-1, 32, 189, 189]           9,216\n",
      "          Identity-7         [-1, 32, 189, 189]               0\n",
      "              ReLU-8         [-1, 32, 189, 189]               0\n",
      "    BatchNormAct2d-9         [-1, 32, 189, 189]              64\n",
      "      ConvNormAct-10         [-1, 32, 189, 189]               0\n",
      "           Conv2d-11         [-1, 64, 189, 189]          18,432\n",
      "         Identity-12         [-1, 64, 189, 189]               0\n",
      "             ReLU-13         [-1, 64, 189, 189]               0\n",
      "   BatchNormAct2d-14         [-1, 64, 189, 189]             128\n",
      "      ConvNormAct-15         [-1, 64, 189, 189]               0\n",
      "        MaxPool2d-16           [-1, 64, 94, 94]               0\n",
      "           Conv2d-17           [-1, 80, 94, 94]           5,120\n",
      "         Identity-18           [-1, 80, 94, 94]               0\n",
      "             ReLU-19           [-1, 80, 94, 94]               0\n",
      "   BatchNormAct2d-20           [-1, 80, 94, 94]             160\n",
      "      ConvNormAct-21           [-1, 80, 94, 94]               0\n",
      "           Conv2d-22          [-1, 192, 92, 92]         138,240\n",
      "         Identity-23          [-1, 192, 92, 92]               0\n",
      "             ReLU-24          [-1, 192, 92, 92]               0\n",
      "   BatchNormAct2d-25          [-1, 192, 92, 92]             384\n",
      "      ConvNormAct-26          [-1, 192, 92, 92]               0\n",
      "        MaxPool2d-27          [-1, 192, 45, 45]               0\n",
      "           Conv2d-28           [-1, 64, 45, 45]          12,288\n",
      "         Identity-29           [-1, 64, 45, 45]               0\n",
      "             ReLU-30           [-1, 64, 45, 45]               0\n",
      "   BatchNormAct2d-31           [-1, 64, 45, 45]             128\n",
      "      ConvNormAct-32           [-1, 64, 45, 45]               0\n",
      "           Conv2d-33           [-1, 48, 45, 45]           9,216\n",
      "         Identity-34           [-1, 48, 45, 45]               0\n",
      "             ReLU-35           [-1, 48, 45, 45]               0\n",
      "   BatchNormAct2d-36           [-1, 48, 45, 45]              96\n",
      "      ConvNormAct-37           [-1, 48, 45, 45]               0\n",
      "           Conv2d-38           [-1, 64, 45, 45]          76,800\n",
      "         Identity-39           [-1, 64, 45, 45]               0\n",
      "             ReLU-40           [-1, 64, 45, 45]               0\n",
      "   BatchNormAct2d-41           [-1, 64, 45, 45]             128\n",
      "      ConvNormAct-42           [-1, 64, 45, 45]               0\n",
      "           Conv2d-43           [-1, 64, 45, 45]          12,288\n",
      "         Identity-44           [-1, 64, 45, 45]               0\n",
      "             ReLU-45           [-1, 64, 45, 45]               0\n",
      "   BatchNormAct2d-46           [-1, 64, 45, 45]             128\n",
      "      ConvNormAct-47           [-1, 64, 45, 45]               0\n",
      "           Conv2d-48           [-1, 96, 45, 45]          55,296\n",
      "         Identity-49           [-1, 96, 45, 45]               0\n",
      "             ReLU-50           [-1, 96, 45, 45]               0\n",
      "   BatchNormAct2d-51           [-1, 96, 45, 45]             192\n",
      "      ConvNormAct-52           [-1, 96, 45, 45]               0\n",
      "           Conv2d-53           [-1, 96, 45, 45]          82,944\n",
      "         Identity-54           [-1, 96, 45, 45]               0\n",
      "             ReLU-55           [-1, 96, 45, 45]               0\n",
      "   BatchNormAct2d-56           [-1, 96, 45, 45]             192\n",
      "      ConvNormAct-57           [-1, 96, 45, 45]               0\n",
      "           Conv2d-58           [-1, 32, 45, 45]           6,144\n",
      "         Identity-59           [-1, 32, 45, 45]               0\n",
      "             ReLU-60           [-1, 32, 45, 45]               0\n",
      "   BatchNormAct2d-61           [-1, 32, 45, 45]              64\n",
      "      ConvNormAct-62           [-1, 32, 45, 45]               0\n",
      "       InceptionA-63          [-1, 256, 45, 45]               0\n",
      "           Conv2d-64           [-1, 64, 45, 45]          16,384\n",
      "         Identity-65           [-1, 64, 45, 45]               0\n",
      "             ReLU-66           [-1, 64, 45, 45]               0\n",
      "   BatchNormAct2d-67           [-1, 64, 45, 45]             128\n",
      "      ConvNormAct-68           [-1, 64, 45, 45]               0\n",
      "           Conv2d-69           [-1, 48, 45, 45]          12,288\n",
      "         Identity-70           [-1, 48, 45, 45]               0\n",
      "             ReLU-71           [-1, 48, 45, 45]               0\n",
      "   BatchNormAct2d-72           [-1, 48, 45, 45]              96\n",
      "      ConvNormAct-73           [-1, 48, 45, 45]               0\n",
      "           Conv2d-74           [-1, 64, 45, 45]          76,800\n",
      "         Identity-75           [-1, 64, 45, 45]               0\n",
      "             ReLU-76           [-1, 64, 45, 45]               0\n",
      "   BatchNormAct2d-77           [-1, 64, 45, 45]             128\n",
      "      ConvNormAct-78           [-1, 64, 45, 45]               0\n",
      "           Conv2d-79           [-1, 64, 45, 45]          16,384\n",
      "         Identity-80           [-1, 64, 45, 45]               0\n",
      "             ReLU-81           [-1, 64, 45, 45]               0\n",
      "   BatchNormAct2d-82           [-1, 64, 45, 45]             128\n",
      "      ConvNormAct-83           [-1, 64, 45, 45]               0\n",
      "           Conv2d-84           [-1, 96, 45, 45]          55,296\n",
      "         Identity-85           [-1, 96, 45, 45]               0\n",
      "             ReLU-86           [-1, 96, 45, 45]               0\n",
      "   BatchNormAct2d-87           [-1, 96, 45, 45]             192\n",
      "      ConvNormAct-88           [-1, 96, 45, 45]               0\n",
      "           Conv2d-89           [-1, 96, 45, 45]          82,944\n",
      "         Identity-90           [-1, 96, 45, 45]               0\n",
      "             ReLU-91           [-1, 96, 45, 45]               0\n",
      "   BatchNormAct2d-92           [-1, 96, 45, 45]             192\n",
      "      ConvNormAct-93           [-1, 96, 45, 45]               0\n",
      "           Conv2d-94           [-1, 64, 45, 45]          16,384\n",
      "         Identity-95           [-1, 64, 45, 45]               0\n",
      "             ReLU-96           [-1, 64, 45, 45]               0\n",
      "   BatchNormAct2d-97           [-1, 64, 45, 45]             128\n",
      "      ConvNormAct-98           [-1, 64, 45, 45]               0\n",
      "       InceptionA-99          [-1, 288, 45, 45]               0\n",
      "          Conv2d-100           [-1, 64, 45, 45]          18,432\n",
      "        Identity-101           [-1, 64, 45, 45]               0\n",
      "            ReLU-102           [-1, 64, 45, 45]               0\n",
      "  BatchNormAct2d-103           [-1, 64, 45, 45]             128\n",
      "     ConvNormAct-104           [-1, 64, 45, 45]               0\n",
      "          Conv2d-105           [-1, 48, 45, 45]          13,824\n",
      "        Identity-106           [-1, 48, 45, 45]               0\n",
      "            ReLU-107           [-1, 48, 45, 45]               0\n",
      "  BatchNormAct2d-108           [-1, 48, 45, 45]              96\n",
      "     ConvNormAct-109           [-1, 48, 45, 45]               0\n",
      "          Conv2d-110           [-1, 64, 45, 45]          76,800\n",
      "        Identity-111           [-1, 64, 45, 45]               0\n",
      "            ReLU-112           [-1, 64, 45, 45]               0\n",
      "  BatchNormAct2d-113           [-1, 64, 45, 45]             128\n",
      "     ConvNormAct-114           [-1, 64, 45, 45]               0\n",
      "          Conv2d-115           [-1, 64, 45, 45]          18,432\n",
      "        Identity-116           [-1, 64, 45, 45]               0\n",
      "            ReLU-117           [-1, 64, 45, 45]               0\n",
      "  BatchNormAct2d-118           [-1, 64, 45, 45]             128\n",
      "     ConvNormAct-119           [-1, 64, 45, 45]               0\n",
      "          Conv2d-120           [-1, 96, 45, 45]          55,296\n",
      "        Identity-121           [-1, 96, 45, 45]               0\n",
      "            ReLU-122           [-1, 96, 45, 45]               0\n",
      "  BatchNormAct2d-123           [-1, 96, 45, 45]             192\n",
      "     ConvNormAct-124           [-1, 96, 45, 45]               0\n",
      "          Conv2d-125           [-1, 96, 45, 45]          82,944\n",
      "        Identity-126           [-1, 96, 45, 45]               0\n",
      "            ReLU-127           [-1, 96, 45, 45]               0\n",
      "  BatchNormAct2d-128           [-1, 96, 45, 45]             192\n",
      "     ConvNormAct-129           [-1, 96, 45, 45]               0\n",
      "          Conv2d-130           [-1, 64, 45, 45]          18,432\n",
      "        Identity-131           [-1, 64, 45, 45]               0\n",
      "            ReLU-132           [-1, 64, 45, 45]               0\n",
      "  BatchNormAct2d-133           [-1, 64, 45, 45]             128\n",
      "     ConvNormAct-134           [-1, 64, 45, 45]               0\n",
      "      InceptionA-135          [-1, 288, 45, 45]               0\n",
      "          Conv2d-136          [-1, 384, 22, 22]         995,328\n",
      "        Identity-137          [-1, 384, 22, 22]               0\n",
      "            ReLU-138          [-1, 384, 22, 22]               0\n",
      "  BatchNormAct2d-139          [-1, 384, 22, 22]             768\n",
      "     ConvNormAct-140          [-1, 384, 22, 22]               0\n",
      "          Conv2d-141           [-1, 64, 45, 45]          18,432\n",
      "        Identity-142           [-1, 64, 45, 45]               0\n",
      "            ReLU-143           [-1, 64, 45, 45]               0\n",
      "  BatchNormAct2d-144           [-1, 64, 45, 45]             128\n",
      "     ConvNormAct-145           [-1, 64, 45, 45]               0\n",
      "          Conv2d-146           [-1, 96, 45, 45]          55,296\n",
      "        Identity-147           [-1, 96, 45, 45]               0\n",
      "            ReLU-148           [-1, 96, 45, 45]               0\n",
      "  BatchNormAct2d-149           [-1, 96, 45, 45]             192\n",
      "     ConvNormAct-150           [-1, 96, 45, 45]               0\n",
      "          Conv2d-151           [-1, 96, 22, 22]          82,944\n",
      "        Identity-152           [-1, 96, 22, 22]               0\n",
      "            ReLU-153           [-1, 96, 22, 22]               0\n",
      "  BatchNormAct2d-154           [-1, 96, 22, 22]             192\n",
      "     ConvNormAct-155           [-1, 96, 22, 22]               0\n",
      "      InceptionB-156          [-1, 768, 22, 22]               0\n",
      "          Conv2d-157          [-1, 192, 22, 22]         147,456\n",
      "        Identity-158          [-1, 192, 22, 22]               0\n",
      "            ReLU-159          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-160          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-161          [-1, 192, 22, 22]               0\n",
      "          Conv2d-162          [-1, 128, 22, 22]          98,304\n",
      "        Identity-163          [-1, 128, 22, 22]               0\n",
      "            ReLU-164          [-1, 128, 22, 22]               0\n",
      "  BatchNormAct2d-165          [-1, 128, 22, 22]             256\n",
      "     ConvNormAct-166          [-1, 128, 22, 22]               0\n",
      "          Conv2d-167          [-1, 128, 22, 22]         114,688\n",
      "        Identity-168          [-1, 128, 22, 22]               0\n",
      "            ReLU-169          [-1, 128, 22, 22]               0\n",
      "  BatchNormAct2d-170          [-1, 128, 22, 22]             256\n",
      "     ConvNormAct-171          [-1, 128, 22, 22]               0\n",
      "          Conv2d-172          [-1, 192, 22, 22]         172,032\n",
      "        Identity-173          [-1, 192, 22, 22]               0\n",
      "            ReLU-174          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-175          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-176          [-1, 192, 22, 22]               0\n",
      "          Conv2d-177          [-1, 128, 22, 22]          98,304\n",
      "        Identity-178          [-1, 128, 22, 22]               0\n",
      "            ReLU-179          [-1, 128, 22, 22]               0\n",
      "  BatchNormAct2d-180          [-1, 128, 22, 22]             256\n",
      "     ConvNormAct-181          [-1, 128, 22, 22]               0\n",
      "          Conv2d-182          [-1, 128, 22, 22]         114,688\n",
      "        Identity-183          [-1, 128, 22, 22]               0\n",
      "            ReLU-184          [-1, 128, 22, 22]               0\n",
      "  BatchNormAct2d-185          [-1, 128, 22, 22]             256\n",
      "     ConvNormAct-186          [-1, 128, 22, 22]               0\n",
      "          Conv2d-187          [-1, 128, 22, 22]         114,688\n",
      "        Identity-188          [-1, 128, 22, 22]               0\n",
      "            ReLU-189          [-1, 128, 22, 22]               0\n",
      "  BatchNormAct2d-190          [-1, 128, 22, 22]             256\n",
      "     ConvNormAct-191          [-1, 128, 22, 22]               0\n",
      "          Conv2d-192          [-1, 128, 22, 22]         114,688\n",
      "        Identity-193          [-1, 128, 22, 22]               0\n",
      "            ReLU-194          [-1, 128, 22, 22]               0\n",
      "  BatchNormAct2d-195          [-1, 128, 22, 22]             256\n",
      "     ConvNormAct-196          [-1, 128, 22, 22]               0\n",
      "          Conv2d-197          [-1, 192, 22, 22]         172,032\n",
      "        Identity-198          [-1, 192, 22, 22]               0\n",
      "            ReLU-199          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-200          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-201          [-1, 192, 22, 22]               0\n",
      "          Conv2d-202          [-1, 192, 22, 22]         147,456\n",
      "        Identity-203          [-1, 192, 22, 22]               0\n",
      "            ReLU-204          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-205          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-206          [-1, 192, 22, 22]               0\n",
      "      InceptionC-207          [-1, 768, 22, 22]               0\n",
      "          Conv2d-208          [-1, 192, 22, 22]         147,456\n",
      "        Identity-209          [-1, 192, 22, 22]               0\n",
      "            ReLU-210          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-211          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-212          [-1, 192, 22, 22]               0\n",
      "          Conv2d-213          [-1, 160, 22, 22]         122,880\n",
      "        Identity-214          [-1, 160, 22, 22]               0\n",
      "            ReLU-215          [-1, 160, 22, 22]               0\n",
      "  BatchNormAct2d-216          [-1, 160, 22, 22]             320\n",
      "     ConvNormAct-217          [-1, 160, 22, 22]               0\n",
      "          Conv2d-218          [-1, 160, 22, 22]         179,200\n",
      "        Identity-219          [-1, 160, 22, 22]               0\n",
      "            ReLU-220          [-1, 160, 22, 22]               0\n",
      "  BatchNormAct2d-221          [-1, 160, 22, 22]             320\n",
      "     ConvNormAct-222          [-1, 160, 22, 22]               0\n",
      "          Conv2d-223          [-1, 192, 22, 22]         215,040\n",
      "        Identity-224          [-1, 192, 22, 22]               0\n",
      "            ReLU-225          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-226          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-227          [-1, 192, 22, 22]               0\n",
      "          Conv2d-228          [-1, 160, 22, 22]         122,880\n",
      "        Identity-229          [-1, 160, 22, 22]               0\n",
      "            ReLU-230          [-1, 160, 22, 22]               0\n",
      "  BatchNormAct2d-231          [-1, 160, 22, 22]             320\n",
      "     ConvNormAct-232          [-1, 160, 22, 22]               0\n",
      "          Conv2d-233          [-1, 160, 22, 22]         179,200\n",
      "        Identity-234          [-1, 160, 22, 22]               0\n",
      "            ReLU-235          [-1, 160, 22, 22]               0\n",
      "  BatchNormAct2d-236          [-1, 160, 22, 22]             320\n",
      "     ConvNormAct-237          [-1, 160, 22, 22]               0\n",
      "          Conv2d-238          [-1, 160, 22, 22]         179,200\n",
      "        Identity-239          [-1, 160, 22, 22]               0\n",
      "            ReLU-240          [-1, 160, 22, 22]               0\n",
      "  BatchNormAct2d-241          [-1, 160, 22, 22]             320\n",
      "     ConvNormAct-242          [-1, 160, 22, 22]               0\n",
      "          Conv2d-243          [-1, 160, 22, 22]         179,200\n",
      "        Identity-244          [-1, 160, 22, 22]               0\n",
      "            ReLU-245          [-1, 160, 22, 22]               0\n",
      "  BatchNormAct2d-246          [-1, 160, 22, 22]             320\n",
      "     ConvNormAct-247          [-1, 160, 22, 22]               0\n",
      "          Conv2d-248          [-1, 192, 22, 22]         215,040\n",
      "        Identity-249          [-1, 192, 22, 22]               0\n",
      "            ReLU-250          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-251          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-252          [-1, 192, 22, 22]               0\n",
      "          Conv2d-253          [-1, 192, 22, 22]         147,456\n",
      "        Identity-254          [-1, 192, 22, 22]               0\n",
      "            ReLU-255          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-256          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-257          [-1, 192, 22, 22]               0\n",
      "      InceptionC-258          [-1, 768, 22, 22]               0\n",
      "          Conv2d-259          [-1, 192, 22, 22]         147,456\n",
      "        Identity-260          [-1, 192, 22, 22]               0\n",
      "            ReLU-261          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-262          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-263          [-1, 192, 22, 22]               0\n",
      "          Conv2d-264          [-1, 160, 22, 22]         122,880\n",
      "        Identity-265          [-1, 160, 22, 22]               0\n",
      "            ReLU-266          [-1, 160, 22, 22]               0\n",
      "  BatchNormAct2d-267          [-1, 160, 22, 22]             320\n",
      "     ConvNormAct-268          [-1, 160, 22, 22]               0\n",
      "          Conv2d-269          [-1, 160, 22, 22]         179,200\n",
      "        Identity-270          [-1, 160, 22, 22]               0\n",
      "            ReLU-271          [-1, 160, 22, 22]               0\n",
      "  BatchNormAct2d-272          [-1, 160, 22, 22]             320\n",
      "     ConvNormAct-273          [-1, 160, 22, 22]               0\n",
      "          Conv2d-274          [-1, 192, 22, 22]         215,040\n",
      "        Identity-275          [-1, 192, 22, 22]               0\n",
      "            ReLU-276          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-277          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-278          [-1, 192, 22, 22]               0\n",
      "          Conv2d-279          [-1, 160, 22, 22]         122,880\n",
      "        Identity-280          [-1, 160, 22, 22]               0\n",
      "            ReLU-281          [-1, 160, 22, 22]               0\n",
      "  BatchNormAct2d-282          [-1, 160, 22, 22]             320\n",
      "     ConvNormAct-283          [-1, 160, 22, 22]               0\n",
      "          Conv2d-284          [-1, 160, 22, 22]         179,200\n",
      "        Identity-285          [-1, 160, 22, 22]               0\n",
      "            ReLU-286          [-1, 160, 22, 22]               0\n",
      "  BatchNormAct2d-287          [-1, 160, 22, 22]             320\n",
      "     ConvNormAct-288          [-1, 160, 22, 22]               0\n",
      "          Conv2d-289          [-1, 160, 22, 22]         179,200\n",
      "        Identity-290          [-1, 160, 22, 22]               0\n",
      "            ReLU-291          [-1, 160, 22, 22]               0\n",
      "  BatchNormAct2d-292          [-1, 160, 22, 22]             320\n",
      "     ConvNormAct-293          [-1, 160, 22, 22]               0\n",
      "          Conv2d-294          [-1, 160, 22, 22]         179,200\n",
      "        Identity-295          [-1, 160, 22, 22]               0\n",
      "            ReLU-296          [-1, 160, 22, 22]               0\n",
      "  BatchNormAct2d-297          [-1, 160, 22, 22]             320\n",
      "     ConvNormAct-298          [-1, 160, 22, 22]               0\n",
      "          Conv2d-299          [-1, 192, 22, 22]         215,040\n",
      "        Identity-300          [-1, 192, 22, 22]               0\n",
      "            ReLU-301          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-302          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-303          [-1, 192, 22, 22]               0\n",
      "          Conv2d-304          [-1, 192, 22, 22]         147,456\n",
      "        Identity-305          [-1, 192, 22, 22]               0\n",
      "            ReLU-306          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-307          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-308          [-1, 192, 22, 22]               0\n",
      "      InceptionC-309          [-1, 768, 22, 22]               0\n",
      "          Conv2d-310          [-1, 192, 22, 22]         147,456\n",
      "        Identity-311          [-1, 192, 22, 22]               0\n",
      "            ReLU-312          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-313          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-314          [-1, 192, 22, 22]               0\n",
      "          Conv2d-315          [-1, 192, 22, 22]         147,456\n",
      "        Identity-316          [-1, 192, 22, 22]               0\n",
      "            ReLU-317          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-318          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-319          [-1, 192, 22, 22]               0\n",
      "          Conv2d-320          [-1, 192, 22, 22]         258,048\n",
      "        Identity-321          [-1, 192, 22, 22]               0\n",
      "            ReLU-322          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-323          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-324          [-1, 192, 22, 22]               0\n",
      "          Conv2d-325          [-1, 192, 22, 22]         258,048\n",
      "        Identity-326          [-1, 192, 22, 22]               0\n",
      "            ReLU-327          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-328          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-329          [-1, 192, 22, 22]               0\n",
      "          Conv2d-330          [-1, 192, 22, 22]         147,456\n",
      "        Identity-331          [-1, 192, 22, 22]               0\n",
      "            ReLU-332          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-333          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-334          [-1, 192, 22, 22]               0\n",
      "          Conv2d-335          [-1, 192, 22, 22]         258,048\n",
      "        Identity-336          [-1, 192, 22, 22]               0\n",
      "            ReLU-337          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-338          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-339          [-1, 192, 22, 22]               0\n",
      "          Conv2d-340          [-1, 192, 22, 22]         258,048\n",
      "        Identity-341          [-1, 192, 22, 22]               0\n",
      "            ReLU-342          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-343          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-344          [-1, 192, 22, 22]               0\n",
      "          Conv2d-345          [-1, 192, 22, 22]         258,048\n",
      "        Identity-346          [-1, 192, 22, 22]               0\n",
      "            ReLU-347          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-348          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-349          [-1, 192, 22, 22]               0\n",
      "          Conv2d-350          [-1, 192, 22, 22]         258,048\n",
      "        Identity-351          [-1, 192, 22, 22]               0\n",
      "            ReLU-352          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-353          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-354          [-1, 192, 22, 22]               0\n",
      "          Conv2d-355          [-1, 192, 22, 22]         147,456\n",
      "        Identity-356          [-1, 192, 22, 22]               0\n",
      "            ReLU-357          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-358          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-359          [-1, 192, 22, 22]               0\n",
      "      InceptionC-360          [-1, 768, 22, 22]               0\n",
      "          Conv2d-361          [-1, 192, 22, 22]         147,456\n",
      "        Identity-362          [-1, 192, 22, 22]               0\n",
      "            ReLU-363          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-364          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-365          [-1, 192, 22, 22]               0\n",
      "          Conv2d-366          [-1, 320, 10, 10]         552,960\n",
      "        Identity-367          [-1, 320, 10, 10]               0\n",
      "            ReLU-368          [-1, 320, 10, 10]               0\n",
      "  BatchNormAct2d-369          [-1, 320, 10, 10]             640\n",
      "     ConvNormAct-370          [-1, 320, 10, 10]               0\n",
      "          Conv2d-371          [-1, 192, 22, 22]         147,456\n",
      "        Identity-372          [-1, 192, 22, 22]               0\n",
      "            ReLU-373          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-374          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-375          [-1, 192, 22, 22]               0\n",
      "          Conv2d-376          [-1, 192, 22, 22]         258,048\n",
      "        Identity-377          [-1, 192, 22, 22]               0\n",
      "            ReLU-378          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-379          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-380          [-1, 192, 22, 22]               0\n",
      "          Conv2d-381          [-1, 192, 22, 22]         258,048\n",
      "        Identity-382          [-1, 192, 22, 22]               0\n",
      "            ReLU-383          [-1, 192, 22, 22]               0\n",
      "  BatchNormAct2d-384          [-1, 192, 22, 22]             384\n",
      "     ConvNormAct-385          [-1, 192, 22, 22]               0\n",
      "          Conv2d-386          [-1, 192, 10, 10]         331,776\n",
      "        Identity-387          [-1, 192, 10, 10]               0\n",
      "            ReLU-388          [-1, 192, 10, 10]               0\n",
      "  BatchNormAct2d-389          [-1, 192, 10, 10]             384\n",
      "     ConvNormAct-390          [-1, 192, 10, 10]               0\n",
      "      InceptionD-391         [-1, 1280, 10, 10]               0\n",
      "          Conv2d-392          [-1, 320, 10, 10]         409,600\n",
      "        Identity-393          [-1, 320, 10, 10]               0\n",
      "            ReLU-394          [-1, 320, 10, 10]               0\n",
      "  BatchNormAct2d-395          [-1, 320, 10, 10]             640\n",
      "     ConvNormAct-396          [-1, 320, 10, 10]               0\n",
      "          Conv2d-397          [-1, 384, 10, 10]         491,520\n",
      "        Identity-398          [-1, 384, 10, 10]               0\n",
      "            ReLU-399          [-1, 384, 10, 10]               0\n",
      "  BatchNormAct2d-400          [-1, 384, 10, 10]             768\n",
      "     ConvNormAct-401          [-1, 384, 10, 10]               0\n",
      "          Conv2d-402          [-1, 384, 10, 10]         442,368\n",
      "        Identity-403          [-1, 384, 10, 10]               0\n",
      "            ReLU-404          [-1, 384, 10, 10]               0\n",
      "  BatchNormAct2d-405          [-1, 384, 10, 10]             768\n",
      "     ConvNormAct-406          [-1, 384, 10, 10]               0\n",
      "          Conv2d-407          [-1, 384, 10, 10]         442,368\n",
      "        Identity-408          [-1, 384, 10, 10]               0\n",
      "            ReLU-409          [-1, 384, 10, 10]               0\n",
      "  BatchNormAct2d-410          [-1, 384, 10, 10]             768\n",
      "     ConvNormAct-411          [-1, 384, 10, 10]               0\n",
      "          Conv2d-412          [-1, 448, 10, 10]         573,440\n",
      "        Identity-413          [-1, 448, 10, 10]               0\n",
      "            ReLU-414          [-1, 448, 10, 10]               0\n",
      "  BatchNormAct2d-415          [-1, 448, 10, 10]             896\n",
      "     ConvNormAct-416          [-1, 448, 10, 10]               0\n",
      "          Conv2d-417          [-1, 384, 10, 10]       1,548,288\n",
      "        Identity-418          [-1, 384, 10, 10]               0\n",
      "            ReLU-419          [-1, 384, 10, 10]               0\n",
      "  BatchNormAct2d-420          [-1, 384, 10, 10]             768\n",
      "     ConvNormAct-421          [-1, 384, 10, 10]               0\n",
      "          Conv2d-422          [-1, 384, 10, 10]         442,368\n",
      "        Identity-423          [-1, 384, 10, 10]               0\n",
      "            ReLU-424          [-1, 384, 10, 10]               0\n",
      "  BatchNormAct2d-425          [-1, 384, 10, 10]             768\n",
      "     ConvNormAct-426          [-1, 384, 10, 10]               0\n",
      "          Conv2d-427          [-1, 384, 10, 10]         442,368\n",
      "        Identity-428          [-1, 384, 10, 10]               0\n",
      "            ReLU-429          [-1, 384, 10, 10]               0\n",
      "  BatchNormAct2d-430          [-1, 384, 10, 10]             768\n",
      "     ConvNormAct-431          [-1, 384, 10, 10]               0\n",
      "          Conv2d-432          [-1, 192, 10, 10]         245,760\n",
      "        Identity-433          [-1, 192, 10, 10]               0\n",
      "            ReLU-434          [-1, 192, 10, 10]               0\n",
      "  BatchNormAct2d-435          [-1, 192, 10, 10]             384\n",
      "     ConvNormAct-436          [-1, 192, 10, 10]               0\n",
      "      InceptionE-437         [-1, 2048, 10, 10]               0\n",
      "          Conv2d-438          [-1, 320, 10, 10]         655,360\n",
      "        Identity-439          [-1, 320, 10, 10]               0\n",
      "            ReLU-440          [-1, 320, 10, 10]               0\n",
      "  BatchNormAct2d-441          [-1, 320, 10, 10]             640\n",
      "     ConvNormAct-442          [-1, 320, 10, 10]               0\n",
      "          Conv2d-443          [-1, 384, 10, 10]         786,432\n",
      "        Identity-444          [-1, 384, 10, 10]               0\n",
      "            ReLU-445          [-1, 384, 10, 10]               0\n",
      "  BatchNormAct2d-446          [-1, 384, 10, 10]             768\n",
      "     ConvNormAct-447          [-1, 384, 10, 10]               0\n",
      "          Conv2d-448          [-1, 384, 10, 10]         442,368\n",
      "        Identity-449          [-1, 384, 10, 10]               0\n",
      "            ReLU-450          [-1, 384, 10, 10]               0\n",
      "  BatchNormAct2d-451          [-1, 384, 10, 10]             768\n",
      "     ConvNormAct-452          [-1, 384, 10, 10]               0\n",
      "          Conv2d-453          [-1, 384, 10, 10]         442,368\n",
      "        Identity-454          [-1, 384, 10, 10]               0\n",
      "            ReLU-455          [-1, 384, 10, 10]               0\n",
      "  BatchNormAct2d-456          [-1, 384, 10, 10]             768\n",
      "     ConvNormAct-457          [-1, 384, 10, 10]               0\n",
      "          Conv2d-458          [-1, 448, 10, 10]         917,504\n",
      "        Identity-459          [-1, 448, 10, 10]               0\n",
      "            ReLU-460          [-1, 448, 10, 10]               0\n",
      "  BatchNormAct2d-461          [-1, 448, 10, 10]             896\n",
      "     ConvNormAct-462          [-1, 448, 10, 10]               0\n",
      "          Conv2d-463          [-1, 384, 10, 10]       1,548,288\n",
      "        Identity-464          [-1, 384, 10, 10]               0\n",
      "            ReLU-465          [-1, 384, 10, 10]               0\n",
      "  BatchNormAct2d-466          [-1, 384, 10, 10]             768\n",
      "     ConvNormAct-467          [-1, 384, 10, 10]               0\n",
      "          Conv2d-468          [-1, 384, 10, 10]         442,368\n",
      "        Identity-469          [-1, 384, 10, 10]               0\n",
      "            ReLU-470          [-1, 384, 10, 10]               0\n",
      "  BatchNormAct2d-471          [-1, 384, 10, 10]             768\n",
      "     ConvNormAct-472          [-1, 384, 10, 10]               0\n",
      "          Conv2d-473          [-1, 384, 10, 10]         442,368\n",
      "        Identity-474          [-1, 384, 10, 10]               0\n",
      "            ReLU-475          [-1, 384, 10, 10]               0\n",
      "  BatchNormAct2d-476          [-1, 384, 10, 10]             768\n",
      "     ConvNormAct-477          [-1, 384, 10, 10]               0\n",
      "          Conv2d-478          [-1, 192, 10, 10]         393,216\n",
      "        Identity-479          [-1, 192, 10, 10]               0\n",
      "            ReLU-480          [-1, 192, 10, 10]               0\n",
      "  BatchNormAct2d-481          [-1, 192, 10, 10]             384\n",
      "     ConvNormAct-482          [-1, 192, 10, 10]               0\n",
      "      InceptionE-483         [-1, 2048, 10, 10]               0\n",
      "AdaptiveAvgPool2d-484           [-1, 2048, 1, 1]               0\n",
      "         Flatten-485                 [-1, 2048]               0\n",
      "SelectAdaptivePool2d-486                 [-1, 2048]               0\n",
      "         Dropout-487                 [-1, 2048]               0\n",
      "          Linear-488                    [-1, 4]           8,196\n",
      "================================================================\n",
      "Total params: 21,793,764\n",
      "Trainable params: 21,793,764\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.69\n",
      "Forward/backward pass size (MB): 605.13\n",
      "Params size (MB): 83.14\n",
      "Estimated Total Size (MB): 689.95\n",
      "----------------------------------------------------------------\n",
      "model : inceptionv3_RockModel\n",
      "no valid counterparts augmentation selected\n",
      "Epoch 1/10\n",
      "----------\n",
      "Epoch: 1     train index of 5 minibatch: 1      time used: 32.64608550071716\n",
      "minibatch AVG loss: 1.9941560268402099\n",
      "\n",
      "Epoch: 1  train \n",
      "Loss: 1.9942  Acc: 10.0000\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 5.0\n",
      "marble-shadow precision: 16.6667  recall: 20.0000\n",
      "marble-shadow sensitivity: 20.0000  specificity: 66.6667\n",
      "marble-shadow FPR: 33.3333  NPV: 71.4286\n",
      "marble-shadow TP: 1.0\n",
      "marble-shadow TN: 10.0\n",
      "marble-shadow FP: 5.0\n",
      "marble-shadow FN: 4.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 80.0000\n",
      "quartzite-oceanblue FPR: 20.0000  NPV: 70.5882\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 12.0\n",
      "quartzite-oceanblue FP: 3.0\n",
      "quartzite-oceanblue FN: 5.0\n",
      "quartzite-patagonia precision: 9.0909  recall: 20.0000\n",
      "quartzite-patagonia sensitivity: 20.0000  specificity: 33.3333\n",
      "quartzite-patagonia FPR: 66.6667  NPV: 55.5556\n",
      "quartzite-patagonia TP: 1.0\n",
      "quartzite-patagonia TN: 5.0\n",
      "quartzite-patagonia FP: 10.0\n",
      "quartzite-patagonia FN: 4.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 1  val \n",
      "Loss: 2.3502  Acc: 8.3333\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 33.3333\n",
      "marble-shadow FPR: 66.6667  NPV: 50.0000\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 3.0\n",
      "marble-shadow FP: 6.0\n",
      "marble-shadow FN: 3.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 66.6667\n",
      "quartzite-oceanblue FPR: 33.3333  NPV: 66.6667\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 6.0\n",
      "quartzite-oceanblue FP: 3.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 33.3333  recall: 33.3333\n",
      "quartzite-patagonia sensitivity: 33.3333  specificity: 77.7778\n",
      "quartzite-patagonia FPR: 22.2222  NPV: 77.7778\n",
      "quartzite-patagonia TP: 1.0\n",
      "quartzite-patagonia TN: 7.0\n",
      "quartzite-patagonia FP: 2.0\n",
      "quartzite-patagonia FN: 2.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Epoch: 2     train index of 5 minibatch: 1      time used: 30.429646253585815\n",
      "minibatch AVG loss: 1.464174735546112\n",
      "\n",
      "Epoch: 2  train \n",
      "Loss: 1.4642  Acc: 40.0000\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 5.0\n",
      "marble-shadow precision: 42.8571  recall: 60.0000\n",
      "marble-shadow sensitivity: 60.0000  specificity: 73.3333\n",
      "marble-shadow FPR: 26.6667  NPV: 84.6154\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 11.0\n",
      "marble-shadow FP: 4.0\n",
      "marble-shadow FN: 2.0\n",
      "quartzite-oceanblue precision: 50.0000  recall: 20.0000\n",
      "quartzite-oceanblue sensitivity: 20.0000  specificity: 93.3333\n",
      "quartzite-oceanblue FPR: 6.6667  NPV: 77.7778\n",
      "quartzite-oceanblue TP: 1.0\n",
      "quartzite-oceanblue TN: 14.0\n",
      "quartzite-oceanblue FP: 1.0\n",
      "quartzite-oceanblue FN: 4.0\n",
      "quartzite-patagonia precision: 36.3636  recall: 80.0000\n",
      "quartzite-patagonia sensitivity: 80.0000  specificity: 53.3333\n",
      "quartzite-patagonia FPR: 46.6667  NPV: 88.8889\n",
      "quartzite-patagonia TP: 4.0\n",
      "quartzite-patagonia TN: 8.0\n",
      "quartzite-patagonia FP: 7.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 2  val \n",
      "Loss: 1.8870  Acc: 25.0000\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 33.3333  recall: 66.6667\n",
      "marble-shadow sensitivity: 66.6667  specificity: 55.5556\n",
      "marble-shadow FPR: 44.4444  NPV: 83.3333\n",
      "marble-shadow TP: 2.0\n",
      "marble-shadow TN: 5.0\n",
      "marble-shadow FP: 4.0\n",
      "marble-shadow FN: 1.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 77.7778\n",
      "quartzite-oceanblue FPR: 22.2222  NPV: 70.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 7.0\n",
      "quartzite-oceanblue FP: 2.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 25.0000  recall: 33.3333\n",
      "quartzite-patagonia sensitivity: 33.3333  specificity: 66.6667\n",
      "quartzite-patagonia FPR: 33.3333  NPV: 75.0000\n",
      "quartzite-patagonia TP: 1.0\n",
      "quartzite-patagonia TN: 6.0\n",
      "quartzite-patagonia FP: 3.0\n",
      "quartzite-patagonia FN: 2.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Epoch: 3     train index of 5 minibatch: 1      time used: 29.328258275985718\n",
      "minibatch AVG loss: 1.223166835308075\n",
      "\n",
      "Epoch: 3  train \n",
      "Loss: 1.2232  Acc: 50.0000\n",
      "granite-blackswan precision: 100.0000  recall: 20.0000\n",
      "granite-blackswan sensitivity: 20.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 78.9474\n",
      "granite-blackswan TP: 1.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 4.0\n",
      "marble-shadow precision: 50.0000  recall: 40.0000\n",
      "marble-shadow sensitivity: 40.0000  specificity: 86.6667\n",
      "marble-shadow FPR: 13.3333  NPV: 81.2500\n",
      "marble-shadow TP: 2.0\n",
      "marble-shadow TN: 13.0\n",
      "marble-shadow FP: 2.0\n",
      "marble-shadow FN: 3.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 40.0000\n",
      "quartzite-oceanblue sensitivity: 40.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 83.3333\n",
      "quartzite-oceanblue TP: 2.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 38.4615  recall: 100.0000\n",
      "quartzite-patagonia sensitivity: 100.0000  specificity: 46.6667\n",
      "quartzite-patagonia FPR: 53.3333  NPV: 100.0000\n",
      "quartzite-patagonia TP: 5.0\n",
      "quartzite-patagonia TN: 7.0\n",
      "quartzite-patagonia FP: 8.0\n",
      "quartzite-patagonia FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 3  val \n",
      "Loss: 1.5479  Acc: 33.3333\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 33.3333  recall: 33.3333\n",
      "marble-shadow sensitivity: 33.3333  specificity: 77.7778\n",
      "marble-shadow FPR: 22.2222  NPV: 77.7778\n",
      "marble-shadow TP: 1.0\n",
      "marble-shadow TN: 7.0\n",
      "marble-shadow FP: 2.0\n",
      "marble-shadow FN: 2.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 33.3333  recall: 100.0000\n",
      "quartzite-patagonia sensitivity: 100.0000  specificity: 33.3333\n",
      "quartzite-patagonia FPR: 66.6667  NPV: 100.0000\n",
      "quartzite-patagonia TP: 3.0\n",
      "quartzite-patagonia TN: 3.0\n",
      "quartzite-patagonia FP: 6.0\n",
      "quartzite-patagonia FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Epoch: 4     train index of 5 minibatch: 1      time used: 28.859938859939575\n",
      "minibatch AVG loss: 1.2196413636207581\n",
      "\n",
      "Epoch: 4  train \n",
      "Loss: 1.2196  Acc: 35.0000\n",
      "granite-blackswan precision: 50.0000  recall: 20.0000\n",
      "granite-blackswan sensitivity: 20.0000  specificity: 93.3333\n",
      "granite-blackswan FPR: 6.6667  NPV: 77.7778\n",
      "granite-blackswan TP: 1.0\n",
      "granite-blackswan TN: 14.0\n",
      "granite-blackswan FP: 1.0\n",
      "granite-blackswan FN: 4.0\n",
      "marble-shadow precision: 66.6667  recall: 80.0000\n",
      "marble-shadow sensitivity: 80.0000  specificity: 86.6667\n",
      "marble-shadow FPR: 13.3333  NPV: 92.8571\n",
      "marble-shadow TP: 4.0\n",
      "marble-shadow TN: 13.0\n",
      "marble-shadow FP: 2.0\n",
      "marble-shadow FN: 1.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 86.6667\n",
      "quartzite-oceanblue FPR: 13.3333  NPV: 72.2222\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 13.0\n",
      "quartzite-oceanblue FP: 2.0\n",
      "quartzite-oceanblue FN: 5.0\n",
      "quartzite-patagonia precision: 20.0000  recall: 40.0000\n",
      "quartzite-patagonia sensitivity: 40.0000  specificity: 46.6667\n",
      "quartzite-patagonia FPR: 53.3333  NPV: 70.0000\n",
      "quartzite-patagonia TP: 2.0\n",
      "quartzite-patagonia TN: 7.0\n",
      "quartzite-patagonia FP: 8.0\n",
      "quartzite-patagonia FN: 3.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 4  val \n",
      "Loss: 1.2577  Acc: 33.3333\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 33.3333  recall: 33.3333\n",
      "marble-shadow sensitivity: 33.3333  specificity: 77.7778\n",
      "marble-shadow FPR: 22.2222  NPV: 77.7778\n",
      "marble-shadow TP: 1.0\n",
      "marble-shadow TN: 7.0\n",
      "marble-shadow FP: 2.0\n",
      "marble-shadow FN: 2.0\n",
      "quartzite-oceanblue precision: 50.0000  recall: 33.3333\n",
      "quartzite-oceanblue sensitivity: 33.3333  specificity: 88.8889\n",
      "quartzite-oceanblue FPR: 11.1111  NPV: 80.0000\n",
      "quartzite-oceanblue TP: 1.0\n",
      "quartzite-oceanblue TN: 8.0\n",
      "quartzite-oceanblue FP: 1.0\n",
      "quartzite-oceanblue FN: 2.0\n",
      "quartzite-patagonia precision: 28.5714  recall: 66.6667\n",
      "quartzite-patagonia sensitivity: 66.6667  specificity: 44.4444\n",
      "quartzite-patagonia FPR: 55.5556  NPV: 80.0000\n",
      "quartzite-patagonia TP: 2.0\n",
      "quartzite-patagonia TN: 4.0\n",
      "quartzite-patagonia FP: 5.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Epoch: 5     train index of 5 minibatch: 1      time used: 33.3884539604187\n",
      "minibatch AVG loss: 0.9447920322418213\n",
      "\n",
      "Epoch: 5  train \n",
      "Loss: 0.9448  Acc: 60.0000\n",
      "granite-blackswan precision: 100.0000  recall: 20.0000\n",
      "granite-blackswan sensitivity: 20.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 78.9474\n",
      "granite-blackswan TP: 1.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 4.0\n",
      "marble-shadow precision: 50.0000  recall: 60.0000\n",
      "marble-shadow sensitivity: 60.0000  specificity: 80.0000\n",
      "marble-shadow FPR: 20.0000  NPV: 85.7143\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 12.0\n",
      "marble-shadow FP: 3.0\n",
      "marble-shadow FN: 2.0\n",
      "quartzite-oceanblue precision: 75.0000  recall: 60.0000\n",
      "quartzite-oceanblue sensitivity: 60.0000  specificity: 93.3333\n",
      "quartzite-oceanblue FPR: 6.6667  NPV: 87.5000\n",
      "quartzite-oceanblue TP: 3.0\n",
      "quartzite-oceanblue TN: 14.0\n",
      "quartzite-oceanblue FP: 1.0\n",
      "quartzite-oceanblue FN: 2.0\n",
      "quartzite-patagonia precision: 55.5556  recall: 100.0000\n",
      "quartzite-patagonia sensitivity: 100.0000  specificity: 73.3333\n",
      "quartzite-patagonia FPR: 26.6667  NPV: 100.0000\n",
      "quartzite-patagonia TP: 5.0\n",
      "quartzite-patagonia TN: 11.0\n",
      "quartzite-patagonia FP: 4.0\n",
      "quartzite-patagonia FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 5  val \n",
      "Loss: 1.1867  Acc: 41.6667\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 40.0000  recall: 66.6667\n",
      "marble-shadow sensitivity: 66.6667  specificity: 66.6667\n",
      "marble-shadow FPR: 33.3333  NPV: 85.7143\n",
      "marble-shadow TP: 2.0\n",
      "marble-shadow TN: 6.0\n",
      "marble-shadow FP: 3.0\n",
      "marble-shadow FN: 1.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 33.3333\n",
      "quartzite-oceanblue sensitivity: 33.3333  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 81.8182\n",
      "quartzite-oceanblue TP: 1.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 2.0\n",
      "quartzite-patagonia precision: 33.3333  recall: 66.6667\n",
      "quartzite-patagonia sensitivity: 66.6667  specificity: 55.5556\n",
      "quartzite-patagonia FPR: 44.4444  NPV: 83.3333\n",
      "quartzite-patagonia TP: 2.0\n",
      "quartzite-patagonia TN: 5.0\n",
      "quartzite-patagonia FP: 4.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Epoch: 6     train index of 5 minibatch: 1      time used: 29.070009231567383\n",
      "minibatch AVG loss: 0.8672098517417908\n",
      "\n",
      "Epoch: 6  train \n",
      "Loss: 0.8672  Acc: 55.0000\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 5.0\n",
      "marble-shadow precision: 50.0000  recall: 80.0000\n",
      "marble-shadow sensitivity: 80.0000  specificity: 73.3333\n",
      "marble-shadow FPR: 26.6667  NPV: 91.6667\n",
      "marble-shadow TP: 4.0\n",
      "marble-shadow TN: 11.0\n",
      "marble-shadow FP: 4.0\n",
      "marble-shadow FN: 1.0\n",
      "quartzite-oceanblue precision: 80.0000  recall: 80.0000\n",
      "quartzite-oceanblue sensitivity: 80.0000  specificity: 93.3333\n",
      "quartzite-oceanblue FPR: 6.6667  NPV: 93.3333\n",
      "quartzite-oceanblue TP: 4.0\n",
      "quartzite-oceanblue TN: 14.0\n",
      "quartzite-oceanblue FP: 1.0\n",
      "quartzite-oceanblue FN: 1.0\n",
      "quartzite-patagonia precision: 42.8571  recall: 60.0000\n",
      "quartzite-patagonia sensitivity: 60.0000  specificity: 73.3333\n",
      "quartzite-patagonia FPR: 26.6667  NPV: 84.6154\n",
      "quartzite-patagonia TP: 3.0\n",
      "quartzite-patagonia TN: 11.0\n",
      "quartzite-patagonia FP: 4.0\n",
      "quartzite-patagonia FN: 2.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 6  val \n",
      "Loss: 1.2186  Acc: 41.6667\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 50.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 66.6667\n",
      "marble-shadow FPR: 33.3333  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 6.0\n",
      "marble-shadow FP: 3.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 33.3333  recall: 66.6667\n",
      "quartzite-patagonia sensitivity: 66.6667  specificity: 55.5556\n",
      "quartzite-patagonia FPR: 44.4444  NPV: 83.3333\n",
      "quartzite-patagonia TP: 2.0\n",
      "quartzite-patagonia TN: 5.0\n",
      "quartzite-patagonia FP: 4.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Epoch: 7     train index of 5 minibatch: 1      time used: 31.196099519729614\n",
      "minibatch AVG loss: 0.7858051836490632\n",
      "\n",
      "Epoch: 7  train \n",
      "Loss: 0.7858  Acc: 60.0000\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 5.0\n",
      "marble-shadow precision: 62.5000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 80.0000\n",
      "marble-shadow FPR: 20.0000  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 12.0\n",
      "marble-shadow FP: 3.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 75.0000  recall: 60.0000\n",
      "quartzite-oceanblue sensitivity: 60.0000  specificity: 93.3333\n",
      "quartzite-oceanblue FPR: 6.6667  NPV: 87.5000\n",
      "quartzite-oceanblue TP: 3.0\n",
      "quartzite-oceanblue TN: 14.0\n",
      "quartzite-oceanblue FP: 1.0\n",
      "quartzite-oceanblue FN: 2.0\n",
      "quartzite-patagonia precision: 50.0000  recall: 80.0000\n",
      "quartzite-patagonia sensitivity: 80.0000  specificity: 73.3333\n",
      "quartzite-patagonia FPR: 26.6667  NPV: 91.6667\n",
      "quartzite-patagonia TP: 4.0\n",
      "quartzite-patagonia TN: 11.0\n",
      "quartzite-patagonia FP: 4.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 7  val \n",
      "Loss: 1.1323  Acc: 50.0000\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 50.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 66.6667\n",
      "marble-shadow FPR: 33.3333  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 6.0\n",
      "marble-shadow FP: 3.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 33.3333\n",
      "quartzite-oceanblue sensitivity: 33.3333  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 81.8182\n",
      "quartzite-oceanblue TP: 1.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 2.0\n",
      "quartzite-patagonia precision: 40.0000  recall: 66.6667\n",
      "quartzite-patagonia sensitivity: 66.6667  specificity: 66.6667\n",
      "quartzite-patagonia FPR: 33.3333  NPV: 85.7143\n",
      "quartzite-patagonia TP: 2.0\n",
      "quartzite-patagonia TN: 6.0\n",
      "quartzite-patagonia FP: 3.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Epoch: 8     train index of 5 minibatch: 1      time used: 31.119147300720215\n",
      "minibatch AVG loss: 0.8933756589889527\n",
      "\n",
      "Epoch: 8  train \n",
      "Loss: 0.8934  Acc: 75.0000\n",
      "granite-blackswan precision: 100.0000  recall: 60.0000\n",
      "granite-blackswan sensitivity: 60.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 88.2353\n",
      "granite-blackswan TP: 3.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 2.0\n",
      "marble-shadow precision: 80.0000  recall: 80.0000\n",
      "marble-shadow sensitivity: 80.0000  specificity: 93.3333\n",
      "marble-shadow FPR: 6.6667  NPV: 93.3333\n",
      "marble-shadow TP: 4.0\n",
      "marble-shadow TN: 14.0\n",
      "marble-shadow FP: 1.0\n",
      "marble-shadow FN: 1.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 60.0000\n",
      "quartzite-oceanblue sensitivity: 60.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 88.2353\n",
      "quartzite-oceanblue TP: 3.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 2.0\n",
      "quartzite-patagonia precision: 55.5556  recall: 100.0000\n",
      "quartzite-patagonia sensitivity: 100.0000  specificity: 73.3333\n",
      "quartzite-patagonia FPR: 26.6667  NPV: 100.0000\n",
      "quartzite-patagonia TP: 5.0\n",
      "quartzite-patagonia TN: 11.0\n",
      "quartzite-patagonia FP: 4.0\n",
      "quartzite-patagonia FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 8  val \n",
      "Loss: 1.2882  Acc: 41.6667\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 42.8571  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 55.5556\n",
      "marble-shadow FPR: 44.4444  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 5.0\n",
      "marble-shadow FP: 4.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 40.0000  recall: 66.6667\n",
      "quartzite-patagonia sensitivity: 66.6667  specificity: 66.6667\n",
      "quartzite-patagonia FPR: 33.3333  NPV: 85.7143\n",
      "quartzite-patagonia TP: 2.0\n",
      "quartzite-patagonia TN: 6.0\n",
      "quartzite-patagonia FP: 3.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Epoch: 9     train index of 5 minibatch: 1      time used: 32.1238694190979\n",
      "minibatch AVG loss: 0.6928754925727845\n",
      "\n",
      "Epoch: 9  train \n",
      "Loss: 0.6929  Acc: 80.0000\n",
      "granite-blackswan precision: 100.0000  recall: 40.0000\n",
      "granite-blackswan sensitivity: 40.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 83.3333\n",
      "granite-blackswan TP: 2.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 57.1429  recall: 80.0000\n",
      "marble-shadow sensitivity: 80.0000  specificity: 80.0000\n",
      "marble-shadow FPR: 20.0000  NPV: 92.3077\n",
      "marble-shadow TP: 4.0\n",
      "marble-shadow TN: 12.0\n",
      "marble-shadow FP: 3.0\n",
      "marble-shadow FN: 1.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-oceanblue TP: 5.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 0.0\n",
      "quartzite-patagonia precision: 83.3333  recall: 100.0000\n",
      "quartzite-patagonia sensitivity: 100.0000  specificity: 93.3333\n",
      "quartzite-patagonia FPR: 6.6667  NPV: 100.0000\n",
      "quartzite-patagonia TP: 5.0\n",
      "quartzite-patagonia TN: 14.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 9  val \n",
      "Loss: 1.2091  Acc: 50.0000\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 50.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 66.6667\n",
      "marble-shadow FPR: 33.3333  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 6.0\n",
      "marble-shadow FP: 3.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 33.3333\n",
      "quartzite-oceanblue sensitivity: 33.3333  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 81.8182\n",
      "quartzite-oceanblue TP: 1.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 2.0\n",
      "quartzite-patagonia precision: 40.0000  recall: 66.6667\n",
      "quartzite-patagonia sensitivity: 66.6667  specificity: 66.6667\n",
      "quartzite-patagonia FPR: 33.3333  NPV: 85.7143\n",
      "quartzite-patagonia TP: 2.0\n",
      "quartzite-patagonia TN: 6.0\n",
      "quartzite-patagonia FP: 3.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Epoch: 10     train index of 5 minibatch: 1      time used: 27.39676022529602\n",
      "minibatch AVG loss: 0.7837339997291565\n",
      "\n",
      "Epoch: 10  train \n",
      "Loss: 0.7837  Acc: 70.0000\n",
      "granite-blackswan precision: 100.0000  recall: 60.0000\n",
      "granite-blackswan sensitivity: 60.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 88.2353\n",
      "granite-blackswan TP: 3.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 2.0\n",
      "marble-shadow precision: 62.5000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 80.0000\n",
      "marble-shadow FPR: 20.0000  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 12.0\n",
      "marble-shadow FP: 3.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 40.0000\n",
      "quartzite-oceanblue sensitivity: 40.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 83.3333\n",
      "quartzite-oceanblue TP: 2.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 57.1429  recall: 80.0000\n",
      "quartzite-patagonia sensitivity: 80.0000  specificity: 80.0000\n",
      "quartzite-patagonia FPR: 20.0000  NPV: 92.3077\n",
      "quartzite-patagonia TP: 4.0\n",
      "quartzite-patagonia TN: 12.0\n",
      "quartzite-patagonia FP: 3.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 10  val \n",
      "Loss: 1.3660  Acc: 41.6667\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 40.0000  recall: 66.6667\n",
      "marble-shadow sensitivity: 66.6667  specificity: 66.6667\n",
      "marble-shadow FPR: 33.3333  NPV: 85.7143\n",
      "marble-shadow TP: 2.0\n",
      "marble-shadow TN: 6.0\n",
      "marble-shadow FP: 3.0\n",
      "marble-shadow FN: 1.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 33.3333\n",
      "quartzite-oceanblue sensitivity: 33.3333  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 81.8182\n",
      "quartzite-oceanblue TP: 1.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 2.0\n",
      "quartzite-patagonia precision: 33.3333  recall: 66.6667\n",
      "quartzite-patagonia sensitivity: 66.6667  specificity: 55.5556\n",
      "quartzite-patagonia FPR: 44.4444  NPV: 83.3333\n",
      "quartzite-patagonia TP: 2.0\n",
      "quartzite-patagonia TN: 5.0\n",
      "quartzite-patagonia FP: 4.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Training complete in 7m 26s\n",
      "Best epoch idx:  9\n",
      "Best epoch train Acc: 80.000000\n",
      "Best epoch val Acc: 50.000000\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "marble-shadow precision: 50.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 66.6667\n",
      "marble-shadow FPR: 33.3333  NPV: 100.0000\n",
      "quartzite-oceanblue precision: 100.0000  recall: 33.3333\n",
      "quartzite-oceanblue sensitivity: 33.3333  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 81.8182\n",
      "quartzite-patagonia precision: 40.0000  recall: 66.6667\n",
      "quartzite-patagonia sensitivity: 66.6667  specificity: 66.6667\n",
      "quartzite-patagonia FPR: 33.3333  NPV: 85.7143\n",
      "model trained by GPU (idx:0) has been saved at  saved_models\\CLS_inceptionv3_RockModel.pth\n"
     ]
    }
   ],
   "source": [
    "!python Train.py --model_idx inceptionv3_RockModel --edge_size 384 --data_augmentation_mode 2 --batch_size 4 --lr 0.00001 --lrf 0.05 --enable_tensorboard --check_minibatch 5 --dataroot sample_datasets/warwick_CLS --model_path saved_models --draw_root runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inceptionv3 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names: ['granite-blackswan', 'marble-shadow', 'quartzite-oceanblue', 'quartzite-patagonia']\n",
      "['inception_next_base',\n",
      " 'inception_next_small',\n",
      " 'inception_next_tiny',\n",
      " 'inception_resnet_v2',\n",
      " 'inception_v3',\n",
      " 'inception_v4']\n",
      "test model outputï¼ tensor([[-1.3287, -0.1401, -1.7336,  1.3368]], grad_fn=<AddmmBackward0>)\n",
      "model is ready now!\n",
      "model loaded\n",
      "model : inceptionv3_RockModel\n",
      "*********************************setting*************************************\n",
      "Namespace(model_idx='inceptionv3_RockModel', MIL_Stripe=False, drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.0, cls_token_off=False, pos_embedding_off=False, att_module='SimAM', gpu_idx=0, dataroot='sample_datasets/warwick_CLS', model_path='saved_models', draw_root='runs', paint=True, enable_notify=False, enable_tensorboard=False, enable_attention_check=True, enable_visualize_check=False, data_augmentation_mode=2, num_classes=0, edge_size=384, batch_size=1, check_minibatch=5)\n",
      "Epoch: Test\n",
      "----------\n",
      "Epoch: test     test index of 5 minibatch: 1      time used: 7.8914008140563965\n",
      "minibatch AVG loss: 1.7125726537342416\n",
      "ERRO in model_idx\n",
      "model: inceptionv3_RockModel  with edge_size 384 is not supported yet\n",
      "Epoch: test     test index of 5 minibatch: 2      time used: 2.3769102096557617\n",
      "minibatch AVG loss: 0.9517689494277874\n",
      "ERRO in model_idx\n",
      "model: inceptionv3_RockModel  with edge_size 384 is not supported yet\n",
      "\n",
      "Epoch:  test \n",
      "Loss: 1.1322  Acc: 58.3333\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 75.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 88.8889\n",
      "marble-shadow FPR: 11.1111  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 8.0\n",
      "marble-shadow FP: 1.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 33.3333\n",
      "quartzite-oceanblue sensitivity: 33.3333  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 81.8182\n",
      "quartzite-oceanblue TP: 1.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 2.0\n",
      "quartzite-patagonia precision: 42.8571  recall: 100.0000\n",
      "quartzite-patagonia sensitivity: 100.0000  specificity: 55.5556\n",
      "quartzite-patagonia FPR: 44.4444  NPV: 100.0000\n",
      "quartzite-patagonia TP: 3.0\n",
      "quartzite-patagonia TN: 5.0\n",
      "quartzite-patagonia FP: 4.0\n",
      "quartzite-patagonia FN: 0.0\n",
      "\n",
      "\n",
      "Testing complete in 0m 13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\usuariolocal\\OneDrive\\Documentos\\Douglas\\Mestrado\\3 - Curso\\Meu projeto\\si_vit_ornamental_rocks\\utils\\visual_usage.py:35: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.pause(0.001)  # pause a bit so that plots are updated\n",
      "c:\\Users\\usuariolocal\\OneDrive\\Documentos\\Douglas\\Mestrado\\3 - Curso\\Meu projeto\\si_vit_ornamental_rocks\\utils\\visual_usage.py:302: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.pause(0.001)  # pause a bit so that plots are updated\n",
      "c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "!python Test.py --model_idx inceptionv3_RockModel --edge_size 384 --data_augmentation_mode 2 --enable_attention_check --check_minibatch 5 --dataroot sample_datasets/warwick_CLS --model_path saved_models --draw_root runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xception network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names: ['granite-blackswan', 'marble-shadow', 'quartzite-oceanblue', 'quartzite-patagonia']\n",
      "*********************************setting*************************************\n",
      "Namespace(model_idx='xception_RockModel', drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.0, cls_token_off=False, pos_embedding_off=False, att_module='SimAM', backbone_PT_off=False, gpu_idx=-1, dataroot='sample_datasets/warwick_CLS', model_path='saved_models', draw_root='runs', paint=True, enable_notify=False, enable_tensorboard=True, enable_attention_check=False, enable_visualize_check=False, enable_sam=False, augmentation_name=None, data_augmentation_mode=2, linearprobing=False, Pre_Trained_model_path=None, num_classes=0, edge_size=384, num_workers=2, batch_size=4, check_minibatch=5, num_epochs=10, intake_epochs=0, lr=1e-05, lrf=0.05, opt_name='Adam')\n",
      "we dont have more GPU idx here, try to use gpu_idx=0\n",
      "['legacy_xception',\n",
      " 'xception41',\n",
      " 'xception41p',\n",
      " 'xception65',\n",
      " 'xception65p',\n",
      " 'xception71']\n",
      "test model outputï¼ tensor([[ 0.1633, -0.1042,  0.0620,  0.0647]], grad_fn=<AddmmBackward0>)\n",
      "model is ready now!\n",
      "GPU: 0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 191, 191]             864\n",
      "       BatchNorm2d-2         [-1, 32, 191, 191]              64\n",
      "              ReLU-3         [-1, 32, 191, 191]               0\n",
      "            Conv2d-4         [-1, 64, 189, 189]          18,432\n",
      "       BatchNorm2d-5         [-1, 64, 189, 189]             128\n",
      "              ReLU-6         [-1, 64, 189, 189]               0\n",
      "            Conv2d-7         [-1, 64, 189, 189]             576\n",
      "            Conv2d-8        [-1, 128, 189, 189]           8,192\n",
      "   SeparableConv2d-9        [-1, 128, 189, 189]               0\n",
      "      BatchNorm2d-10        [-1, 128, 189, 189]             256\n",
      "             ReLU-11        [-1, 128, 189, 189]               0\n",
      "           Conv2d-12        [-1, 128, 189, 189]           1,152\n",
      "           Conv2d-13        [-1, 128, 189, 189]          16,384\n",
      "  SeparableConv2d-14        [-1, 128, 189, 189]               0\n",
      "      BatchNorm2d-15        [-1, 128, 189, 189]             256\n",
      "        MaxPool2d-16          [-1, 128, 95, 95]               0\n",
      "           Conv2d-17          [-1, 128, 95, 95]           8,192\n",
      "      BatchNorm2d-18          [-1, 128, 95, 95]             256\n",
      "            Block-19          [-1, 128, 95, 95]               0\n",
      "             ReLU-20          [-1, 128, 95, 95]               0\n",
      "           Conv2d-21          [-1, 128, 95, 95]           1,152\n",
      "           Conv2d-22          [-1, 256, 95, 95]          32,768\n",
      "  SeparableConv2d-23          [-1, 256, 95, 95]               0\n",
      "      BatchNorm2d-24          [-1, 256, 95, 95]             512\n",
      "             ReLU-25          [-1, 256, 95, 95]               0\n",
      "           Conv2d-26          [-1, 256, 95, 95]           2,304\n",
      "           Conv2d-27          [-1, 256, 95, 95]          65,536\n",
      "  SeparableConv2d-28          [-1, 256, 95, 95]               0\n",
      "      BatchNorm2d-29          [-1, 256, 95, 95]             512\n",
      "        MaxPool2d-30          [-1, 256, 48, 48]               0\n",
      "           Conv2d-31          [-1, 256, 48, 48]          32,768\n",
      "      BatchNorm2d-32          [-1, 256, 48, 48]             512\n",
      "            Block-33          [-1, 256, 48, 48]               0\n",
      "             ReLU-34          [-1, 256, 48, 48]               0\n",
      "           Conv2d-35          [-1, 256, 48, 48]           2,304\n",
      "           Conv2d-36          [-1, 728, 48, 48]         186,368\n",
      "  SeparableConv2d-37          [-1, 728, 48, 48]               0\n",
      "      BatchNorm2d-38          [-1, 728, 48, 48]           1,456\n",
      "             ReLU-39          [-1, 728, 48, 48]               0\n",
      "           Conv2d-40          [-1, 728, 48, 48]           6,552\n",
      "           Conv2d-41          [-1, 728, 48, 48]         529,984\n",
      "  SeparableConv2d-42          [-1, 728, 48, 48]               0\n",
      "      BatchNorm2d-43          [-1, 728, 48, 48]           1,456\n",
      "        MaxPool2d-44          [-1, 728, 24, 24]               0\n",
      "           Conv2d-45          [-1, 728, 24, 24]         186,368\n",
      "      BatchNorm2d-46          [-1, 728, 24, 24]           1,456\n",
      "            Block-47          [-1, 728, 24, 24]               0\n",
      "             ReLU-48          [-1, 728, 24, 24]               0\n",
      "           Conv2d-49          [-1, 728, 24, 24]           6,552\n",
      "           Conv2d-50          [-1, 728, 24, 24]         529,984\n",
      "  SeparableConv2d-51          [-1, 728, 24, 24]               0\n",
      "      BatchNorm2d-52          [-1, 728, 24, 24]           1,456\n",
      "             ReLU-53          [-1, 728, 24, 24]               0\n",
      "           Conv2d-54          [-1, 728, 24, 24]           6,552\n",
      "           Conv2d-55          [-1, 728, 24, 24]         529,984\n",
      "  SeparableConv2d-56          [-1, 728, 24, 24]               0\n",
      "      BatchNorm2d-57          [-1, 728, 24, 24]           1,456\n",
      "             ReLU-58          [-1, 728, 24, 24]               0\n",
      "           Conv2d-59          [-1, 728, 24, 24]           6,552\n",
      "           Conv2d-60          [-1, 728, 24, 24]         529,984\n",
      "  SeparableConv2d-61          [-1, 728, 24, 24]               0\n",
      "      BatchNorm2d-62          [-1, 728, 24, 24]           1,456\n",
      "            Block-63          [-1, 728, 24, 24]               0\n",
      "             ReLU-64          [-1, 728, 24, 24]               0\n",
      "           Conv2d-65          [-1, 728, 24, 24]           6,552\n",
      "           Conv2d-66          [-1, 728, 24, 24]         529,984\n",
      "  SeparableConv2d-67          [-1, 728, 24, 24]               0\n",
      "      BatchNorm2d-68          [-1, 728, 24, 24]           1,456\n",
      "             ReLU-69          [-1, 728, 24, 24]               0\n",
      "           Conv2d-70          [-1, 728, 24, 24]           6,552\n",
      "           Conv2d-71          [-1, 728, 24, 24]         529,984\n",
      "  SeparableConv2d-72          [-1, 728, 24, 24]               0\n",
      "      BatchNorm2d-73          [-1, 728, 24, 24]           1,456\n",
      "             ReLU-74          [-1, 728, 24, 24]               0\n",
      "           Conv2d-75          [-1, 728, 24, 24]           6,552\n",
      "           Conv2d-76          [-1, 728, 24, 24]         529,984\n",
      "  SeparableConv2d-77          [-1, 728, 24, 24]               0\n",
      "      BatchNorm2d-78          [-1, 728, 24, 24]           1,456\n",
      "            Block-79          [-1, 728, 24, 24]               0\n",
      "             ReLU-80          [-1, 728, 24, 24]               0\n",
      "           Conv2d-81          [-1, 728, 24, 24]           6,552\n",
      "           Conv2d-82          [-1, 728, 24, 24]         529,984\n",
      "  SeparableConv2d-83          [-1, 728, 24, 24]               0\n",
      "      BatchNorm2d-84          [-1, 728, 24, 24]           1,456\n",
      "             ReLU-85          [-1, 728, 24, 24]               0\n",
      "           Conv2d-86          [-1, 728, 24, 24]           6,552\n",
      "           Conv2d-87          [-1, 728, 24, 24]         529,984\n",
      "  SeparableConv2d-88          [-1, 728, 24, 24]               0\n",
      "      BatchNorm2d-89          [-1, 728, 24, 24]           1,456\n",
      "             ReLU-90          [-1, 728, 24, 24]               0\n",
      "           Conv2d-91          [-1, 728, 24, 24]           6,552\n",
      "           Conv2d-92          [-1, 728, 24, 24]         529,984\n",
      "  SeparableConv2d-93          [-1, 728, 24, 24]               0\n",
      "      BatchNorm2d-94          [-1, 728, 24, 24]           1,456\n",
      "            Block-95          [-1, 728, 24, 24]               0\n",
      "             ReLU-96          [-1, 728, 24, 24]               0\n",
      "           Conv2d-97          [-1, 728, 24, 24]           6,552\n",
      "           Conv2d-98          [-1, 728, 24, 24]         529,984\n",
      "  SeparableConv2d-99          [-1, 728, 24, 24]               0\n",
      "     BatchNorm2d-100          [-1, 728, 24, 24]           1,456\n",
      "            ReLU-101          [-1, 728, 24, 24]               0\n",
      "          Conv2d-102          [-1, 728, 24, 24]           6,552\n",
      "          Conv2d-103          [-1, 728, 24, 24]         529,984\n",
      " SeparableConv2d-104          [-1, 728, 24, 24]               0\n",
      "     BatchNorm2d-105          [-1, 728, 24, 24]           1,456\n",
      "            ReLU-106          [-1, 728, 24, 24]               0\n",
      "          Conv2d-107          [-1, 728, 24, 24]           6,552\n",
      "          Conv2d-108          [-1, 728, 24, 24]         529,984\n",
      " SeparableConv2d-109          [-1, 728, 24, 24]               0\n",
      "     BatchNorm2d-110          [-1, 728, 24, 24]           1,456\n",
      "           Block-111          [-1, 728, 24, 24]               0\n",
      "            ReLU-112          [-1, 728, 24, 24]               0\n",
      "          Conv2d-113          [-1, 728, 24, 24]           6,552\n",
      "          Conv2d-114          [-1, 728, 24, 24]         529,984\n",
      " SeparableConv2d-115          [-1, 728, 24, 24]               0\n",
      "     BatchNorm2d-116          [-1, 728, 24, 24]           1,456\n",
      "            ReLU-117          [-1, 728, 24, 24]               0\n",
      "          Conv2d-118          [-1, 728, 24, 24]           6,552\n",
      "          Conv2d-119          [-1, 728, 24, 24]         529,984\n",
      " SeparableConv2d-120          [-1, 728, 24, 24]               0\n",
      "     BatchNorm2d-121          [-1, 728, 24, 24]           1,456\n",
      "            ReLU-122          [-1, 728, 24, 24]               0\n",
      "          Conv2d-123          [-1, 728, 24, 24]           6,552\n",
      "          Conv2d-124          [-1, 728, 24, 24]         529,984\n",
      " SeparableConv2d-125          [-1, 728, 24, 24]               0\n",
      "     BatchNorm2d-126          [-1, 728, 24, 24]           1,456\n",
      "           Block-127          [-1, 728, 24, 24]               0\n",
      "            ReLU-128          [-1, 728, 24, 24]               0\n",
      "          Conv2d-129          [-1, 728, 24, 24]           6,552\n",
      "          Conv2d-130          [-1, 728, 24, 24]         529,984\n",
      " SeparableConv2d-131          [-1, 728, 24, 24]               0\n",
      "     BatchNorm2d-132          [-1, 728, 24, 24]           1,456\n",
      "            ReLU-133          [-1, 728, 24, 24]               0\n",
      "          Conv2d-134          [-1, 728, 24, 24]           6,552\n",
      "          Conv2d-135          [-1, 728, 24, 24]         529,984\n",
      " SeparableConv2d-136          [-1, 728, 24, 24]               0\n",
      "     BatchNorm2d-137          [-1, 728, 24, 24]           1,456\n",
      "            ReLU-138          [-1, 728, 24, 24]               0\n",
      "          Conv2d-139          [-1, 728, 24, 24]           6,552\n",
      "          Conv2d-140          [-1, 728, 24, 24]         529,984\n",
      " SeparableConv2d-141          [-1, 728, 24, 24]               0\n",
      "     BatchNorm2d-142          [-1, 728, 24, 24]           1,456\n",
      "           Block-143          [-1, 728, 24, 24]               0\n",
      "            ReLU-144          [-1, 728, 24, 24]               0\n",
      "          Conv2d-145          [-1, 728, 24, 24]           6,552\n",
      "          Conv2d-146          [-1, 728, 24, 24]         529,984\n",
      " SeparableConv2d-147          [-1, 728, 24, 24]               0\n",
      "     BatchNorm2d-148          [-1, 728, 24, 24]           1,456\n",
      "            ReLU-149          [-1, 728, 24, 24]               0\n",
      "          Conv2d-150          [-1, 728, 24, 24]           6,552\n",
      "          Conv2d-151          [-1, 728, 24, 24]         529,984\n",
      " SeparableConv2d-152          [-1, 728, 24, 24]               0\n",
      "     BatchNorm2d-153          [-1, 728, 24, 24]           1,456\n",
      "            ReLU-154          [-1, 728, 24, 24]               0\n",
      "          Conv2d-155          [-1, 728, 24, 24]           6,552\n",
      "          Conv2d-156          [-1, 728, 24, 24]         529,984\n",
      " SeparableConv2d-157          [-1, 728, 24, 24]               0\n",
      "     BatchNorm2d-158          [-1, 728, 24, 24]           1,456\n",
      "           Block-159          [-1, 728, 24, 24]               0\n",
      "            ReLU-160          [-1, 728, 24, 24]               0\n",
      "          Conv2d-161          [-1, 728, 24, 24]           6,552\n",
      "          Conv2d-162          [-1, 728, 24, 24]         529,984\n",
      " SeparableConv2d-163          [-1, 728, 24, 24]               0\n",
      "     BatchNorm2d-164          [-1, 728, 24, 24]           1,456\n",
      "            ReLU-165          [-1, 728, 24, 24]               0\n",
      "          Conv2d-166          [-1, 728, 24, 24]           6,552\n",
      "          Conv2d-167          [-1, 728, 24, 24]         529,984\n",
      " SeparableConv2d-168          [-1, 728, 24, 24]               0\n",
      "     BatchNorm2d-169          [-1, 728, 24, 24]           1,456\n",
      "            ReLU-170          [-1, 728, 24, 24]               0\n",
      "          Conv2d-171          [-1, 728, 24, 24]           6,552\n",
      "          Conv2d-172          [-1, 728, 24, 24]         529,984\n",
      " SeparableConv2d-173          [-1, 728, 24, 24]               0\n",
      "     BatchNorm2d-174          [-1, 728, 24, 24]           1,456\n",
      "           Block-175          [-1, 728, 24, 24]               0\n",
      "            ReLU-176          [-1, 728, 24, 24]               0\n",
      "          Conv2d-177          [-1, 728, 24, 24]           6,552\n",
      "          Conv2d-178          [-1, 728, 24, 24]         529,984\n",
      " SeparableConv2d-179          [-1, 728, 24, 24]               0\n",
      "     BatchNorm2d-180          [-1, 728, 24, 24]           1,456\n",
      "            ReLU-181          [-1, 728, 24, 24]               0\n",
      "          Conv2d-182          [-1, 728, 24, 24]           6,552\n",
      "          Conv2d-183         [-1, 1024, 24, 24]         745,472\n",
      " SeparableConv2d-184         [-1, 1024, 24, 24]               0\n",
      "     BatchNorm2d-185         [-1, 1024, 24, 24]           2,048\n",
      "       MaxPool2d-186         [-1, 1024, 12, 12]               0\n",
      "          Conv2d-187         [-1, 1024, 12, 12]         745,472\n",
      "     BatchNorm2d-188         [-1, 1024, 12, 12]           2,048\n",
      "           Block-189         [-1, 1024, 12, 12]               0\n",
      "          Conv2d-190         [-1, 1024, 12, 12]           9,216\n",
      "          Conv2d-191         [-1, 1536, 12, 12]       1,572,864\n",
      " SeparableConv2d-192         [-1, 1536, 12, 12]               0\n",
      "     BatchNorm2d-193         [-1, 1536, 12, 12]           3,072\n",
      "            ReLU-194         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-195         [-1, 1536, 12, 12]          13,824\n",
      "          Conv2d-196         [-1, 2048, 12, 12]       3,145,728\n",
      " SeparableConv2d-197         [-1, 2048, 12, 12]               0\n",
      "     BatchNorm2d-198         [-1, 2048, 12, 12]           4,096\n",
      "            ReLU-199         [-1, 2048, 12, 12]               0\n",
      "AdaptiveAvgPool2d-200           [-1, 2048, 1, 1]               0\n",
      "         Flatten-201                 [-1, 2048]               0\n",
      "SelectAdaptivePool2d-202                 [-1, 2048]               0\n",
      "          Linear-203                    [-1, 4]           8,196\n",
      "================================================================\n",
      "Total params: 20,815,148\n",
      "Trainable params: 20,815,148\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.69\n",
      "Forward/backward pass size (MB): 1180.13\n",
      "Params size (MB): 79.40\n",
      "Estimated Total Size (MB): 1261.22\n",
      "----------------------------------------------------------------\n",
      "model : xception_RockModel\n",
      "no valid counterparts augmentation selected\n",
      "Epoch 1/10\n",
      "----------\n",
      "Epoch: 1     train index of 5 minibatch: 1      time used: 65.87828159332275\n",
      "minibatch AVG loss: 1.3782276391983033\n",
      "\n",
      "Epoch: 1  train \n",
      "Loss: 1.3782  Acc: 30.0000\n",
      "granite-blackswan precision: 26.3158  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 6.6667\n",
      "granite-blackswan FPR: 93.3333  NPV: 100.0000\n",
      "granite-blackswan TP: 5.0\n",
      "granite-blackswan TN: 1.0\n",
      "granite-blackswan FP: 14.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 75.0000\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 15.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 5.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 20.0000\n",
      "quartzite-oceanblue sensitivity: 20.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 78.9474\n",
      "quartzite-oceanblue TP: 1.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 4.0\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-patagonia TP: 0.0\n",
      "quartzite-patagonia TN: 15.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 5.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 1  val \n",
      "Loss: 1.3257  Acc: 50.0000\n",
      "granite-blackswan precision: 33.3333  recall: 66.6667\n",
      "granite-blackswan sensitivity: 66.6667  specificity: 55.5556\n",
      "granite-blackswan FPR: 44.4444  NPV: 83.3333\n",
      "granite-blackswan TP: 2.0\n",
      "granite-blackswan TN: 5.0\n",
      "granite-blackswan FP: 4.0\n",
      "granite-blackswan FN: 1.0\n",
      "marble-shadow precision: 100.0000  recall: 33.3333\n",
      "marble-shadow sensitivity: 33.3333  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 81.8182\n",
      "marble-shadow TP: 1.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 2.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-oceanblue TP: 3.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 0.0\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 77.7778\n",
      "quartzite-patagonia FPR: 22.2222  NPV: 70.0000\n",
      "quartzite-patagonia TP: 0.0\n",
      "quartzite-patagonia TN: 7.0\n",
      "quartzite-patagonia FP: 2.0\n",
      "quartzite-patagonia FN: 3.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Epoch: 2     train index of 5 minibatch: 1      time used: 50.482731342315674\n",
      "minibatch AVG loss: 1.3739171028137207\n",
      "\n",
      "Epoch: 2  train \n",
      "Loss: 1.3739  Acc: 35.0000\n",
      "granite-blackswan precision: 25.0000  recall: 80.0000\n",
      "granite-blackswan sensitivity: 80.0000  specificity: 20.0000\n",
      "granite-blackswan FPR: 80.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 4.0\n",
      "granite-blackswan TN: 3.0\n",
      "granite-blackswan FP: 12.0\n",
      "granite-blackswan FN: 1.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 75.0000\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 15.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 5.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 40.0000\n",
      "quartzite-oceanblue sensitivity: 40.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 83.3333\n",
      "quartzite-oceanblue TP: 2.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 50.0000  recall: 20.0000\n",
      "quartzite-patagonia sensitivity: 20.0000  specificity: 93.3333\n",
      "quartzite-patagonia FPR: 6.6667  NPV: 77.7778\n",
      "quartzite-patagonia TP: 1.0\n",
      "quartzite-patagonia TN: 14.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 4.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 2  val \n",
      "Loss: 1.3567  Acc: 33.3333\n",
      "granite-blackswan precision: 33.3333  recall: 66.6667\n",
      "granite-blackswan sensitivity: 66.6667  specificity: 55.5556\n",
      "granite-blackswan FPR: 44.4444  NPV: 83.3333\n",
      "granite-blackswan TP: 2.0\n",
      "granite-blackswan TN: 5.0\n",
      "granite-blackswan FP: 4.0\n",
      "granite-blackswan FN: 1.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 88.8889\n",
      "marble-shadow FPR: 11.1111  NPV: 72.7273\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 8.0\n",
      "marble-shadow FP: 1.0\n",
      "marble-shadow FN: 3.0\n",
      "quartzite-oceanblue precision: 66.6667  recall: 66.6667\n",
      "quartzite-oceanblue sensitivity: 66.6667  specificity: 88.8889\n",
      "quartzite-oceanblue FPR: 11.1111  NPV: 88.8889\n",
      "quartzite-oceanblue TP: 2.0\n",
      "quartzite-oceanblue TN: 8.0\n",
      "quartzite-oceanblue FP: 1.0\n",
      "quartzite-oceanblue FN: 1.0\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 77.7778\n",
      "quartzite-patagonia FPR: 22.2222  NPV: 70.0000\n",
      "quartzite-patagonia TP: 0.0\n",
      "quartzite-patagonia TN: 7.0\n",
      "quartzite-patagonia FP: 2.0\n",
      "quartzite-patagonia FN: 3.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Epoch: 3     train index of 5 minibatch: 1      time used: 48.17862391471863\n",
      "minibatch AVG loss: 1.3574480056762694\n",
      "\n",
      "Epoch: 3  train \n",
      "Loss: 1.3574  Acc: 40.0000\n",
      "granite-blackswan precision: 31.2500  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 26.6667\n",
      "granite-blackswan FPR: 73.3333  NPV: 100.0000\n",
      "granite-blackswan TP: 5.0\n",
      "granite-blackswan TN: 4.0\n",
      "granite-blackswan FP: 11.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 75.0000\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 15.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 5.0\n",
      "quartzite-oceanblue precision: 66.6667  recall: 40.0000\n",
      "quartzite-oceanblue sensitivity: 40.0000  specificity: 93.3333\n",
      "quartzite-oceanblue FPR: 6.6667  NPV: 82.3529\n",
      "quartzite-oceanblue TP: 2.0\n",
      "quartzite-oceanblue TN: 14.0\n",
      "quartzite-oceanblue FP: 1.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 20.0000\n",
      "quartzite-patagonia sensitivity: 20.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 78.9474\n",
      "quartzite-patagonia TP: 1.0\n",
      "quartzite-patagonia TN: 15.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 4.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 3  val \n",
      "Loss: 1.3675  Acc: 25.0000\n",
      "granite-blackswan precision: 28.5714  recall: 66.6667\n",
      "granite-blackswan sensitivity: 66.6667  specificity: 44.4444\n",
      "granite-blackswan FPR: 55.5556  NPV: 80.0000\n",
      "granite-blackswan TP: 2.0\n",
      "granite-blackswan TN: 4.0\n",
      "granite-blackswan FP: 5.0\n",
      "granite-blackswan FN: 1.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 75.0000\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 3.0\n",
      "quartzite-oceanblue precision: 25.0000  recall: 33.3333\n",
      "quartzite-oceanblue sensitivity: 33.3333  specificity: 66.6667\n",
      "quartzite-oceanblue FPR: 33.3333  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 1.0\n",
      "quartzite-oceanblue TN: 6.0\n",
      "quartzite-oceanblue FP: 3.0\n",
      "quartzite-oceanblue FN: 2.0\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 88.8889\n",
      "quartzite-patagonia FPR: 11.1111  NPV: 72.7273\n",
      "quartzite-patagonia TP: 0.0\n",
      "quartzite-patagonia TN: 8.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 3.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Epoch: 4     train index of 5 minibatch: 1      time used: 60.72904086112976\n",
      "minibatch AVG loss: 1.3652529001235962\n",
      "\n",
      "Epoch: 4  train \n",
      "Loss: 1.3653  Acc: 35.0000\n",
      "granite-blackswan precision: 25.0000  recall: 80.0000\n",
      "granite-blackswan sensitivity: 80.0000  specificity: 20.0000\n",
      "granite-blackswan FPR: 80.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 4.0\n",
      "granite-blackswan TN: 3.0\n",
      "granite-blackswan FP: 12.0\n",
      "granite-blackswan FN: 1.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 75.0000\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 15.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 5.0\n",
      "quartzite-oceanblue precision: 66.6667  recall: 40.0000\n",
      "quartzite-oceanblue sensitivity: 40.0000  specificity: 93.3333\n",
      "quartzite-oceanblue FPR: 6.6667  NPV: 82.3529\n",
      "quartzite-oceanblue TP: 2.0\n",
      "quartzite-oceanblue TN: 14.0\n",
      "quartzite-oceanblue FP: 1.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 20.0000\n",
      "quartzite-patagonia sensitivity: 20.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 78.9474\n",
      "quartzite-patagonia TP: 1.0\n",
      "quartzite-patagonia TN: 15.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 4.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 4  val \n",
      "Loss: 1.3649  Acc: 41.6667\n",
      "granite-blackswan precision: 33.3333  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 33.3333\n",
      "granite-blackswan FPR: 66.6667  NPV: 100.0000\n",
      "granite-blackswan TP: 3.0\n",
      "granite-blackswan TN: 3.0\n",
      "granite-blackswan FP: 6.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 75.0000\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 3.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 33.3333\n",
      "quartzite-oceanblue sensitivity: 33.3333  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 81.8182\n",
      "quartzite-oceanblue TP: 1.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 2.0\n",
      "quartzite-patagonia precision: 50.0000  recall: 33.3333\n",
      "quartzite-patagonia sensitivity: 33.3333  specificity: 88.8889\n",
      "quartzite-patagonia FPR: 11.1111  NPV: 80.0000\n",
      "quartzite-patagonia TP: 1.0\n",
      "quartzite-patagonia TN: 8.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 2.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Epoch: 5     train index of 5 minibatch: 1      time used: 52.22638750076294\n",
      "minibatch AVG loss: 1.3714965105056762\n",
      "\n",
      "Epoch: 5  train \n",
      "Loss: 1.3715  Acc: 35.0000\n",
      "granite-blackswan precision: 29.4118  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 20.0000\n",
      "granite-blackswan FPR: 80.0000  NPV: 100.0000\n",
      "granite-blackswan TP: 5.0\n",
      "granite-blackswan TN: 3.0\n",
      "granite-blackswan FP: 12.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 75.0000\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 15.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 5.0\n",
      "quartzite-oceanblue precision: 66.6667  recall: 40.0000\n",
      "quartzite-oceanblue sensitivity: 40.0000  specificity: 93.3333\n",
      "quartzite-oceanblue FPR: 6.6667  NPV: 82.3529\n",
      "quartzite-oceanblue TP: 2.0\n",
      "quartzite-oceanblue TN: 14.0\n",
      "quartzite-oceanblue FP: 1.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-patagonia TP: 0.0\n",
      "quartzite-patagonia TN: 15.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 5.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 5  val \n",
      "Loss: 1.3741  Acc: 33.3333\n",
      "granite-blackswan precision: 33.3333  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 33.3333\n",
      "granite-blackswan FPR: 66.6667  NPV: 100.0000\n",
      "granite-blackswan TP: 3.0\n",
      "granite-blackswan TN: 3.0\n",
      "granite-blackswan FP: 6.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 75.0000\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 3.0\n",
      "quartzite-oceanblue precision: 50.0000  recall: 33.3333\n",
      "quartzite-oceanblue sensitivity: 33.3333  specificity: 88.8889\n",
      "quartzite-oceanblue FPR: 11.1111  NPV: 80.0000\n",
      "quartzite-oceanblue TP: 1.0\n",
      "quartzite-oceanblue TN: 8.0\n",
      "quartzite-oceanblue FP: 1.0\n",
      "quartzite-oceanblue FN: 2.0\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 88.8889\n",
      "quartzite-patagonia FPR: 11.1111  NPV: 72.7273\n",
      "quartzite-patagonia TP: 0.0\n",
      "quartzite-patagonia TN: 8.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 3.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Epoch: 6     train index of 5 minibatch: 1      time used: 51.01682090759277\n",
      "minibatch AVG loss: 1.3384243726730347\n",
      "\n",
      "Epoch: 6  train \n",
      "Loss: 1.3384  Acc: 30.0000\n",
      "granite-blackswan precision: 33.3333  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 33.3333\n",
      "granite-blackswan FPR: 66.6667  NPV: 100.0000\n",
      "granite-blackswan TP: 5.0\n",
      "granite-blackswan TN: 5.0\n",
      "granite-blackswan FP: 10.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 75.0000\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 15.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 5.0\n",
      "quartzite-oceanblue precision: 25.0000  recall: 20.0000\n",
      "quartzite-oceanblue sensitivity: 20.0000  specificity: 80.0000\n",
      "quartzite-oceanblue FPR: 20.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 1.0\n",
      "quartzite-oceanblue TN: 12.0\n",
      "quartzite-oceanblue FP: 3.0\n",
      "quartzite-oceanblue FN: 4.0\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 93.3333\n",
      "quartzite-patagonia FPR: 6.6667  NPV: 73.6842\n",
      "quartzite-patagonia TP: 0.0\n",
      "quartzite-patagonia TN: 14.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 5.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 6  val \n",
      "Loss: 1.3894  Acc: 16.6667\n",
      "granite-blackswan precision: 25.0000  recall: 66.6667\n",
      "granite-blackswan sensitivity: 66.6667  specificity: 33.3333\n",
      "granite-blackswan FPR: 66.6667  NPV: 75.0000\n",
      "granite-blackswan TP: 2.0\n",
      "granite-blackswan TN: 3.0\n",
      "granite-blackswan FP: 6.0\n",
      "granite-blackswan FN: 1.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 75.0000\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 3.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 77.7778\n",
      "quartzite-oceanblue FPR: 22.2222  NPV: 70.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 7.0\n",
      "quartzite-oceanblue FP: 2.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 77.7778\n",
      "quartzite-patagonia FPR: 22.2222  NPV: 70.0000\n",
      "quartzite-patagonia TP: 0.0\n",
      "quartzite-patagonia TN: 7.0\n",
      "quartzite-patagonia FP: 2.0\n",
      "quartzite-patagonia FN: 3.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Epoch: 7     train index of 5 minibatch: 1      time used: 47.940823554992676\n",
      "minibatch AVG loss: 1.3319946765899657\n",
      "\n",
      "Epoch: 7  train \n",
      "Loss: 1.3320  Acc: 50.0000\n",
      "granite-blackswan precision: 35.7143  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 40.0000\n",
      "granite-blackswan FPR: 60.0000  NPV: 100.0000\n",
      "granite-blackswan TP: 5.0\n",
      "granite-blackswan TN: 6.0\n",
      "granite-blackswan FP: 9.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 75.0000\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 15.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 5.0\n",
      "quartzite-oceanblue precision: 80.0000  recall: 80.0000\n",
      "quartzite-oceanblue sensitivity: 80.0000  specificity: 93.3333\n",
      "quartzite-oceanblue FPR: 6.6667  NPV: 93.3333\n",
      "quartzite-oceanblue TP: 4.0\n",
      "quartzite-oceanblue TN: 14.0\n",
      "quartzite-oceanblue FP: 1.0\n",
      "quartzite-oceanblue FN: 1.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 20.0000\n",
      "quartzite-patagonia sensitivity: 20.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 78.9474\n",
      "quartzite-patagonia TP: 1.0\n",
      "quartzite-patagonia TN: 15.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 4.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 7  val \n",
      "Loss: 1.3833  Acc: 16.6667\n",
      "granite-blackswan precision: 22.2222  recall: 66.6667\n",
      "granite-blackswan sensitivity: 66.6667  specificity: 22.2222\n",
      "granite-blackswan FPR: 77.7778  NPV: 66.6667\n",
      "granite-blackswan TP: 2.0\n",
      "granite-blackswan TN: 2.0\n",
      "granite-blackswan FP: 7.0\n",
      "granite-blackswan FN: 1.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 75.0000\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 3.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 77.7778\n",
      "quartzite-oceanblue FPR: 22.2222  NPV: 70.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 7.0\n",
      "quartzite-oceanblue FP: 2.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 88.8889\n",
      "quartzite-patagonia FPR: 11.1111  NPV: 72.7273\n",
      "quartzite-patagonia TP: 0.0\n",
      "quartzite-patagonia TN: 8.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 3.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Epoch: 8     train index of 5 minibatch: 1      time used: 60.64182162284851\n",
      "minibatch AVG loss: 1.3457990169525147\n",
      "\n",
      "Epoch: 8  train \n",
      "Loss: 1.3458  Acc: 40.0000\n",
      "granite-blackswan precision: 33.3333  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 33.3333\n",
      "granite-blackswan FPR: 66.6667  NPV: 100.0000\n",
      "granite-blackswan TP: 5.0\n",
      "granite-blackswan TN: 5.0\n",
      "granite-blackswan FP: 10.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 75.0000\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 15.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 5.0\n",
      "quartzite-oceanblue precision: 66.6667  recall: 40.0000\n",
      "quartzite-oceanblue sensitivity: 40.0000  specificity: 93.3333\n",
      "quartzite-oceanblue FPR: 6.6667  NPV: 82.3529\n",
      "quartzite-oceanblue TP: 2.0\n",
      "quartzite-oceanblue TN: 14.0\n",
      "quartzite-oceanblue FP: 1.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 50.0000  recall: 20.0000\n",
      "quartzite-patagonia sensitivity: 20.0000  specificity: 93.3333\n",
      "quartzite-patagonia FPR: 6.6667  NPV: 77.7778\n",
      "quartzite-patagonia TP: 1.0\n",
      "quartzite-patagonia TN: 14.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 4.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 8  val \n",
      "Loss: 1.3766  Acc: 25.0000\n",
      "granite-blackswan precision: 25.0000  recall: 66.6667\n",
      "granite-blackswan sensitivity: 66.6667  specificity: 33.3333\n",
      "granite-blackswan FPR: 66.6667  NPV: 75.0000\n",
      "granite-blackswan TP: 2.0\n",
      "granite-blackswan TN: 3.0\n",
      "granite-blackswan FP: 6.0\n",
      "granite-blackswan FN: 1.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 75.0000\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 3.0\n",
      "quartzite-oceanblue precision: 33.3333  recall: 33.3333\n",
      "quartzite-oceanblue sensitivity: 33.3333  specificity: 77.7778\n",
      "quartzite-oceanblue FPR: 22.2222  NPV: 77.7778\n",
      "quartzite-oceanblue TP: 1.0\n",
      "quartzite-oceanblue TN: 7.0\n",
      "quartzite-oceanblue FP: 2.0\n",
      "quartzite-oceanblue FN: 2.0\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 88.8889\n",
      "quartzite-patagonia FPR: 11.1111  NPV: 72.7273\n",
      "quartzite-patagonia TP: 0.0\n",
      "quartzite-patagonia TN: 8.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 3.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Epoch: 9     train index of 5 minibatch: 1      time used: 62.91555166244507\n",
      "minibatch AVG loss: 1.345180869102478\n",
      "\n",
      "Epoch: 9  train \n",
      "Loss: 1.3452  Acc: 50.0000\n",
      "granite-blackswan precision: 33.3333  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 33.3333\n",
      "granite-blackswan FPR: 66.6667  NPV: 100.0000\n",
      "granite-blackswan TP: 5.0\n",
      "granite-blackswan TN: 5.0\n",
      "granite-blackswan FP: 10.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 75.0000\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 15.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 5.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 60.0000\n",
      "quartzite-oceanblue sensitivity: 60.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 88.2353\n",
      "quartzite-oceanblue TP: 3.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 2.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 40.0000\n",
      "quartzite-patagonia sensitivity: 40.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 83.3333\n",
      "quartzite-patagonia TP: 2.0\n",
      "quartzite-patagonia TN: 15.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 3.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 9  val \n",
      "Loss: 1.3648  Acc: 25.0000\n",
      "granite-blackswan precision: 25.0000  recall: 66.6667\n",
      "granite-blackswan sensitivity: 66.6667  specificity: 33.3333\n",
      "granite-blackswan FPR: 66.6667  NPV: 75.0000\n",
      "granite-blackswan TP: 2.0\n",
      "granite-blackswan TN: 3.0\n",
      "granite-blackswan FP: 6.0\n",
      "granite-blackswan FN: 1.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 75.0000\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 3.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 77.7778\n",
      "quartzite-oceanblue FPR: 22.2222  NPV: 70.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 7.0\n",
      "quartzite-oceanblue FP: 2.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 50.0000  recall: 33.3333\n",
      "quartzite-patagonia sensitivity: 33.3333  specificity: 88.8889\n",
      "quartzite-patagonia FPR: 11.1111  NPV: 80.0000\n",
      "quartzite-patagonia TP: 1.0\n",
      "quartzite-patagonia TN: 8.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 2.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Epoch: 10     train index of 5 minibatch: 1      time used: 62.77778172492981\n",
      "minibatch AVG loss: 1.3480094432830811\n",
      "\n",
      "Epoch: 10  train \n",
      "Loss: 1.3480  Acc: 40.0000\n",
      "granite-blackswan precision: 28.5714  recall: 80.0000\n",
      "granite-blackswan sensitivity: 80.0000  specificity: 33.3333\n",
      "granite-blackswan FPR: 66.6667  NPV: 83.3333\n",
      "granite-blackswan TP: 4.0\n",
      "granite-blackswan TN: 5.0\n",
      "granite-blackswan FP: 10.0\n",
      "granite-blackswan FN: 1.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 75.0000\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 15.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 5.0\n",
      "quartzite-oceanblue precision: 50.0000  recall: 20.0000\n",
      "quartzite-oceanblue sensitivity: 20.0000  specificity: 93.3333\n",
      "quartzite-oceanblue FPR: 6.6667  NPV: 77.7778\n",
      "quartzite-oceanblue TP: 1.0\n",
      "quartzite-oceanblue TN: 14.0\n",
      "quartzite-oceanblue FP: 1.0\n",
      "quartzite-oceanblue FN: 4.0\n",
      "quartzite-patagonia precision: 75.0000  recall: 60.0000\n",
      "quartzite-patagonia sensitivity: 60.0000  specificity: 93.3333\n",
      "quartzite-patagonia FPR: 6.6667  NPV: 87.5000\n",
      "quartzite-patagonia TP: 3.0\n",
      "quartzite-patagonia TN: 14.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 2.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 10  val \n",
      "Loss: 1.3589  Acc: 25.0000\n",
      "granite-blackswan precision: 22.2222  recall: 66.6667\n",
      "granite-blackswan sensitivity: 66.6667  specificity: 22.2222\n",
      "granite-blackswan FPR: 77.7778  NPV: 66.6667\n",
      "granite-blackswan TP: 2.0\n",
      "granite-blackswan TN: 2.0\n",
      "granite-blackswan FP: 7.0\n",
      "granite-blackswan FN: 1.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 75.0000\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 3.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 88.8889\n",
      "quartzite-oceanblue FPR: 11.1111  NPV: 72.7273\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 8.0\n",
      "quartzite-oceanblue FP: 1.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 50.0000  recall: 33.3333\n",
      "quartzite-patagonia sensitivity: 33.3333  specificity: 88.8889\n",
      "quartzite-patagonia FPR: 11.1111  NPV: 80.0000\n",
      "quartzite-patagonia TP: 1.0\n",
      "quartzite-patagonia TN: 8.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 2.0\n",
      "\n",
      "\n",
      "\n",
      "Training complete in 11m 57s\n",
      "Best epoch idx:  1\n",
      "Best epoch train Acc: 30.000000\n",
      "Best epoch val Acc: 50.000000\n",
      "granite-blackswan precision: 33.3333  recall: 66.6667\n",
      "granite-blackswan sensitivity: 66.6667  specificity: 55.5556\n",
      "granite-blackswan FPR: 44.4444  NPV: 83.3333\n",
      "marble-shadow precision: 100.0000  recall: 33.3333\n",
      "marble-shadow sensitivity: 33.3333  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 81.8182\n",
      "quartzite-oceanblue precision: 100.0000  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 77.7778\n",
      "quartzite-patagonia FPR: 22.2222  NPV: 70.0000\n",
      "model trained by GPU (idx:0) has been saved at  saved_models\\CLS_xception_RockModel.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\timm\\models\\_factory.py:117: UserWarning: Mapping deprecated model name xception to current legacy_xception.\n",
      "  model = create_fn(\n"
     ]
    }
   ],
   "source": [
    "!python Train.py --model_idx xception_RockModel --edge_size 384 --data_augmentation_mode 2 --batch_size 4 --lr 0.00001 --lrf 0.05 --enable_tensorboard --check_minibatch 5 --dataroot sample_datasets/warwick_CLS --model_path saved_models --draw_root runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xception test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names: ['granite-blackswan', 'marble-shadow', 'quartzite-oceanblue', 'quartzite-patagonia']\n",
      "['legacy_xception',\n",
      " 'xception41',\n",
      " 'xception41p',\n",
      " 'xception65',\n",
      " 'xception65p',\n",
      " 'xception71']\n",
      "test model outputï¼ tensor([[ 0.0286,  0.0564,  0.1051, -0.0616]], grad_fn=<AddmmBackward0>)\n",
      "model is ready now!\n",
      "model loaded\n",
      "model : xception_RockModel\n",
      "*********************************setting*************************************\n",
      "Namespace(model_idx='xception_RockModel', MIL_Stripe=False, drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.0, cls_token_off=False, pos_embedding_off=False, att_module='SimAM', gpu_idx=0, dataroot='sample_datasets/warwick_CLS', model_path='saved_models', draw_root='runs', paint=True, enable_notify=False, enable_tensorboard=False, enable_attention_check=True, enable_visualize_check=False, data_augmentation_mode=2, num_classes=0, edge_size=384, batch_size=1, check_minibatch=5)\n",
      "Epoch: Test\n",
      "----------\n",
      "Epoch: test     test index of 5 minibatch: 1      time used: 8.968117952346802\n",
      "minibatch AVG loss: 1.3368658065795898\n",
      "ERRO in model_idx\n",
      "model: xception_RockModel  with edge_size 384 is not supported yet\n",
      "Epoch: test     test index of 5 minibatch: 2      time used: 3.1799824237823486\n",
      "minibatch AVG loss: 1.282700252532959\n",
      "ERRO in model_idx\n",
      "model: xception_RockModel  with edge_size 384 is not supported yet\n",
      "\n",
      "Epoch:  test \n",
      "Loss: 1.3150  Acc: 50.0000\n",
      "granite-blackswan precision: 40.0000  recall: 66.6667\n",
      "granite-blackswan sensitivity: 66.6667  specificity: 66.6667\n",
      "granite-blackswan FPR: 33.3333  NPV: 85.7143\n",
      "granite-blackswan TP: 2.0\n",
      "granite-blackswan TN: 6.0\n",
      "granite-blackswan FP: 3.0\n",
      "granite-blackswan FN: 1.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 75.0000\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 3.0\n",
      "quartzite-oceanblue precision: 60.0000  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 77.7778\n",
      "quartzite-oceanblue FPR: 22.2222  NPV: 100.0000\n",
      "quartzite-oceanblue TP: 3.0\n",
      "quartzite-oceanblue TN: 7.0\n",
      "quartzite-oceanblue FP: 2.0\n",
      "quartzite-oceanblue FN: 0.0\n",
      "quartzite-patagonia precision: 50.0000  recall: 33.3333\n",
      "quartzite-patagonia sensitivity: 33.3333  specificity: 88.8889\n",
      "quartzite-patagonia FPR: 11.1111  NPV: 80.0000\n",
      "quartzite-patagonia TP: 1.0\n",
      "quartzite-patagonia TN: 8.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 2.0\n",
      "\n",
      "\n",
      "Testing complete in 0m 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\timm\\models\\_factory.py:117: UserWarning: Mapping deprecated model name xception to current legacy_xception.\n",
      "  model = create_fn(\n",
      "c:\\Users\\usuariolocal\\OneDrive\\Documentos\\Douglas\\Mestrado\\3 - Curso\\Meu projeto\\si_vit_ornamental_rocks\\utils\\visual_usage.py:35: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.pause(0.001)  # pause a bit so that plots are updated\n",
      "c:\\Users\\usuariolocal\\OneDrive\\Documentos\\Douglas\\Mestrado\\3 - Curso\\Meu projeto\\si_vit_ornamental_rocks\\utils\\visual_usage.py:302: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.pause(0.001)  # pause a bit so that plots are updated\n",
      "c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "!python Test.py --model_idx xception_RockModel --edge_size 384 --data_augmentation_mode 2 --enable_attention_check --check_minibatch 5 --dataroot sample_datasets/warwick_CLS --model_path saved_models --draw_root runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50 network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names: ['granite-blackswan', 'marble-shadow', 'quartzite-oceanblue', 'quartzite-patagonia']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*********************************setting*************************************\n",
      "Namespace(model_idx='ResNet50_RockModel', drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.0, cls_token_off=False, pos_embedding_off=False, att_module='SimAM', backbone_PT_off=False, gpu_idx=-1, dataroot='sample_datasets/warwick_CLS', model_path='saved_models', draw_root='runs', paint=True, enable_notify=False, enable_tensorboard=True, enable_attention_check=False, enable_visualize_check=False, enable_sam=False, augmentation_name=None, data_augmentation_mode=2, linearprobing=False, Pre_Trained_model_path=None, num_classes=0, edge_size=384, num_workers=2, batch_size=4, check_minibatch=5, num_epochs=10, intake_epochs=0, lr=1e-05, lrf=0.05, opt_name='Adam')\n",
      "we dont have more GPU idx here, try to use gpu_idx=0\n",
      "test model outputï¼ tensor([[ 0.1753,  0.2951, -0.0209, -0.0013]], grad_fn=<AddmmBackward0>)\n",
      "model is ready now!\n",
      "GPU: 0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 192, 192]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 192, 192]             128\n",
      "              ReLU-3         [-1, 64, 192, 192]               0\n",
      "         MaxPool2d-4           [-1, 64, 96, 96]               0\n",
      "            Conv2d-5           [-1, 64, 96, 96]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 96, 96]             128\n",
      "              ReLU-7           [-1, 64, 96, 96]               0\n",
      "            Conv2d-8           [-1, 64, 96, 96]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 96, 96]             128\n",
      "             ReLU-10           [-1, 64, 96, 96]               0\n",
      "           Conv2d-11          [-1, 256, 96, 96]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 96, 96]             512\n",
      "           Conv2d-13          [-1, 256, 96, 96]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 96, 96]             512\n",
      "             ReLU-15          [-1, 256, 96, 96]               0\n",
      "       Bottleneck-16          [-1, 256, 96, 96]               0\n",
      "           Conv2d-17           [-1, 64, 96, 96]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 96, 96]             128\n",
      "             ReLU-19           [-1, 64, 96, 96]               0\n",
      "           Conv2d-20           [-1, 64, 96, 96]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 96, 96]             128\n",
      "             ReLU-22           [-1, 64, 96, 96]               0\n",
      "           Conv2d-23          [-1, 256, 96, 96]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 96, 96]             512\n",
      "             ReLU-25          [-1, 256, 96, 96]               0\n",
      "       Bottleneck-26          [-1, 256, 96, 96]               0\n",
      "           Conv2d-27           [-1, 64, 96, 96]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 96, 96]             128\n",
      "             ReLU-29           [-1, 64, 96, 96]               0\n",
      "           Conv2d-30           [-1, 64, 96, 96]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 96, 96]             128\n",
      "             ReLU-32           [-1, 64, 96, 96]               0\n",
      "           Conv2d-33          [-1, 256, 96, 96]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 96, 96]             512\n",
      "             ReLU-35          [-1, 256, 96, 96]               0\n",
      "       Bottleneck-36          [-1, 256, 96, 96]               0\n",
      "           Conv2d-37          [-1, 128, 96, 96]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 96, 96]             256\n",
      "             ReLU-39          [-1, 128, 96, 96]               0\n",
      "           Conv2d-40          [-1, 128, 48, 48]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 48, 48]             256\n",
      "             ReLU-42          [-1, 128, 48, 48]               0\n",
      "           Conv2d-43          [-1, 512, 48, 48]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 48, 48]           1,024\n",
      "           Conv2d-45          [-1, 512, 48, 48]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 48, 48]           1,024\n",
      "             ReLU-47          [-1, 512, 48, 48]               0\n",
      "       Bottleneck-48          [-1, 512, 48, 48]               0\n",
      "           Conv2d-49          [-1, 128, 48, 48]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 48, 48]             256\n",
      "             ReLU-51          [-1, 128, 48, 48]               0\n",
      "           Conv2d-52          [-1, 128, 48, 48]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 48, 48]             256\n",
      "             ReLU-54          [-1, 128, 48, 48]               0\n",
      "           Conv2d-55          [-1, 512, 48, 48]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 48, 48]           1,024\n",
      "             ReLU-57          [-1, 512, 48, 48]               0\n",
      "       Bottleneck-58          [-1, 512, 48, 48]               0\n",
      "           Conv2d-59          [-1, 128, 48, 48]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 48, 48]             256\n",
      "             ReLU-61          [-1, 128, 48, 48]               0\n",
      "           Conv2d-62          [-1, 128, 48, 48]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 48, 48]             256\n",
      "             ReLU-64          [-1, 128, 48, 48]               0\n",
      "           Conv2d-65          [-1, 512, 48, 48]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 48, 48]           1,024\n",
      "             ReLU-67          [-1, 512, 48, 48]               0\n",
      "       Bottleneck-68          [-1, 512, 48, 48]               0\n",
      "           Conv2d-69          [-1, 128, 48, 48]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 48, 48]             256\n",
      "             ReLU-71          [-1, 128, 48, 48]               0\n",
      "           Conv2d-72          [-1, 128, 48, 48]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 48, 48]             256\n",
      "             ReLU-74          [-1, 128, 48, 48]               0\n",
      "           Conv2d-75          [-1, 512, 48, 48]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 48, 48]           1,024\n",
      "             ReLU-77          [-1, 512, 48, 48]               0\n",
      "       Bottleneck-78          [-1, 512, 48, 48]               0\n",
      "           Conv2d-79          [-1, 256, 48, 48]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 48, 48]             512\n",
      "             ReLU-81          [-1, 256, 48, 48]               0\n",
      "           Conv2d-82          [-1, 256, 24, 24]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 24, 24]             512\n",
      "             ReLU-84          [-1, 256, 24, 24]               0\n",
      "           Conv2d-85         [-1, 1024, 24, 24]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 24, 24]           2,048\n",
      "           Conv2d-87         [-1, 1024, 24, 24]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 24, 24]           2,048\n",
      "             ReLU-89         [-1, 1024, 24, 24]               0\n",
      "       Bottleneck-90         [-1, 1024, 24, 24]               0\n",
      "           Conv2d-91          [-1, 256, 24, 24]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 24, 24]             512\n",
      "             ReLU-93          [-1, 256, 24, 24]               0\n",
      "           Conv2d-94          [-1, 256, 24, 24]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 24, 24]             512\n",
      "             ReLU-96          [-1, 256, 24, 24]               0\n",
      "           Conv2d-97         [-1, 1024, 24, 24]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 24, 24]           2,048\n",
      "             ReLU-99         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-100         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-101          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 24, 24]             512\n",
      "            ReLU-103          [-1, 256, 24, 24]               0\n",
      "          Conv2d-104          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 24, 24]             512\n",
      "            ReLU-106          [-1, 256, 24, 24]               0\n",
      "          Conv2d-107         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-109         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-110         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-111          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 24, 24]             512\n",
      "            ReLU-113          [-1, 256, 24, 24]               0\n",
      "          Conv2d-114          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 24, 24]             512\n",
      "            ReLU-116          [-1, 256, 24, 24]               0\n",
      "          Conv2d-117         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-119         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-120         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-121          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 24, 24]             512\n",
      "            ReLU-123          [-1, 256, 24, 24]               0\n",
      "          Conv2d-124          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 24, 24]             512\n",
      "            ReLU-126          [-1, 256, 24, 24]               0\n",
      "          Conv2d-127         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-129         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-130         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-131          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 24, 24]             512\n",
      "            ReLU-133          [-1, 256, 24, 24]               0\n",
      "          Conv2d-134          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 24, 24]             512\n",
      "            ReLU-136          [-1, 256, 24, 24]               0\n",
      "          Conv2d-137         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-139         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-140         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-141          [-1, 512, 24, 24]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 24, 24]           1,024\n",
      "            ReLU-143          [-1, 512, 24, 24]               0\n",
      "          Conv2d-144          [-1, 512, 12, 12]       2,359,296\n",
      "     BatchNorm2d-145          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-146          [-1, 512, 12, 12]               0\n",
      "          Conv2d-147         [-1, 2048, 12, 12]       1,048,576\n",
      "     BatchNorm2d-148         [-1, 2048, 12, 12]           4,096\n",
      "          Conv2d-149         [-1, 2048, 12, 12]       2,097,152\n",
      "     BatchNorm2d-150         [-1, 2048, 12, 12]           4,096\n",
      "            ReLU-151         [-1, 2048, 12, 12]               0\n",
      "      Bottleneck-152         [-1, 2048, 12, 12]               0\n",
      "          Conv2d-153          [-1, 512, 12, 12]       1,048,576\n",
      "     BatchNorm2d-154          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-155          [-1, 512, 12, 12]               0\n",
      "          Conv2d-156          [-1, 512, 12, 12]       2,359,296\n",
      "     BatchNorm2d-157          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-158          [-1, 512, 12, 12]               0\n",
      "          Conv2d-159         [-1, 2048, 12, 12]       1,048,576\n",
      "     BatchNorm2d-160         [-1, 2048, 12, 12]           4,096\n",
      "            ReLU-161         [-1, 2048, 12, 12]               0\n",
      "      Bottleneck-162         [-1, 2048, 12, 12]               0\n",
      "          Conv2d-163          [-1, 512, 12, 12]       1,048,576\n",
      "     BatchNorm2d-164          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-165          [-1, 512, 12, 12]               0\n",
      "          Conv2d-166          [-1, 512, 12, 12]       2,359,296\n",
      "     BatchNorm2d-167          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-168          [-1, 512, 12, 12]               0\n",
      "          Conv2d-169         [-1, 2048, 12, 12]       1,048,576\n",
      "     BatchNorm2d-170         [-1, 2048, 12, 12]           4,096\n",
      "            ReLU-171         [-1, 2048, 12, 12]               0\n",
      "      Bottleneck-172         [-1, 2048, 12, 12]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                    [-1, 4]           8,196\n",
      "================================================================\n",
      "Total params: 23,516,228\n",
      "Trainable params: 23,516,228\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.69\n",
      "Forward/backward pass size (MB): 842.08\n",
      "Params size (MB): 89.71\n",
      "Estimated Total Size (MB): 933.47\n",
      "----------------------------------------------------------------\n",
      "model : ResNet50_RockModel\n",
      "no valid counterparts augmentation selected\n",
      "Epoch 1/10\n",
      "----------\n",
      "Epoch: 1     train index of 5 minibatch: 1      time used: 49.37645173072815\n",
      "minibatch AVG loss: 1.4064561605453492\n",
      "\n",
      "Epoch: 1  train \n",
      "Loss: 1.4065  Acc: 45.0000\n",
      "granite-blackswan precision: 57.1429  recall: 80.0000\n",
      "granite-blackswan sensitivity: 80.0000  specificity: 80.0000\n",
      "granite-blackswan FPR: 20.0000  NPV: 92.3077\n",
      "granite-blackswan TP: 4.0\n",
      "granite-blackswan TN: 12.0\n",
      "granite-blackswan FP: 3.0\n",
      "granite-blackswan FN: 1.0\n",
      "marble-shadow precision: 38.4615  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 46.6667\n",
      "marble-shadow FPR: 53.3333  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 7.0\n",
      "marble-shadow FP: 8.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 5.0\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-patagonia TP: 0.0\n",
      "quartzite-patagonia TN: 15.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 5.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 1  val \n",
      "Loss: 1.3190  Acc: 25.0000\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 20.0000  recall: 66.6667\n",
      "marble-shadow sensitivity: 66.6667  specificity: 11.1111\n",
      "marble-shadow FPR: 88.8889  NPV: 50.0000\n",
      "marble-shadow TP: 2.0\n",
      "marble-shadow TN: 1.0\n",
      "marble-shadow FP: 8.0\n",
      "marble-shadow FN: 1.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 50.0000  recall: 33.3333\n",
      "quartzite-patagonia sensitivity: 33.3333  specificity: 88.8889\n",
      "quartzite-patagonia FPR: 11.1111  NPV: 80.0000\n",
      "quartzite-patagonia TP: 1.0\n",
      "quartzite-patagonia TN: 8.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 2.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Epoch: 2     train index of 5 minibatch: 1      time used: 44.78870725631714\n",
      "minibatch AVG loss: 1.3036048650741576\n",
      "\n",
      "Epoch: 2  train \n",
      "Loss: 1.3036  Acc: 35.0000\n",
      "granite-blackswan precision: 33.3333  recall: 40.0000\n",
      "granite-blackswan sensitivity: 40.0000  specificity: 73.3333\n",
      "granite-blackswan FPR: 26.6667  NPV: 78.5714\n",
      "granite-blackswan TP: 2.0\n",
      "granite-blackswan TN: 11.0\n",
      "granite-blackswan FP: 4.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 38.4615  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 46.6667\n",
      "marble-shadow FPR: 53.3333  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 7.0\n",
      "marble-shadow FP: 8.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 5.0\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 93.3333\n",
      "quartzite-patagonia FPR: 6.6667  NPV: 73.6842\n",
      "quartzite-patagonia TP: 0.0\n",
      "quartzite-patagonia TN: 14.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 5.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 2  val \n",
      "Loss: 1.3635  Acc: 8.3333\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 10.0000  recall: 33.3333\n",
      "marble-shadow sensitivity: 33.3333  specificity: 0.0000\n",
      "marble-shadow FPR: 100.0000  NPV: 0.0000\n",
      "marble-shadow TP: 1.0\n",
      "marble-shadow TN: 0.0\n",
      "marble-shadow FP: 9.0\n",
      "marble-shadow FN: 2.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 77.7778\n",
      "quartzite-patagonia FPR: 22.2222  NPV: 70.0000\n",
      "quartzite-patagonia TP: 0.0\n",
      "quartzite-patagonia TN: 7.0\n",
      "quartzite-patagonia FP: 2.0\n",
      "quartzite-patagonia FN: 3.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Epoch: 3     train index of 5 minibatch: 1      time used: 35.88988494873047\n",
      "minibatch AVG loss: 1.247235655784607\n",
      "\n",
      "Epoch: 3  train \n",
      "Loss: 1.2472  Acc: 45.0000\n",
      "granite-blackswan precision: 50.0000  recall: 60.0000\n",
      "granite-blackswan sensitivity: 60.0000  specificity: 80.0000\n",
      "granite-blackswan FPR: 20.0000  NPV: 85.7143\n",
      "granite-blackswan TP: 3.0\n",
      "granite-blackswan TN: 12.0\n",
      "granite-blackswan FP: 3.0\n",
      "granite-blackswan FN: 2.0\n",
      "marble-shadow precision: 41.6667  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 53.3333\n",
      "marble-shadow FPR: 46.6667  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 8.0\n",
      "marble-shadow FP: 7.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 5.0\n",
      "quartzite-patagonia precision: 50.0000  recall: 20.0000\n",
      "quartzite-patagonia sensitivity: 20.0000  specificity: 93.3333\n",
      "quartzite-patagonia FPR: 6.6667  NPV: 77.7778\n",
      "quartzite-patagonia TP: 1.0\n",
      "quartzite-patagonia TN: 14.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 4.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 3  val \n",
      "Loss: 1.3562  Acc: 8.3333\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 10.0000  recall: 33.3333\n",
      "marble-shadow sensitivity: 33.3333  specificity: 0.0000\n",
      "marble-shadow FPR: 100.0000  NPV: 0.0000\n",
      "marble-shadow TP: 1.0\n",
      "marble-shadow TN: 0.0\n",
      "marble-shadow FP: 9.0\n",
      "marble-shadow FN: 2.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 77.7778\n",
      "quartzite-patagonia FPR: 22.2222  NPV: 70.0000\n",
      "quartzite-patagonia TP: 0.0\n",
      "quartzite-patagonia TN: 7.0\n",
      "quartzite-patagonia FP: 2.0\n",
      "quartzite-patagonia FN: 3.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Epoch: 4     train index of 5 minibatch: 1      time used: 29.428394556045532\n",
      "minibatch AVG loss: 1.1879793882369996\n",
      "\n",
      "Epoch: 4  train \n",
      "Loss: 1.1880  Acc: 50.0000\n",
      "granite-blackswan precision: 57.1429  recall: 80.0000\n",
      "granite-blackswan sensitivity: 80.0000  specificity: 80.0000\n",
      "granite-blackswan FPR: 20.0000  NPV: 92.3077\n",
      "granite-blackswan TP: 4.0\n",
      "granite-blackswan TN: 12.0\n",
      "granite-blackswan FP: 3.0\n",
      "granite-blackswan FN: 1.0\n",
      "marble-shadow precision: 41.6667  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 53.3333\n",
      "marble-shadow FPR: 46.6667  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 8.0\n",
      "marble-shadow FP: 7.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 5.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 20.0000\n",
      "quartzite-patagonia sensitivity: 20.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 78.9474\n",
      "quartzite-patagonia TP: 1.0\n",
      "quartzite-patagonia TN: 15.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 4.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 4  val \n",
      "Loss: 1.3374  Acc: 16.6667\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 22.2222  recall: 66.6667\n",
      "marble-shadow sensitivity: 66.6667  specificity: 22.2222\n",
      "marble-shadow FPR: 77.7778  NPV: 66.6667\n",
      "marble-shadow TP: 2.0\n",
      "marble-shadow TN: 2.0\n",
      "marble-shadow FP: 7.0\n",
      "marble-shadow FN: 1.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 66.6667\n",
      "quartzite-patagonia FPR: 33.3333  NPV: 66.6667\n",
      "quartzite-patagonia TP: 0.0\n",
      "quartzite-patagonia TN: 6.0\n",
      "quartzite-patagonia FP: 3.0\n",
      "quartzite-patagonia FN: 3.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Epoch: 5     train index of 5 minibatch: 1      time used: 35.06725478172302\n",
      "minibatch AVG loss: 1.1087926745414733\n",
      "\n",
      "Epoch: 5  train \n",
      "Loss: 1.1088  Acc: 65.0000\n",
      "granite-blackswan precision: 66.6667  recall: 80.0000\n",
      "granite-blackswan sensitivity: 80.0000  specificity: 86.6667\n",
      "granite-blackswan FPR: 13.3333  NPV: 92.8571\n",
      "granite-blackswan TP: 4.0\n",
      "granite-blackswan TN: 13.0\n",
      "granite-blackswan FP: 2.0\n",
      "granite-blackswan FN: 1.0\n",
      "marble-shadow precision: 50.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 66.6667\n",
      "marble-shadow FPR: 33.3333  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 10.0\n",
      "marble-shadow FP: 5.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 20.0000\n",
      "quartzite-oceanblue sensitivity: 20.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 78.9474\n",
      "quartzite-oceanblue TP: 1.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 4.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 60.0000\n",
      "quartzite-patagonia sensitivity: 60.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 88.2353\n",
      "quartzite-patagonia TP: 3.0\n",
      "quartzite-patagonia TN: 15.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 2.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 5  val \n",
      "Loss: 1.3037  Acc: 41.6667\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 60.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 77.7778\n",
      "marble-shadow FPR: 22.2222  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 7.0\n",
      "marble-shadow FP: 2.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 28.5714  recall: 66.6667\n",
      "quartzite-patagonia sensitivity: 66.6667  specificity: 44.4444\n",
      "quartzite-patagonia FPR: 55.5556  NPV: 80.0000\n",
      "quartzite-patagonia TP: 2.0\n",
      "quartzite-patagonia TN: 4.0\n",
      "quartzite-patagonia FP: 5.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Epoch: 6     train index of 5 minibatch: 1      time used: 38.00535869598389\n",
      "minibatch AVG loss: 1.1219143629074098\n",
      "\n",
      "Epoch: 6  train \n",
      "Loss: 1.1219  Acc: 60.0000\n",
      "granite-blackswan precision: 80.0000  recall: 80.0000\n",
      "granite-blackswan sensitivity: 80.0000  specificity: 93.3333\n",
      "granite-blackswan FPR: 6.6667  NPV: 93.3333\n",
      "granite-blackswan TP: 4.0\n",
      "granite-blackswan TN: 14.0\n",
      "granite-blackswan FP: 1.0\n",
      "granite-blackswan FN: 1.0\n",
      "marble-shadow precision: 45.4545  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 60.0000\n",
      "marble-shadow FPR: 40.0000  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 6.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 5.0\n",
      "quartzite-patagonia precision: 75.0000  recall: 60.0000\n",
      "quartzite-patagonia sensitivity: 60.0000  specificity: 93.3333\n",
      "quartzite-patagonia FPR: 6.6667  NPV: 87.5000\n",
      "quartzite-patagonia TP: 3.0\n",
      "quartzite-patagonia TN: 14.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 2.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 6  val \n",
      "Loss: 1.2535  Acc: 41.6667\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 60.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 77.7778\n",
      "marble-shadow FPR: 22.2222  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 7.0\n",
      "marble-shadow FP: 2.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 28.5714  recall: 66.6667\n",
      "quartzite-patagonia sensitivity: 66.6667  specificity: 44.4444\n",
      "quartzite-patagonia FPR: 55.5556  NPV: 80.0000\n",
      "quartzite-patagonia TP: 2.0\n",
      "quartzite-patagonia TN: 4.0\n",
      "quartzite-patagonia FP: 5.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Epoch: 7     train index of 5 minibatch: 1      time used: 33.620301723480225\n",
      "minibatch AVG loss: 1.1450718641281128\n",
      "\n",
      "Epoch: 7  train \n",
      "Loss: 1.1451  Acc: 70.0000\n",
      "granite-blackswan precision: 83.3333  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 93.3333\n",
      "granite-blackswan FPR: 6.6667  NPV: 100.0000\n",
      "granite-blackswan TP: 5.0\n",
      "granite-blackswan TN: 14.0\n",
      "granite-blackswan FP: 1.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 55.5556  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 73.3333\n",
      "marble-shadow FPR: 26.6667  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 11.0\n",
      "marble-shadow FP: 4.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 40.0000\n",
      "quartzite-oceanblue sensitivity: 40.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 83.3333\n",
      "quartzite-oceanblue TP: 2.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 66.6667  recall: 40.0000\n",
      "quartzite-patagonia sensitivity: 40.0000  specificity: 93.3333\n",
      "quartzite-patagonia FPR: 6.6667  NPV: 82.3529\n",
      "quartzite-patagonia TP: 2.0\n",
      "quartzite-patagonia TN: 14.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 3.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 7  val \n",
      "Loss: 1.2048  Acc: 50.0000\n",
      "granite-blackswan precision: 100.0000  recall: 33.3333\n",
      "granite-blackswan sensitivity: 33.3333  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 81.8182\n",
      "granite-blackswan TP: 1.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 2.0\n",
      "marble-shadow precision: 60.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 77.7778\n",
      "marble-shadow FPR: 22.2222  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 7.0\n",
      "marble-shadow FP: 2.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 88.8889\n",
      "quartzite-oceanblue FPR: 11.1111  NPV: 72.7273\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 8.0\n",
      "quartzite-oceanblue FP: 1.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 40.0000  recall: 66.6667\n",
      "quartzite-patagonia sensitivity: 66.6667  specificity: 66.6667\n",
      "quartzite-patagonia FPR: 33.3333  NPV: 85.7143\n",
      "quartzite-patagonia TP: 2.0\n",
      "quartzite-patagonia TN: 6.0\n",
      "quartzite-patagonia FP: 3.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Epoch: 8     train index of 5 minibatch: 1      time used: 39.27657103538513\n",
      "minibatch AVG loss: 1.017759346961975\n",
      "\n",
      "Epoch: 8  train \n",
      "Loss: 1.0178  Acc: 80.0000\n",
      "granite-blackswan precision: 80.0000  recall: 80.0000\n",
      "granite-blackswan sensitivity: 80.0000  specificity: 93.3333\n",
      "granite-blackswan FPR: 6.6667  NPV: 93.3333\n",
      "granite-blackswan TP: 4.0\n",
      "granite-blackswan TN: 14.0\n",
      "granite-blackswan FP: 1.0\n",
      "granite-blackswan FN: 1.0\n",
      "marble-shadow precision: 71.4286  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 86.6667\n",
      "marble-shadow FPR: 13.3333  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 13.0\n",
      "marble-shadow FP: 2.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 60.0000\n",
      "quartzite-oceanblue sensitivity: 60.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 88.2353\n",
      "quartzite-oceanblue TP: 3.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 2.0\n",
      "quartzite-patagonia precision: 80.0000  recall: 80.0000\n",
      "quartzite-patagonia sensitivity: 80.0000  specificity: 93.3333\n",
      "quartzite-patagonia FPR: 6.6667  NPV: 93.3333\n",
      "quartzite-patagonia TP: 4.0\n",
      "quartzite-patagonia TN: 14.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 8  val \n",
      "Loss: 1.1527  Acc: 50.0000\n",
      "granite-blackswan precision: 100.0000  recall: 33.3333\n",
      "granite-blackswan sensitivity: 33.3333  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 81.8182\n",
      "granite-blackswan TP: 1.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 2.0\n",
      "marble-shadow precision: 60.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 77.7778\n",
      "marble-shadow FPR: 22.2222  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 7.0\n",
      "marble-shadow FP: 2.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 88.8889\n",
      "quartzite-oceanblue FPR: 11.1111  NPV: 72.7273\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 8.0\n",
      "quartzite-oceanblue FP: 1.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 40.0000  recall: 66.6667\n",
      "quartzite-patagonia sensitivity: 66.6667  specificity: 66.6667\n",
      "quartzite-patagonia FPR: 33.3333  NPV: 85.7143\n",
      "quartzite-patagonia TP: 2.0\n",
      "quartzite-patagonia TN: 6.0\n",
      "quartzite-patagonia FP: 3.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Epoch: 9     train index of 5 minibatch: 1      time used: 33.281769037246704\n",
      "minibatch AVG loss: 0.9966102480888367\n",
      "\n",
      "Epoch: 9  train \n",
      "Loss: 0.9966  Acc: 85.0000\n",
      "granite-blackswan precision: 83.3333  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 93.3333\n",
      "granite-blackswan FPR: 6.6667  NPV: 100.0000\n",
      "granite-blackswan TP: 5.0\n",
      "granite-blackswan TN: 14.0\n",
      "granite-blackswan FP: 1.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 71.4286  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 86.6667\n",
      "marble-shadow FPR: 13.3333  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 13.0\n",
      "marble-shadow FP: 2.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 60.0000\n",
      "quartzite-oceanblue sensitivity: 60.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 88.2353\n",
      "quartzite-oceanblue TP: 3.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 2.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 80.0000\n",
      "quartzite-patagonia sensitivity: 80.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 93.7500\n",
      "quartzite-patagonia TP: 4.0\n",
      "quartzite-patagonia TN: 15.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 9  val \n",
      "Loss: 1.1108  Acc: 58.3333\n",
      "granite-blackswan precision: 100.0000  recall: 66.6667\n",
      "granite-blackswan sensitivity: 66.6667  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 90.0000\n",
      "granite-blackswan TP: 2.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 1.0\n",
      "marble-shadow precision: 60.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 77.7778\n",
      "marble-shadow FPR: 22.2222  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 7.0\n",
      "marble-shadow FP: 2.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 40.0000  recall: 66.6667\n",
      "quartzite-patagonia sensitivity: 66.6667  specificity: 66.6667\n",
      "quartzite-patagonia FPR: 33.3333  NPV: 85.7143\n",
      "quartzite-patagonia TP: 2.0\n",
      "quartzite-patagonia TN: 6.0\n",
      "quartzite-patagonia FP: 3.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Epoch: 10     train index of 5 minibatch: 1      time used: 34.569554805755615\n",
      "minibatch AVG loss: 1.0992003679275513\n",
      "\n",
      "Epoch: 10  train \n",
      "Loss: 1.0992  Acc: 75.0000\n",
      "granite-blackswan precision: 66.6667  recall: 80.0000\n",
      "granite-blackswan sensitivity: 80.0000  specificity: 86.6667\n",
      "granite-blackswan FPR: 13.3333  NPV: 92.8571\n",
      "granite-blackswan TP: 4.0\n",
      "granite-blackswan TN: 13.0\n",
      "granite-blackswan FP: 2.0\n",
      "granite-blackswan FN: 1.0\n",
      "marble-shadow precision: 71.4286  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 86.6667\n",
      "marble-shadow FPR: 13.3333  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 13.0\n",
      "marble-shadow FP: 2.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 40.0000\n",
      "quartzite-oceanblue sensitivity: 40.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 83.3333\n",
      "quartzite-oceanblue TP: 2.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 80.0000  recall: 80.0000\n",
      "quartzite-patagonia sensitivity: 80.0000  specificity: 93.3333\n",
      "quartzite-patagonia FPR: 6.6667  NPV: 93.3333\n",
      "quartzite-patagonia TP: 4.0\n",
      "quartzite-patagonia TN: 14.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 10  val \n",
      "Loss: 1.0931  Acc: 58.3333\n",
      "granite-blackswan precision: 100.0000  recall: 66.6667\n",
      "granite-blackswan sensitivity: 66.6667  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 90.0000\n",
      "granite-blackswan TP: 2.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 1.0\n",
      "marble-shadow precision: 60.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 77.7778\n",
      "marble-shadow FPR: 22.2222  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 7.0\n",
      "marble-shadow FP: 2.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 40.0000  recall: 66.6667\n",
      "quartzite-patagonia sensitivity: 66.6667  specificity: 66.6667\n",
      "quartzite-patagonia FPR: 33.3333  NPV: 85.7143\n",
      "quartzite-patagonia TP: 2.0\n",
      "quartzite-patagonia TN: 6.0\n",
      "quartzite-patagonia FP: 3.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Training complete in 8m 32s\n",
      "Best epoch idx:  9\n",
      "Best epoch train Acc: 85.000000\n",
      "Best epoch val Acc: 58.333333\n",
      "granite-blackswan precision: 100.0000  recall: 66.6667\n",
      "granite-blackswan sensitivity: 66.6667  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 90.0000\n",
      "marble-shadow precision: 60.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 77.7778\n",
      "marble-shadow FPR: 22.2222  NPV: 100.0000\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-patagonia precision: 40.0000  recall: 66.6667\n",
      "quartzite-patagonia sensitivity: 66.6667  specificity: 66.6667\n",
      "quartzite-patagonia FPR: 33.3333  NPV: 85.7143\n",
      "model trained by GPU (idx:0) has been saved at  saved_models\\CLS_ResNet50_RockModel.pth\n"
     ]
    }
   ],
   "source": [
    "!python Train.py --model_idx ResNet50_RockModel --edge_size 384 --data_augmentation_mode 2 --batch_size 4 --lr 0.00001 --lrf 0.05 --enable_tensorboard --check_minibatch 5 --dataroot sample_datasets/warwick_CLS --model_path saved_models --draw_root runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names: ['granite-blackswan', 'marble-shadow', 'quartzite-oceanblue', 'quartzite-patagonia']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "Exception ignored in: <function BaseCAM.__del__ at 0x0000028160E49900>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\usuariolocal\\OneDrive\\Documentos\\Douglas\\Mestrado\\3 - Curso\\Meu projeto\\si_vit_ornamental_rocks\\pytorch_grad_cam\\base_cam.py\", line 191, in __del__\n",
      "    self.activations_and_grads.release()\n",
      "AttributeError: 'GradCAM' object has no attribute 'activations_and_grads'\n",
      "Exception ignored in: <function BaseCAM.__del__ at 0x0000028160E49900>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\usuariolocal\\OneDrive\\Documentos\\Douglas\\Mestrado\\3 - Curso\\Meu projeto\\si_vit_ornamental_rocks\\pytorch_grad_cam\\base_cam.py\", line 191, in __del__\n",
      "    self.activations_and_grads.release()\n",
      "AttributeError: 'GradCAM' object has no attribute 'activations_and_grads'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test model outputï¼ tensor([[-0.1912,  0.8562,  0.5144, -0.6979]], grad_fn=<AddmmBackward0>)\n",
      "model is ready now!\n",
      "model loaded\n",
      "model : ResNet50_RockModel\n",
      "*********************************setting*************************************\n",
      "Namespace(model_idx='ResNet50_RockModel', MIL_Stripe=False, drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.0, cls_token_off=False, pos_embedding_off=False, att_module='SimAM', gpu_idx=0, dataroot='sample_datasets/warwick_CLS', model_path='saved_models', draw_root='runs', paint=True, enable_notify=False, enable_tensorboard=False, enable_attention_check=True, enable_visualize_check=False, data_augmentation_mode=2, num_classes=0, edge_size=384, batch_size=1, check_minibatch=5)\n",
      "Epoch: Test\n",
      "----------\n",
      "Epoch: test     test index of 5 minibatch: 1      time used: 7.279638767242432\n",
      "minibatch AVG loss: 1.0926458477973937\n",
      "model: ResNet50_RockModel  with edge_size 384 is not supported yet\n",
      "Epoch: test     test index of 5 minibatch: 2      time used: 2.1087284088134766\n",
      "minibatch AVG loss: 1.1845079898834228\n",
      "model: ResNet50_RockModel  with edge_size 384 is not supported yet\n",
      "\n",
      "Epoch:  test \n",
      "Loss: 1.1213  Acc: 66.6667\n",
      "granite-blackswan precision: 100.0000  recall: 66.6667\n",
      "granite-blackswan sensitivity: 66.6667  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 90.0000\n",
      "granite-blackswan TP: 2.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 1.0\n",
      "marble-shadow precision: 50.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 66.6667\n",
      "marble-shadow FPR: 33.3333  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 6.0\n",
      "marble-shadow FP: 3.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 75.0000  recall: 100.0000\n",
      "quartzite-patagonia sensitivity: 100.0000  specificity: 88.8889\n",
      "quartzite-patagonia FPR: 11.1111  NPV: 100.0000\n",
      "quartzite-patagonia TP: 3.0\n",
      "quartzite-patagonia TN: 8.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 0.0\n",
      "\n",
      "\n",
      "Testing complete in 0m 13s\n"
     ]
    }
   ],
   "source": [
    "!python Test.py --model_idx ResNet50_RockModel --edge_size 384 --data_augmentation_mode 2 --enable_attention_check --check_minibatch 5 --dataroot sample_datasets/warwick_CLS --model_path saved_models --draw_root runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet101 network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names: ['granite-blackswan', 'marble-shadow', 'quartzite-oceanblue', 'quartzite-patagonia']\n",
      "*********************************setting*************************************\n",
      "Namespace(model_idx='ResNet101_RockModel', drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.0, cls_token_off=False, pos_embedding_off=False, att_module='SimAM', backbone_PT_off=False, gpu_idx=-1, dataroot='sample_datasets/warwick_CLS', model_path='saved_models', draw_root='runs', paint=True, enable_notify=False, enable_tensorboard=True, enable_attention_check=False, enable_visualize_check=False, enable_sam=False, augmentation_name=None, data_augmentation_mode=2, linearprobing=False, Pre_Trained_model_path=None, num_classes=0, edge_size=384, num_workers=2, batch_size=4, check_minibatch=5, num_epochs=10, intake_epochs=0, lr=1e-05, lrf=0.05, opt_name='Adam')\n",
      "we dont have more GPU idx here, try to use gpu_idx=0\n",
      "test model outputï¼ tensor([[-0.4021,  0.0979, -0.1426, -0.1592]], grad_fn=<AddmmBackward0>)\n",
      "model is ready now!\n",
      "GPU: 0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 192, 192]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 192, 192]             128\n",
      "              ReLU-3         [-1, 64, 192, 192]               0\n",
      "         MaxPool2d-4           [-1, 64, 96, 96]               0\n",
      "            Conv2d-5           [-1, 64, 96, 96]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 96, 96]             128\n",
      "              ReLU-7           [-1, 64, 96, 96]               0\n",
      "            Conv2d-8           [-1, 64, 96, 96]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 96, 96]             128\n",
      "             ReLU-10           [-1, 64, 96, 96]               0\n",
      "           Conv2d-11          [-1, 256, 96, 96]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 96, 96]             512\n",
      "           Conv2d-13          [-1, 256, 96, 96]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 96, 96]             512\n",
      "             ReLU-15          [-1, 256, 96, 96]               0\n",
      "       Bottleneck-16          [-1, 256, 96, 96]               0\n",
      "           Conv2d-17           [-1, 64, 96, 96]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 96, 96]             128\n",
      "             ReLU-19           [-1, 64, 96, 96]               0\n",
      "           Conv2d-20           [-1, 64, 96, 96]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 96, 96]             128\n",
      "             ReLU-22           [-1, 64, 96, 96]               0\n",
      "           Conv2d-23          [-1, 256, 96, 96]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 96, 96]             512\n",
      "             ReLU-25          [-1, 256, 96, 96]               0\n",
      "       Bottleneck-26          [-1, 256, 96, 96]               0\n",
      "           Conv2d-27           [-1, 64, 96, 96]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 96, 96]             128\n",
      "             ReLU-29           [-1, 64, 96, 96]               0\n",
      "           Conv2d-30           [-1, 64, 96, 96]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 96, 96]             128\n",
      "             ReLU-32           [-1, 64, 96, 96]               0\n",
      "           Conv2d-33          [-1, 256, 96, 96]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 96, 96]             512\n",
      "             ReLU-35          [-1, 256, 96, 96]               0\n",
      "       Bottleneck-36          [-1, 256, 96, 96]               0\n",
      "           Conv2d-37          [-1, 128, 96, 96]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 96, 96]             256\n",
      "             ReLU-39          [-1, 128, 96, 96]               0\n",
      "           Conv2d-40          [-1, 128, 48, 48]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 48, 48]             256\n",
      "             ReLU-42          [-1, 128, 48, 48]               0\n",
      "           Conv2d-43          [-1, 512, 48, 48]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 48, 48]           1,024\n",
      "           Conv2d-45          [-1, 512, 48, 48]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 48, 48]           1,024\n",
      "             ReLU-47          [-1, 512, 48, 48]               0\n",
      "       Bottleneck-48          [-1, 512, 48, 48]               0\n",
      "           Conv2d-49          [-1, 128, 48, 48]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 48, 48]             256\n",
      "             ReLU-51          [-1, 128, 48, 48]               0\n",
      "           Conv2d-52          [-1, 128, 48, 48]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 48, 48]             256\n",
      "             ReLU-54          [-1, 128, 48, 48]               0\n",
      "           Conv2d-55          [-1, 512, 48, 48]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 48, 48]           1,024\n",
      "             ReLU-57          [-1, 512, 48, 48]               0\n",
      "       Bottleneck-58          [-1, 512, 48, 48]               0\n",
      "           Conv2d-59          [-1, 128, 48, 48]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 48, 48]             256\n",
      "             ReLU-61          [-1, 128, 48, 48]               0\n",
      "           Conv2d-62          [-1, 128, 48, 48]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 48, 48]             256\n",
      "             ReLU-64          [-1, 128, 48, 48]               0\n",
      "           Conv2d-65          [-1, 512, 48, 48]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 48, 48]           1,024\n",
      "             ReLU-67          [-1, 512, 48, 48]               0\n",
      "       Bottleneck-68          [-1, 512, 48, 48]               0\n",
      "           Conv2d-69          [-1, 128, 48, 48]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 48, 48]             256\n",
      "             ReLU-71          [-1, 128, 48, 48]               0\n",
      "           Conv2d-72          [-1, 128, 48, 48]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 48, 48]             256\n",
      "             ReLU-74          [-1, 128, 48, 48]               0\n",
      "           Conv2d-75          [-1, 512, 48, 48]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 48, 48]           1,024\n",
      "             ReLU-77          [-1, 512, 48, 48]               0\n",
      "       Bottleneck-78          [-1, 512, 48, 48]               0\n",
      "           Conv2d-79          [-1, 256, 48, 48]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 48, 48]             512\n",
      "             ReLU-81          [-1, 256, 48, 48]               0\n",
      "           Conv2d-82          [-1, 256, 24, 24]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 24, 24]             512\n",
      "             ReLU-84          [-1, 256, 24, 24]               0\n",
      "           Conv2d-85         [-1, 1024, 24, 24]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 24, 24]           2,048\n",
      "           Conv2d-87         [-1, 1024, 24, 24]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 24, 24]           2,048\n",
      "             ReLU-89         [-1, 1024, 24, 24]               0\n",
      "       Bottleneck-90         [-1, 1024, 24, 24]               0\n",
      "           Conv2d-91          [-1, 256, 24, 24]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 24, 24]             512\n",
      "             ReLU-93          [-1, 256, 24, 24]               0\n",
      "           Conv2d-94          [-1, 256, 24, 24]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 24, 24]             512\n",
      "             ReLU-96          [-1, 256, 24, 24]               0\n",
      "           Conv2d-97         [-1, 1024, 24, 24]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 24, 24]           2,048\n",
      "             ReLU-99         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-100         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-101          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 24, 24]             512\n",
      "            ReLU-103          [-1, 256, 24, 24]               0\n",
      "          Conv2d-104          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 24, 24]             512\n",
      "            ReLU-106          [-1, 256, 24, 24]               0\n",
      "          Conv2d-107         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-109         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-110         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-111          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 24, 24]             512\n",
      "            ReLU-113          [-1, 256, 24, 24]               0\n",
      "          Conv2d-114          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 24, 24]             512\n",
      "            ReLU-116          [-1, 256, 24, 24]               0\n",
      "          Conv2d-117         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-119         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-120         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-121          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 24, 24]             512\n",
      "            ReLU-123          [-1, 256, 24, 24]               0\n",
      "          Conv2d-124          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 24, 24]             512\n",
      "            ReLU-126          [-1, 256, 24, 24]               0\n",
      "          Conv2d-127         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-129         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-130         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-131          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 24, 24]             512\n",
      "            ReLU-133          [-1, 256, 24, 24]               0\n",
      "          Conv2d-134          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 24, 24]             512\n",
      "            ReLU-136          [-1, 256, 24, 24]               0\n",
      "          Conv2d-137         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-139         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-140         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-141          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-142          [-1, 256, 24, 24]             512\n",
      "            ReLU-143          [-1, 256, 24, 24]               0\n",
      "          Conv2d-144          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-145          [-1, 256, 24, 24]             512\n",
      "            ReLU-146          [-1, 256, 24, 24]               0\n",
      "          Conv2d-147         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-148         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-149         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-150         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-151          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-152          [-1, 256, 24, 24]             512\n",
      "            ReLU-153          [-1, 256, 24, 24]               0\n",
      "          Conv2d-154          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-155          [-1, 256, 24, 24]             512\n",
      "            ReLU-156          [-1, 256, 24, 24]               0\n",
      "          Conv2d-157         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-158         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-159         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-160         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-161          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-162          [-1, 256, 24, 24]             512\n",
      "            ReLU-163          [-1, 256, 24, 24]               0\n",
      "          Conv2d-164          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-165          [-1, 256, 24, 24]             512\n",
      "            ReLU-166          [-1, 256, 24, 24]               0\n",
      "          Conv2d-167         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-168         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-169         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-170         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-171          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-172          [-1, 256, 24, 24]             512\n",
      "            ReLU-173          [-1, 256, 24, 24]               0\n",
      "          Conv2d-174          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-175          [-1, 256, 24, 24]             512\n",
      "            ReLU-176          [-1, 256, 24, 24]               0\n",
      "          Conv2d-177         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-178         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-179         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-180         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-181          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-182          [-1, 256, 24, 24]             512\n",
      "            ReLU-183          [-1, 256, 24, 24]               0\n",
      "          Conv2d-184          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-185          [-1, 256, 24, 24]             512\n",
      "            ReLU-186          [-1, 256, 24, 24]               0\n",
      "          Conv2d-187         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-188         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-189         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-190         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-191          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-192          [-1, 256, 24, 24]             512\n",
      "            ReLU-193          [-1, 256, 24, 24]               0\n",
      "          Conv2d-194          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-195          [-1, 256, 24, 24]             512\n",
      "            ReLU-196          [-1, 256, 24, 24]               0\n",
      "          Conv2d-197         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-198         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-199         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-200         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-201          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-202          [-1, 256, 24, 24]             512\n",
      "            ReLU-203          [-1, 256, 24, 24]               0\n",
      "          Conv2d-204          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-205          [-1, 256, 24, 24]             512\n",
      "            ReLU-206          [-1, 256, 24, 24]               0\n",
      "          Conv2d-207         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-208         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-209         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-210         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-211          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-212          [-1, 256, 24, 24]             512\n",
      "            ReLU-213          [-1, 256, 24, 24]               0\n",
      "          Conv2d-214          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-215          [-1, 256, 24, 24]             512\n",
      "            ReLU-216          [-1, 256, 24, 24]               0\n",
      "          Conv2d-217         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-218         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-219         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-220         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-221          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-222          [-1, 256, 24, 24]             512\n",
      "            ReLU-223          [-1, 256, 24, 24]               0\n",
      "          Conv2d-224          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-225          [-1, 256, 24, 24]             512\n",
      "            ReLU-226          [-1, 256, 24, 24]               0\n",
      "          Conv2d-227         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-228         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-229         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-230         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-231          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-232          [-1, 256, 24, 24]             512\n",
      "            ReLU-233          [-1, 256, 24, 24]               0\n",
      "          Conv2d-234          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-235          [-1, 256, 24, 24]             512\n",
      "            ReLU-236          [-1, 256, 24, 24]               0\n",
      "          Conv2d-237         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-238         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-239         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-240         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-241          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-242          [-1, 256, 24, 24]             512\n",
      "            ReLU-243          [-1, 256, 24, 24]               0\n",
      "          Conv2d-244          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-245          [-1, 256, 24, 24]             512\n",
      "            ReLU-246          [-1, 256, 24, 24]               0\n",
      "          Conv2d-247         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-248         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-249         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-250         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-251          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-252          [-1, 256, 24, 24]             512\n",
      "            ReLU-253          [-1, 256, 24, 24]               0\n",
      "          Conv2d-254          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-255          [-1, 256, 24, 24]             512\n",
      "            ReLU-256          [-1, 256, 24, 24]               0\n",
      "          Conv2d-257         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-258         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-259         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-260         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-261          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-262          [-1, 256, 24, 24]             512\n",
      "            ReLU-263          [-1, 256, 24, 24]               0\n",
      "          Conv2d-264          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-265          [-1, 256, 24, 24]             512\n",
      "            ReLU-266          [-1, 256, 24, 24]               0\n",
      "          Conv2d-267         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-268         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-269         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-270         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-271          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-272          [-1, 256, 24, 24]             512\n",
      "            ReLU-273          [-1, 256, 24, 24]               0\n",
      "          Conv2d-274          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-275          [-1, 256, 24, 24]             512\n",
      "            ReLU-276          [-1, 256, 24, 24]               0\n",
      "          Conv2d-277         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-278         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-279         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-280         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-281          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-282          [-1, 256, 24, 24]             512\n",
      "            ReLU-283          [-1, 256, 24, 24]               0\n",
      "          Conv2d-284          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-285          [-1, 256, 24, 24]             512\n",
      "            ReLU-286          [-1, 256, 24, 24]               0\n",
      "          Conv2d-287         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-288         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-289         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-290         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-291          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-292          [-1, 256, 24, 24]             512\n",
      "            ReLU-293          [-1, 256, 24, 24]               0\n",
      "          Conv2d-294          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-295          [-1, 256, 24, 24]             512\n",
      "            ReLU-296          [-1, 256, 24, 24]               0\n",
      "          Conv2d-297         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-298         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-299         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-300         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-301          [-1, 256, 24, 24]         262,144\n",
      "     BatchNorm2d-302          [-1, 256, 24, 24]             512\n",
      "            ReLU-303          [-1, 256, 24, 24]               0\n",
      "          Conv2d-304          [-1, 256, 24, 24]         589,824\n",
      "     BatchNorm2d-305          [-1, 256, 24, 24]             512\n",
      "            ReLU-306          [-1, 256, 24, 24]               0\n",
      "          Conv2d-307         [-1, 1024, 24, 24]         262,144\n",
      "     BatchNorm2d-308         [-1, 1024, 24, 24]           2,048\n",
      "            ReLU-309         [-1, 1024, 24, 24]               0\n",
      "      Bottleneck-310         [-1, 1024, 24, 24]               0\n",
      "          Conv2d-311          [-1, 512, 24, 24]         524,288\n",
      "     BatchNorm2d-312          [-1, 512, 24, 24]           1,024\n",
      "            ReLU-313          [-1, 512, 24, 24]               0\n",
      "          Conv2d-314          [-1, 512, 12, 12]       2,359,296\n",
      "     BatchNorm2d-315          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-316          [-1, 512, 12, 12]               0\n",
      "          Conv2d-317         [-1, 2048, 12, 12]       1,048,576\n",
      "     BatchNorm2d-318         [-1, 2048, 12, 12]           4,096\n",
      "          Conv2d-319         [-1, 2048, 12, 12]       2,097,152\n",
      "     BatchNorm2d-320         [-1, 2048, 12, 12]           4,096\n",
      "            ReLU-321         [-1, 2048, 12, 12]               0\n",
      "      Bottleneck-322         [-1, 2048, 12, 12]               0\n",
      "          Conv2d-323          [-1, 512, 12, 12]       1,048,576\n",
      "     BatchNorm2d-324          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-325          [-1, 512, 12, 12]               0\n",
      "          Conv2d-326          [-1, 512, 12, 12]       2,359,296\n",
      "     BatchNorm2d-327          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-328          [-1, 512, 12, 12]               0\n",
      "          Conv2d-329         [-1, 2048, 12, 12]       1,048,576\n",
      "     BatchNorm2d-330         [-1, 2048, 12, 12]           4,096\n",
      "            ReLU-331         [-1, 2048, 12, 12]               0\n",
      "      Bottleneck-332         [-1, 2048, 12, 12]               0\n",
      "          Conv2d-333          [-1, 512, 12, 12]       1,048,576\n",
      "     BatchNorm2d-334          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-335          [-1, 512, 12, 12]               0\n",
      "          Conv2d-336          [-1, 512, 12, 12]       2,359,296\n",
      "     BatchNorm2d-337          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-338          [-1, 512, 12, 12]               0\n",
      "          Conv2d-339         [-1, 2048, 12, 12]       1,048,576\n",
      "     BatchNorm2d-340         [-1, 2048, 12, 12]           4,096\n",
      "            ReLU-341         [-1, 2048, 12, 12]               0\n",
      "      Bottleneck-342         [-1, 2048, 12, 12]               0\n",
      "AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n",
      "          Linear-344                    [-1, 4]           8,196\n",
      "================================================================\n",
      "Total params: 42,508,356\n",
      "Trainable params: 42,508,356\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.69\n",
      "Forward/backward pass size (MB): 1262.83\n",
      "Params size (MB): 162.16\n",
      "Estimated Total Size (MB): 1426.67\n",
      "----------------------------------------------------------------\n",
      "model : ResNet101_RockModel\n",
      "no valid counterparts augmentation selected\n",
      "Epoch 1/10\n",
      "----------\n",
      "Epoch: 1     train index of 5 minibatch: 1      time used: 41.576963901519775\n",
      "minibatch AVG loss: 1.4642906188964844\n",
      "\n",
      "Epoch: 1  train \n",
      "Loss: 1.4643  Acc: 20.0000\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 5.0\n",
      "marble-shadow precision: 21.0526  recall: 80.0000\n",
      "marble-shadow sensitivity: 80.0000  specificity: 0.0000\n",
      "marble-shadow FPR: 100.0000  NPV: 0.0000\n",
      "marble-shadow TP: 4.0\n",
      "marble-shadow TN: 0.0\n",
      "marble-shadow FP: 15.0\n",
      "marble-shadow FN: 1.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 5.0\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 93.3333\n",
      "quartzite-patagonia FPR: 6.6667  NPV: 73.6842\n",
      "quartzite-patagonia TP: 0.0\n",
      "quartzite-patagonia TN: 14.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 5.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 1  val \n",
      "Loss: 1.4383  Acc: 0.0000\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 11.1111\n",
      "marble-shadow FPR: 88.8889  NPV: 25.0000\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 1.0\n",
      "marble-shadow FP: 8.0\n",
      "marble-shadow FN: 3.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 55.5556\n",
      "quartzite-patagonia FPR: 44.4444  NPV: 62.5000\n",
      "quartzite-patagonia TP: 0.0\n",
      "quartzite-patagonia TN: 5.0\n",
      "quartzite-patagonia FP: 4.0\n",
      "quartzite-patagonia FN: 3.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Epoch: 2     train index of 5 minibatch: 1      time used: 30.050337314605713\n",
      "minibatch AVG loss: 1.301194190979004\n",
      "\n",
      "Epoch: 2  train \n",
      "Loss: 1.3012  Acc: 45.0000\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 5.0\n",
      "marble-shadow precision: 31.2500  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 26.6667\n",
      "marble-shadow FPR: 73.3333  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 4.0\n",
      "marble-shadow FP: 11.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 60.0000\n",
      "quartzite-oceanblue sensitivity: 60.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 88.2353\n",
      "quartzite-oceanblue TP: 3.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 2.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 20.0000\n",
      "quartzite-patagonia sensitivity: 20.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 78.9474\n",
      "quartzite-patagonia TP: 1.0\n",
      "quartzite-patagonia TN: 15.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 4.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 2  val \n",
      "Loss: 1.3803  Acc: 33.3333\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 30.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 22.2222\n",
      "marble-shadow FPR: 77.7778  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 2.0\n",
      "marble-shadow FP: 7.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 50.0000  recall: 33.3333\n",
      "quartzite-patagonia sensitivity: 33.3333  specificity: 88.8889\n",
      "quartzite-patagonia FPR: 11.1111  NPV: 80.0000\n",
      "quartzite-patagonia TP: 1.0\n",
      "quartzite-patagonia TN: 8.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 2.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Epoch: 3     train index of 5 minibatch: 1      time used: 30.869071006774902\n",
      "minibatch AVG loss: 1.2375839233398438\n",
      "\n",
      "Epoch: 3  train \n",
      "Loss: 1.2376  Acc: 55.0000\n",
      "granite-blackswan precision: 100.0000  recall: 20.0000\n",
      "granite-blackswan sensitivity: 20.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 78.9474\n",
      "granite-blackswan TP: 1.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 4.0\n",
      "marble-shadow precision: 38.4615  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 46.6667\n",
      "marble-shadow FPR: 53.3333  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 7.0\n",
      "marble-shadow FP: 8.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 20.0000\n",
      "quartzite-oceanblue sensitivity: 20.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 78.9474\n",
      "quartzite-oceanblue TP: 1.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 4.0\n",
      "quartzite-patagonia precision: 80.0000  recall: 80.0000\n",
      "quartzite-patagonia sensitivity: 80.0000  specificity: 93.3333\n",
      "quartzite-patagonia FPR: 6.6667  NPV: 93.3333\n",
      "quartzite-patagonia TP: 4.0\n",
      "quartzite-patagonia TN: 14.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 3  val \n",
      "Loss: 1.5687  Acc: 0.0000\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 0.0000\n",
      "marble-shadow FPR: 100.0000  NPV: 0.0000\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 0.0\n",
      "marble-shadow FP: 9.0\n",
      "marble-shadow FN: 3.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 66.6667\n",
      "quartzite-patagonia FPR: 33.3333  NPV: 66.6667\n",
      "quartzite-patagonia TP: 0.0\n",
      "quartzite-patagonia TN: 6.0\n",
      "quartzite-patagonia FP: 3.0\n",
      "quartzite-patagonia FN: 3.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Epoch: 4     train index of 5 minibatch: 1      time used: 28.45188331604004\n",
      "minibatch AVG loss: 1.1578839540481567\n",
      "\n",
      "Epoch: 4  train \n",
      "Loss: 1.1579  Acc: 70.0000\n",
      "granite-blackswan precision: 100.0000  recall: 60.0000\n",
      "granite-blackswan sensitivity: 60.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 88.2353\n",
      "granite-blackswan TP: 3.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 2.0\n",
      "marble-shadow precision: 45.4545  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 60.0000\n",
      "marble-shadow FPR: 40.0000  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 6.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 60.0000\n",
      "quartzite-oceanblue sensitivity: 60.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 88.2353\n",
      "quartzite-oceanblue TP: 3.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 2.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 60.0000\n",
      "quartzite-patagonia sensitivity: 60.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 88.2353\n",
      "quartzite-patagonia TP: 3.0\n",
      "quartzite-patagonia TN: 15.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 2.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 4  val \n",
      "Loss: 1.3869  Acc: 25.0000\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 25.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 0.0000\n",
      "marble-shadow FPR: 100.0000  NPV: 0.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 0.0\n",
      "marble-shadow FP: 9.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-patagonia TP: 0.0\n",
      "quartzite-patagonia TN: 9.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 3.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Epoch: 5     train index of 5 minibatch: 1      time used: 29.91656470298767\n",
      "minibatch AVG loss: 1.1246842622756958\n",
      "\n",
      "Epoch: 5  train \n",
      "Loss: 1.1247  Acc: 75.0000\n",
      "granite-blackswan precision: 100.0000  recall: 60.0000\n",
      "granite-blackswan sensitivity: 60.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 88.2353\n",
      "granite-blackswan TP: 3.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 2.0\n",
      "marble-shadow precision: 55.5556  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 73.3333\n",
      "marble-shadow FPR: 26.6667  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 11.0\n",
      "marble-shadow FP: 4.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 75.0000  recall: 60.0000\n",
      "quartzite-oceanblue sensitivity: 60.0000  specificity: 93.3333\n",
      "quartzite-oceanblue FPR: 6.6667  NPV: 87.5000\n",
      "quartzite-oceanblue TP: 3.0\n",
      "quartzite-oceanblue TN: 14.0\n",
      "quartzite-oceanblue FP: 1.0\n",
      "quartzite-oceanblue FN: 2.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 80.0000\n",
      "quartzite-patagonia sensitivity: 80.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 93.7500\n",
      "quartzite-patagonia TP: 4.0\n",
      "quartzite-patagonia TN: 15.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 5  val \n",
      "Loss: 1.2970  Acc: 33.3333\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 27.2727  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 11.1111\n",
      "marble-shadow FPR: 88.8889  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 1.0\n",
      "marble-shadow FP: 8.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 33.3333\n",
      "quartzite-patagonia sensitivity: 33.3333  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 81.8182\n",
      "quartzite-patagonia TP: 1.0\n",
      "quartzite-patagonia TN: 9.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 2.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Epoch: 6     train index of 5 minibatch: 1      time used: 31.27862286567688\n",
      "minibatch AVG loss: 1.093597173690796\n",
      "\n",
      "Epoch: 6  train \n",
      "Loss: 1.0936  Acc: 80.0000\n",
      "granite-blackswan precision: 100.0000  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 100.0000\n",
      "granite-blackswan TP: 5.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 62.5000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 80.0000\n",
      "marble-shadow FPR: 20.0000  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 12.0\n",
      "marble-shadow FP: 3.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 40.0000\n",
      "quartzite-oceanblue sensitivity: 40.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 83.3333\n",
      "quartzite-oceanblue TP: 2.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 80.0000  recall: 80.0000\n",
      "quartzite-patagonia sensitivity: 80.0000  specificity: 93.3333\n",
      "quartzite-patagonia FPR: 6.6667  NPV: 93.3333\n",
      "quartzite-patagonia TP: 4.0\n",
      "quartzite-patagonia TN: 14.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 6  val \n",
      "Loss: 1.2087  Acc: 58.3333\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 37.5000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 44.4444\n",
      "marble-shadow FPR: 55.5556  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 4.0\n",
      "marble-shadow FP: 5.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 66.6667\n",
      "quartzite-oceanblue sensitivity: 66.6667  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 90.0000\n",
      "quartzite-oceanblue TP: 2.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 1.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 66.6667\n",
      "quartzite-patagonia sensitivity: 66.6667  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 90.0000\n",
      "quartzite-patagonia TP: 2.0\n",
      "quartzite-patagonia TN: 9.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Epoch: 7     train index of 5 minibatch: 1      time used: 40.575045347213745\n",
      "minibatch AVG loss: 1.0890959739685058\n",
      "\n",
      "Epoch: 7  train \n",
      "Loss: 1.0891  Acc: 75.0000\n",
      "granite-blackswan precision: 100.0000  recall: 80.0000\n",
      "granite-blackswan sensitivity: 80.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 93.7500\n",
      "granite-blackswan TP: 4.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 1.0\n",
      "marble-shadow precision: 55.5556  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 73.3333\n",
      "marble-shadow FPR: 26.6667  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 11.0\n",
      "marble-shadow FP: 4.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 40.0000\n",
      "quartzite-oceanblue sensitivity: 40.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 83.3333\n",
      "quartzite-oceanblue TP: 2.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 80.0000  recall: 80.0000\n",
      "quartzite-patagonia sensitivity: 80.0000  specificity: 93.3333\n",
      "quartzite-patagonia FPR: 6.6667  NPV: 93.3333\n",
      "quartzite-patagonia TP: 4.0\n",
      "quartzite-patagonia TN: 14.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 7  val \n",
      "Loss: 1.1227  Acc: 58.3333\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 42.8571  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 55.5556\n",
      "marble-shadow FPR: 44.4444  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 5.0\n",
      "marble-shadow FP: 4.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 66.6667  recall: 66.6667\n",
      "quartzite-oceanblue sensitivity: 66.6667  specificity: 88.8889\n",
      "quartzite-oceanblue FPR: 11.1111  NPV: 88.8889\n",
      "quartzite-oceanblue TP: 2.0\n",
      "quartzite-oceanblue TN: 8.0\n",
      "quartzite-oceanblue FP: 1.0\n",
      "quartzite-oceanblue FN: 1.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 66.6667\n",
      "quartzite-patagonia sensitivity: 66.6667  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 90.0000\n",
      "quartzite-patagonia TP: 2.0\n",
      "quartzite-patagonia TN: 9.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Epoch: 8     train index of 5 minibatch: 1      time used: 33.106163024902344\n",
      "minibatch AVG loss: 0.9963724851608277\n",
      "\n",
      "Epoch: 8  train \n",
      "Loss: 0.9964  Acc: 85.0000\n",
      "granite-blackswan precision: 83.3333  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 93.3333\n",
      "granite-blackswan FPR: 6.6667  NPV: 100.0000\n",
      "granite-blackswan TP: 5.0\n",
      "granite-blackswan TN: 14.0\n",
      "granite-blackswan FP: 1.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 83.3333  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 93.3333\n",
      "marble-shadow FPR: 6.6667  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 14.0\n",
      "marble-shadow FP: 1.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 40.0000\n",
      "quartzite-oceanblue sensitivity: 40.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 83.3333\n",
      "quartzite-oceanblue TP: 2.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 83.3333  recall: 100.0000\n",
      "quartzite-patagonia sensitivity: 100.0000  specificity: 93.3333\n",
      "quartzite-patagonia FPR: 6.6667  NPV: 100.0000\n",
      "quartzite-patagonia TP: 5.0\n",
      "quartzite-patagonia TN: 14.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 8  val \n",
      "Loss: 1.0624  Acc: 58.3333\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 50.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 66.6667\n",
      "marble-shadow FPR: 33.3333  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 6.0\n",
      "marble-shadow FP: 3.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 50.0000  recall: 66.6667\n",
      "quartzite-oceanblue sensitivity: 66.6667  specificity: 77.7778\n",
      "quartzite-oceanblue FPR: 22.2222  NPV: 87.5000\n",
      "quartzite-oceanblue TP: 2.0\n",
      "quartzite-oceanblue TN: 7.0\n",
      "quartzite-oceanblue FP: 2.0\n",
      "quartzite-oceanblue FN: 1.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 66.6667\n",
      "quartzite-patagonia sensitivity: 66.6667  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 90.0000\n",
      "quartzite-patagonia TP: 2.0\n",
      "quartzite-patagonia TN: 9.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Epoch: 9     train index of 5 minibatch: 1      time used: 57.47913146018982\n",
      "minibatch AVG loss: 1.0219951629638673\n",
      "\n",
      "Epoch: 9  train \n",
      "Loss: 1.0220  Acc: 80.0000\n",
      "granite-blackswan precision: 100.0000  recall: 80.0000\n",
      "granite-blackswan sensitivity: 80.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 93.7500\n",
      "granite-blackswan TP: 4.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 1.0\n",
      "marble-shadow precision: 71.4286  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 86.6667\n",
      "marble-shadow FPR: 13.3333  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 13.0\n",
      "marble-shadow FP: 2.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 60.0000\n",
      "quartzite-oceanblue sensitivity: 60.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 88.2353\n",
      "quartzite-oceanblue TP: 3.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 2.0\n",
      "quartzite-patagonia precision: 66.6667  recall: 80.0000\n",
      "quartzite-patagonia sensitivity: 80.0000  specificity: 86.6667\n",
      "quartzite-patagonia FPR: 13.3333  NPV: 92.8571\n",
      "quartzite-patagonia TP: 4.0\n",
      "quartzite-patagonia TN: 13.0\n",
      "quartzite-patagonia FP: 2.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 9  val \n",
      "Loss: 1.0261  Acc: 58.3333\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 60.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 77.7778\n",
      "marble-shadow FPR: 22.2222  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 7.0\n",
      "marble-shadow FP: 2.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 40.0000  recall: 66.6667\n",
      "quartzite-oceanblue sensitivity: 66.6667  specificity: 66.6667\n",
      "quartzite-oceanblue FPR: 33.3333  NPV: 85.7143\n",
      "quartzite-oceanblue TP: 2.0\n",
      "quartzite-oceanblue TN: 6.0\n",
      "quartzite-oceanblue FP: 3.0\n",
      "quartzite-oceanblue FN: 1.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 66.6667\n",
      "quartzite-patagonia sensitivity: 66.6667  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 90.0000\n",
      "quartzite-patagonia TP: 2.0\n",
      "quartzite-patagonia TN: 9.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Epoch: 10     train index of 5 minibatch: 1      time used: 58.98630404472351\n",
      "minibatch AVG loss: 0.9253658652305603\n",
      "\n",
      "Epoch: 10  train \n",
      "Loss: 0.9254  Acc: 90.0000\n",
      "granite-blackswan precision: 100.0000  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 100.0000\n",
      "granite-blackswan TP: 5.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 83.3333  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 93.3333\n",
      "marble-shadow FPR: 6.6667  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 14.0\n",
      "marble-shadow FP: 1.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 80.0000\n",
      "quartzite-oceanblue sensitivity: 80.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 93.7500\n",
      "quartzite-oceanblue TP: 4.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 1.0\n",
      "quartzite-patagonia precision: 80.0000  recall: 80.0000\n",
      "quartzite-patagonia sensitivity: 80.0000  specificity: 93.3333\n",
      "quartzite-patagonia FPR: 6.6667  NPV: 93.3333\n",
      "quartzite-patagonia TP: 4.0\n",
      "quartzite-patagonia TN: 14.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 10  val \n",
      "Loss: 1.0029  Acc: 50.0000\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 60.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 77.7778\n",
      "marble-shadow FPR: 22.2222  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 7.0\n",
      "marble-shadow FP: 2.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 33.3333  recall: 66.6667\n",
      "quartzite-oceanblue sensitivity: 66.6667  specificity: 55.5556\n",
      "quartzite-oceanblue FPR: 44.4444  NPV: 83.3333\n",
      "quartzite-oceanblue TP: 2.0\n",
      "quartzite-oceanblue TN: 5.0\n",
      "quartzite-oceanblue FP: 4.0\n",
      "quartzite-oceanblue FN: 1.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 33.3333\n",
      "quartzite-patagonia sensitivity: 33.3333  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 81.8182\n",
      "quartzite-patagonia TP: 1.0\n",
      "quartzite-patagonia TN: 9.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 2.0\n",
      "\n",
      "\n",
      "\n",
      "Training complete in 8m 28s\n",
      "Best epoch idx:  8\n",
      "Best epoch train Acc: 85.000000\n",
      "Best epoch val Acc: 58.333333\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "marble-shadow precision: 50.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 66.6667\n",
      "marble-shadow FPR: 33.3333  NPV: 100.0000\n",
      "quartzite-oceanblue precision: 50.0000  recall: 66.6667\n",
      "quartzite-oceanblue sensitivity: 66.6667  specificity: 77.7778\n",
      "quartzite-oceanblue FPR: 22.2222  NPV: 87.5000\n",
      "quartzite-patagonia precision: 100.0000  recall: 66.6667\n",
      "quartzite-patagonia sensitivity: 66.6667  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 90.0000\n",
      "model trained by GPU (idx:0) has been saved at  saved_models\\CLS_ResNet101_RockModel.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "!python Train.py --model_idx ResNet101_RockModel --edge_size 384 --data_augmentation_mode 2 --batch_size 4 --lr 0.00001 --lrf 0.05 --enable_tensorboard --check_minibatch 5 --dataroot sample_datasets/warwick_CLS --model_path saved_models --draw_root runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet101 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names: ['granite-blackswan', 'marble-shadow', 'quartzite-oceanblue', 'quartzite-patagonia']\n",
      "test model outputï¼ tensor([[-0.8220,  0.0281, -0.5508, -0.4037]], grad_fn=<AddmmBackward0>)\n",
      "model is ready now!\n",
      "model loaded\n",
      "model : ResNet101_RockModel\n",
      "*********************************setting*************************************\n",
      "Namespace(model_idx='ResNet101_RockModel', MIL_Stripe=False, drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.0, cls_token_off=False, pos_embedding_off=False, att_module='SimAM', gpu_idx=0, dataroot='sample_datasets/warwick_CLS', model_path='saved_models', draw_root='runs', paint=True, enable_notify=False, enable_tensorboard=False, enable_attention_check=True, enable_visualize_check=False, data_augmentation_mode=2, num_classes=0, edge_size=384, batch_size=1, check_minibatch=5)\n",
      "Epoch: Test\n",
      "----------\n",
      "Epoch: test     test index of 5 minibatch: 1      time used: 11.460999011993408\n",
      "minibatch AVG loss: 1.0649438619613647\n",
      "model: ResNet101_RockModel  with edge_size 384 is not supported yet\n",
      "Epoch: test     test index of 5 minibatch: 2      time used: 3.31597900390625\n",
      "minibatch AVG loss: 1.0534110367298126\n",
      "model: ResNet101_RockModel  with edge_size 384 is not supported yet\n",
      "\n",
      "Epoch:  test \n",
      "Loss: 1.0536  Acc: 58.3333\n",
      "granite-blackswan precision: 100.0000  recall: 33.3333\n",
      "granite-blackswan sensitivity: 33.3333  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 81.8182\n",
      "granite-blackswan TP: 1.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 2.0\n",
      "marble-shadow precision: 60.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 77.7778\n",
      "marble-shadow FPR: 22.2222  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 7.0\n",
      "marble-shadow FP: 2.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 50.0000  recall: 100.0000\n",
      "quartzite-patagonia sensitivity: 100.0000  specificity: 66.6667\n",
      "quartzite-patagonia FPR: 33.3333  NPV: 100.0000\n",
      "quartzite-patagonia TP: 3.0\n",
      "quartzite-patagonia TN: 6.0\n",
      "quartzite-patagonia FP: 3.0\n",
      "quartzite-patagonia FN: 0.0\n",
      "\n",
      "\n",
      "Testing complete in 0m 19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "Exception ignored in: <function BaseCAM.__del__ at 0x0000022B6A395990>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\usuariolocal\\OneDrive\\Documentos\\Douglas\\Mestrado\\3 - Curso\\Meu projeto\\si_vit_ornamental_rocks\\pytorch_grad_cam\\base_cam.py\", line 191, in __del__\n",
      "    self.activations_and_grads.release()\n",
      "AttributeError: 'GradCAM' object has no attribute 'activations_and_grads'\n",
      "Exception ignored in: <function BaseCAM.__del__ at 0x0000022B6A395990>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\usuariolocal\\OneDrive\\Documentos\\Douglas\\Mestrado\\3 - Curso\\Meu projeto\\si_vit_ornamental_rocks\\pytorch_grad_cam\\base_cam.py\", line 191, in __del__\n",
      "    self.activations_and_grads.release()\n",
      "AttributeError: 'GradCAM' object has no attribute 'activations_and_grads'\n"
     ]
    }
   ],
   "source": [
    "!python Test.py --model_idx ResNet101_RockModel --edge_size 384 --data_augmentation_mode 2 --enable_attention_check --check_minibatch 5 --dataroot sample_datasets/warwick_CLS --model_path saved_models --draw_root runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vgg16 network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names: ['granite-blackswan', 'marble-shadow', 'quartzite-oceanblue', 'quartzite-patagonia']\n",
      "*********************************setting*************************************\n",
      "Namespace(model_idx='vgg16_RockModel', drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.0, cls_token_off=False, pos_embedding_off=False, att_module='SimAM', backbone_PT_off=False, gpu_idx=-1, dataroot='sample_datasets/warwick_CLS', model_path='saved_models', draw_root='runs', paint=True, enable_notify=False, enable_tensorboard=True, enable_attention_check=False, enable_visualize_check=False, enable_sam=False, augmentation_name=None, data_augmentation_mode=2, linearprobing=False, Pre_Trained_model_path=None, num_classes=0, edge_size=384, num_workers=2, batch_size=4, check_minibatch=5, num_epochs=10, intake_epochs=0, lr=1e-05, lrf=0.05, opt_name='Adam')\n",
      "we dont have more GPU idx here, try to use gpu_idx=0\n",
      "['repvgg_a0',\n",
      " 'repvgg_a1',\n",
      " 'repvgg_a2',\n",
      " 'repvgg_b0',\n",
      " 'repvgg_b1',\n",
      " 'repvgg_b1g4',\n",
      " 'repvgg_b2',\n",
      " 'repvgg_b2g4',\n",
      " 'repvgg_b3',\n",
      " 'repvgg_b3g4',\n",
      " 'repvgg_d2se',\n",
      " 'vgg11',\n",
      " 'vgg11_bn',\n",
      " 'vgg13',\n",
      " 'vgg13_bn',\n",
      " 'vgg16',\n",
      " 'vgg16_bn',\n",
      " 'vgg19',\n",
      " 'vgg19_bn']\n",
      "test model outputï¼ tensor([[-0.0602,  0.0432,  0.0212,  0.1338]], grad_fn=<AddmmBackward0>)\n",
      "model is ready now!\n",
      "GPU: 0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 384, 384]           1,792\n",
      "              ReLU-2         [-1, 64, 384, 384]               0\n",
      "            Conv2d-3         [-1, 64, 384, 384]          36,928\n",
      "              ReLU-4         [-1, 64, 384, 384]               0\n",
      "         MaxPool2d-5         [-1, 64, 192, 192]               0\n",
      "            Conv2d-6        [-1, 128, 192, 192]          73,856\n",
      "              ReLU-7        [-1, 128, 192, 192]               0\n",
      "            Conv2d-8        [-1, 128, 192, 192]         147,584\n",
      "              ReLU-9        [-1, 128, 192, 192]               0\n",
      "        MaxPool2d-10          [-1, 128, 96, 96]               0\n",
      "           Conv2d-11          [-1, 256, 96, 96]         295,168\n",
      "             ReLU-12          [-1, 256, 96, 96]               0\n",
      "           Conv2d-13          [-1, 256, 96, 96]         590,080\n",
      "             ReLU-14          [-1, 256, 96, 96]               0\n",
      "           Conv2d-15          [-1, 256, 96, 96]         590,080\n",
      "             ReLU-16          [-1, 256, 96, 96]               0\n",
      "        MaxPool2d-17          [-1, 256, 48, 48]               0\n",
      "           Conv2d-18          [-1, 512, 48, 48]       1,180,160\n",
      "             ReLU-19          [-1, 512, 48, 48]               0\n",
      "           Conv2d-20          [-1, 512, 48, 48]       2,359,808\n",
      "             ReLU-21          [-1, 512, 48, 48]               0\n",
      "           Conv2d-22          [-1, 512, 48, 48]       2,359,808\n",
      "             ReLU-23          [-1, 512, 48, 48]               0\n",
      "        MaxPool2d-24          [-1, 512, 24, 24]               0\n",
      "           Conv2d-25          [-1, 512, 24, 24]       2,359,808\n",
      "             ReLU-26          [-1, 512, 24, 24]               0\n",
      "           Conv2d-27          [-1, 512, 24, 24]       2,359,808\n",
      "             ReLU-28          [-1, 512, 24, 24]               0\n",
      "           Conv2d-29          [-1, 512, 24, 24]       2,359,808\n",
      "             ReLU-30          [-1, 512, 24, 24]               0\n",
      "        MaxPool2d-31          [-1, 512, 12, 12]               0\n",
      "           Conv2d-32           [-1, 4096, 6, 6]     102,764,544\n",
      "             ReLU-33           [-1, 4096, 6, 6]               0\n",
      "          Dropout-34           [-1, 4096, 6, 6]               0\n",
      "           Conv2d-35           [-1, 4096, 6, 6]      16,781,312\n",
      "             ReLU-36           [-1, 4096, 6, 6]               0\n",
      "          ConvMlp-37           [-1, 4096, 6, 6]               0\n",
      "AdaptiveAvgPool2d-38           [-1, 4096, 1, 1]               0\n",
      "          Flatten-39                 [-1, 4096]               0\n",
      "SelectAdaptivePool2d-40                 [-1, 4096]               0\n",
      "          Dropout-41                 [-1, 4096]               0\n",
      "           Linear-42                    [-1, 4]          16,388\n",
      "         Identity-43                    [-1, 4]               0\n",
      "   ClassifierHead-44                    [-1, 4]               0\n",
      "================================================================\n",
      "Total params: 134,276,932\n",
      "Trainable params: 134,276,932\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.69\n",
      "Forward/backward pass size (MB): 648.69\n",
      "Params size (MB): 512.23\n",
      "Estimated Total Size (MB): 1162.60\n",
      "----------------------------------------------------------------\n",
      "model : vgg16_RockModel\n",
      "no valid counterparts augmentation selected\n",
      "Epoch 1/10\n",
      "----------\n",
      "Epoch: 1     train index of 5 minibatch: 1      time used: 106.31128740310669\n",
      "minibatch AVG loss: 1.3345630884170532\n",
      "\n",
      "Epoch: 1  train \n",
      "Loss: 1.3346  Acc: 55.0000\n",
      "granite-blackswan precision: 100.0000  recall: 40.0000\n",
      "granite-blackswan sensitivity: 40.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 83.3333\n",
      "granite-blackswan TP: 2.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 40.0000  recall: 80.0000\n",
      "marble-shadow sensitivity: 80.0000  specificity: 60.0000\n",
      "marble-shadow FPR: 40.0000  NPV: 90.0000\n",
      "marble-shadow TP: 4.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 6.0\n",
      "marble-shadow FN: 1.0\n",
      "quartzite-oceanblue precision: 62.5000  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 80.0000\n",
      "quartzite-oceanblue FPR: 20.0000  NPV: 100.0000\n",
      "quartzite-oceanblue TP: 5.0\n",
      "quartzite-oceanblue TN: 12.0\n",
      "quartzite-oceanblue FP: 3.0\n",
      "quartzite-oceanblue FN: 0.0\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-patagonia TP: 0.0\n",
      "quartzite-patagonia TN: 15.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 5.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 1  val \n",
      "Loss: 1.2449  Acc: 66.6667\n",
      "granite-blackswan precision: 60.0000  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 77.7778\n",
      "granite-blackswan FPR: 22.2222  NPV: 100.0000\n",
      "granite-blackswan TP: 3.0\n",
      "granite-blackswan TN: 7.0\n",
      "granite-blackswan FP: 2.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 66.6667  recall: 66.6667\n",
      "marble-shadow sensitivity: 66.6667  specificity: 88.8889\n",
      "marble-shadow FPR: 11.1111  NPV: 88.8889\n",
      "marble-shadow TP: 2.0\n",
      "marble-shadow TN: 8.0\n",
      "marble-shadow FP: 1.0\n",
      "marble-shadow FN: 1.0\n",
      "quartzite-oceanblue precision: 66.6667  recall: 66.6667\n",
      "quartzite-oceanblue sensitivity: 66.6667  specificity: 88.8889\n",
      "quartzite-oceanblue FPR: 11.1111  NPV: 88.8889\n",
      "quartzite-oceanblue TP: 2.0\n",
      "quartzite-oceanblue TN: 8.0\n",
      "quartzite-oceanblue FP: 1.0\n",
      "quartzite-oceanblue FN: 1.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 33.3333\n",
      "quartzite-patagonia sensitivity: 33.3333  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 81.8182\n",
      "quartzite-patagonia TP: 1.0\n",
      "quartzite-patagonia TN: 9.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 2.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Epoch: 2     train index of 5 minibatch: 1      time used: 85.63803601264954\n",
      "minibatch AVG loss: 1.169236993789673\n",
      "\n",
      "Epoch: 2  train \n",
      "Loss: 1.1692  Acc: 95.0000\n",
      "granite-blackswan precision: 100.0000  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 100.0000\n",
      "granite-blackswan TP: 5.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 100.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 15.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 83.3333  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 93.3333\n",
      "quartzite-oceanblue FPR: 6.6667  NPV: 100.0000\n",
      "quartzite-oceanblue TP: 5.0\n",
      "quartzite-oceanblue TN: 14.0\n",
      "quartzite-oceanblue FP: 1.0\n",
      "quartzite-oceanblue FN: 0.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 80.0000\n",
      "quartzite-patagonia sensitivity: 80.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 93.7500\n",
      "quartzite-patagonia TP: 4.0\n",
      "quartzite-patagonia TN: 15.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 2  val \n",
      "Loss: 1.1317  Acc: 66.6667\n",
      "granite-blackswan precision: 50.0000  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 66.6667\n",
      "granite-blackswan FPR: 33.3333  NPV: 100.0000\n",
      "granite-blackswan TP: 3.0\n",
      "granite-blackswan TN: 6.0\n",
      "granite-blackswan FP: 3.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 100.0000  recall: 33.3333\n",
      "marble-shadow sensitivity: 33.3333  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 81.8182\n",
      "marble-shadow TP: 1.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 2.0\n",
      "quartzite-oceanblue precision: 75.0000  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 88.8889\n",
      "quartzite-oceanblue FPR: 11.1111  NPV: 100.0000\n",
      "quartzite-oceanblue TP: 3.0\n",
      "quartzite-oceanblue TN: 8.0\n",
      "quartzite-oceanblue FP: 1.0\n",
      "quartzite-oceanblue FN: 0.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 33.3333\n",
      "quartzite-patagonia sensitivity: 33.3333  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 81.8182\n",
      "quartzite-patagonia TP: 1.0\n",
      "quartzite-patagonia TN: 9.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 2.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Epoch: 3     train index of 5 minibatch: 1      time used: 75.71204209327698\n",
      "minibatch AVG loss: 1.03802170753479\n",
      "\n",
      "Epoch: 3  train \n",
      "Loss: 1.0380  Acc: 95.0000\n",
      "granite-blackswan precision: 100.0000  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 100.0000\n",
      "granite-blackswan TP: 5.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 100.0000  recall: 80.0000\n",
      "marble-shadow sensitivity: 80.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 93.7500\n",
      "marble-shadow TP: 4.0\n",
      "marble-shadow TN: 15.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 1.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-oceanblue TP: 5.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 0.0\n",
      "quartzite-patagonia precision: 83.3333  recall: 100.0000\n",
      "quartzite-patagonia sensitivity: 100.0000  specificity: 93.3333\n",
      "quartzite-patagonia FPR: 6.6667  NPV: 100.0000\n",
      "quartzite-patagonia TP: 5.0\n",
      "quartzite-patagonia TN: 14.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 3  val \n",
      "Loss: 1.0057  Acc: 100.0000\n",
      "granite-blackswan precision: 100.0000  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 100.0000\n",
      "granite-blackswan TP: 3.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 100.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-oceanblue TP: 3.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 0.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 100.0000\n",
      "quartzite-patagonia sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-patagonia TP: 3.0\n",
      "quartzite-patagonia TN: 9.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Epoch: 4     train index of 5 minibatch: 1      time used: 93.47978186607361\n",
      "minibatch AVG loss: 0.8475962281227112\n",
      "\n",
      "Epoch: 4  train \n",
      "Loss: 0.8476  Acc: 100.0000\n",
      "granite-blackswan precision: 100.0000  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 100.0000\n",
      "granite-blackswan TP: 5.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 100.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 15.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-oceanblue TP: 5.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 0.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 100.0000\n",
      "quartzite-patagonia sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-patagonia TP: 5.0\n",
      "quartzite-patagonia TN: 15.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 4  val \n",
      "Loss: 0.8749  Acc: 91.6667\n",
      "granite-blackswan precision: 100.0000  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 100.0000\n",
      "granite-blackswan TP: 3.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 100.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 75.0000  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 88.8889\n",
      "quartzite-oceanblue FPR: 11.1111  NPV: 100.0000\n",
      "quartzite-oceanblue TP: 3.0\n",
      "quartzite-oceanblue TN: 8.0\n",
      "quartzite-oceanblue FP: 1.0\n",
      "quartzite-oceanblue FN: 0.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 66.6667\n",
      "quartzite-patagonia sensitivity: 66.6667  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 90.0000\n",
      "quartzite-patagonia TP: 2.0\n",
      "quartzite-patagonia TN: 9.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Epoch: 5     train index of 5 minibatch: 1      time used: 83.35203886032104\n",
      "minibatch AVG loss: 0.6643729925155639\n",
      "\n",
      "Epoch: 5  train \n",
      "Loss: 0.6644  Acc: 100.0000\n",
      "granite-blackswan precision: 100.0000  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 100.0000\n",
      "granite-blackswan TP: 5.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 100.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 15.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-oceanblue TP: 5.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 0.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 100.0000\n",
      "quartzite-patagonia sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-patagonia TP: 5.0\n",
      "quartzite-patagonia TN: 15.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 5  val \n",
      "Loss: 0.7627  Acc: 91.6667\n",
      "granite-blackswan precision: 100.0000  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 100.0000\n",
      "granite-blackswan TP: 3.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 100.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 75.0000  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 88.8889\n",
      "quartzite-oceanblue FPR: 11.1111  NPV: 100.0000\n",
      "quartzite-oceanblue TP: 3.0\n",
      "quartzite-oceanblue TN: 8.0\n",
      "quartzite-oceanblue FP: 1.0\n",
      "quartzite-oceanblue FN: 0.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 66.6667\n",
      "quartzite-patagonia sensitivity: 66.6667  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 90.0000\n",
      "quartzite-patagonia TP: 2.0\n",
      "quartzite-patagonia TN: 9.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Epoch: 6     train index of 5 minibatch: 1      time used: 88.53214001655579\n",
      "minibatch AVG loss: 0.47720748782157896\n",
      "\n",
      "Epoch: 6  train \n",
      "Loss: 0.4772  Acc: 95.0000\n",
      "granite-blackswan precision: 100.0000  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 100.0000\n",
      "granite-blackswan TP: 5.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 100.0000  recall: 80.0000\n",
      "marble-shadow sensitivity: 80.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 93.7500\n",
      "marble-shadow TP: 4.0\n",
      "marble-shadow TN: 15.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 1.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-oceanblue TP: 5.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 0.0\n",
      "quartzite-patagonia precision: 83.3333  recall: 100.0000\n",
      "quartzite-patagonia sensitivity: 100.0000  specificity: 93.3333\n",
      "quartzite-patagonia FPR: 6.6667  NPV: 100.0000\n",
      "quartzite-patagonia TP: 5.0\n",
      "quartzite-patagonia TN: 14.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 6  val \n",
      "Loss: 0.6653  Acc: 100.0000\n",
      "granite-blackswan precision: 100.0000  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 100.0000\n",
      "granite-blackswan TP: 3.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 100.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-oceanblue TP: 3.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 0.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 100.0000\n",
      "quartzite-patagonia sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-patagonia TP: 3.0\n",
      "quartzite-patagonia TN: 9.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Epoch: 7     train index of 5 minibatch: 1      time used: 103.20973443984985\n",
      "minibatch AVG loss: 0.38756023347377777\n",
      "\n",
      "Epoch: 7  train \n",
      "Loss: 0.3876  Acc: 100.0000\n",
      "granite-blackswan precision: 100.0000  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 100.0000\n",
      "granite-blackswan TP: 5.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 100.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 15.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-oceanblue TP: 5.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 0.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 100.0000\n",
      "quartzite-patagonia sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-patagonia TP: 5.0\n",
      "quartzite-patagonia TN: 15.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 7  val \n",
      "Loss: 0.6060  Acc: 100.0000\n",
      "granite-blackswan precision: 100.0000  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 100.0000\n",
      "granite-blackswan TP: 3.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 100.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-oceanblue TP: 3.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 0.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 100.0000\n",
      "quartzite-patagonia sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-patagonia TP: 3.0\n",
      "quartzite-patagonia TN: 9.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Epoch: 8     train index of 5 minibatch: 1      time used: 84.42215824127197\n",
      "minibatch AVG loss: 0.3430791825056076\n",
      "\n",
      "Epoch: 8  train \n",
      "Loss: 0.3431  Acc: 100.0000\n",
      "granite-blackswan precision: 100.0000  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 100.0000\n",
      "granite-blackswan TP: 5.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 100.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 15.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-oceanblue TP: 5.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 0.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 100.0000\n",
      "quartzite-patagonia sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-patagonia TP: 5.0\n",
      "quartzite-patagonia TN: 15.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 8  val \n",
      "Loss: 0.5792  Acc: 100.0000\n",
      "granite-blackswan precision: 100.0000  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 100.0000\n",
      "granite-blackswan TP: 3.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 100.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-oceanblue TP: 3.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 0.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 100.0000\n",
      "quartzite-patagonia sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-patagonia TP: 3.0\n",
      "quartzite-patagonia TN: 9.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Epoch: 9     train index of 5 minibatch: 1      time used: 99.98512125015259\n",
      "minibatch AVG loss: 0.2912916526198387\n",
      "\n",
      "Epoch: 9  train \n",
      "Loss: 0.2913  Acc: 100.0000\n",
      "granite-blackswan precision: 100.0000  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 100.0000\n",
      "granite-blackswan TP: 5.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 100.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 100.0000\n",
      "marble-shadow TP: 5.0\n",
      "marble-shadow TN: 15.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-oceanblue TP: 5.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 0.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 100.0000\n",
      "quartzite-patagonia sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-patagonia TP: 5.0\n",
      "quartzite-patagonia TN: 15.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 9  val \n",
      "Loss: 0.5669  Acc: 91.6667\n",
      "granite-blackswan precision: 100.0000  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 100.0000\n",
      "granite-blackswan TP: 3.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 100.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 75.0000  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 88.8889\n",
      "quartzite-oceanblue FPR: 11.1111  NPV: 100.0000\n",
      "quartzite-oceanblue TP: 3.0\n",
      "quartzite-oceanblue TN: 8.0\n",
      "quartzite-oceanblue FP: 1.0\n",
      "quartzite-oceanblue FN: 0.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 66.6667\n",
      "quartzite-patagonia sensitivity: 66.6667  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 90.0000\n",
      "quartzite-patagonia TP: 2.0\n",
      "quartzite-patagonia TN: 9.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Epoch: 10     train index of 5 minibatch: 1      time used: 87.19324612617493\n",
      "minibatch AVG loss: 0.29628925770521164\n",
      "\n",
      "Epoch: 10  train \n",
      "Loss: 0.2963  Acc: 95.0000\n",
      "granite-blackswan precision: 100.0000  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 100.0000\n",
      "granite-blackswan TP: 5.0\n",
      "granite-blackswan TN: 15.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 100.0000  recall: 80.0000\n",
      "marble-shadow sensitivity: 80.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 93.7500\n",
      "marble-shadow TP: 4.0\n",
      "marble-shadow TN: 15.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 1.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-oceanblue TP: 5.0\n",
      "quartzite-oceanblue TN: 15.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 0.0\n",
      "quartzite-patagonia precision: 83.3333  recall: 100.0000\n",
      "quartzite-patagonia sensitivity: 100.0000  specificity: 93.3333\n",
      "quartzite-patagonia FPR: 6.6667  NPV: 100.0000\n",
      "quartzite-patagonia TP: 5.0\n",
      "quartzite-patagonia TN: 14.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 0.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 10  val \n",
      "Loss: 0.5609  Acc: 91.6667\n",
      "granite-blackswan precision: 100.0000  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 100.0000\n",
      "granite-blackswan TP: 3.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 100.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 75.0000  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 88.8889\n",
      "quartzite-oceanblue FPR: 11.1111  NPV: 100.0000\n",
      "quartzite-oceanblue TP: 3.0\n",
      "quartzite-oceanblue TN: 8.0\n",
      "quartzite-oceanblue FP: 1.0\n",
      "quartzite-oceanblue FN: 0.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 66.6667\n",
      "quartzite-patagonia sensitivity: 66.6667  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 90.0000\n",
      "quartzite-patagonia TP: 2.0\n",
      "quartzite-patagonia TN: 9.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Training complete in 19m 19s\n",
      "Best epoch idx:  8\n",
      "Best epoch train Acc: 100.000000\n",
      "Best epoch val Acc: 100.000000\n",
      "granite-blackswan precision: 100.0000  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 100.0000\n",
      "marble-shadow precision: 100.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-oceanblue precision: 100.0000  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-patagonia precision: 100.0000  recall: 100.0000\n",
      "quartzite-patagonia sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 100.0000\n",
      "model trained by GPU (idx:0) has been saved at  saved_models\\CLS_vgg16_RockModel.pth\n"
     ]
    }
   ],
   "source": [
    "!python Train.py --model_idx vgg16_RockModel --edge_size 384 --data_augmentation_mode 2 --batch_size 4 --lr 0.00001 --lrf 0.05 --enable_tensorboard --check_minibatch 5 --dataroot sample_datasets/warwick_CLS --model_path saved_models --draw_root runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vgg16 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names: ['granite-blackswan', 'marble-shadow', 'quartzite-oceanblue', 'quartzite-patagonia']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function BaseCAM.__del__ at 0x000002169862A3B0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\usuariolocal\\OneDrive\\Documentos\\Douglas\\Mestrado\\3 - Curso\\Meu projeto\\si_vit_ornamental_rocks\\pytorch_grad_cam\\base_cam.py\", line 191, in __del__\n",
      "    self.activations_and_grads.release()\n",
      "AttributeError: 'GradCAM' object has no attribute 'activations_and_grads'\n",
      "Exception ignored in: <function BaseCAM.__del__ at 0x000002169862A3B0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\usuariolocal\\OneDrive\\Documentos\\Douglas\\Mestrado\\3 - Curso\\Meu projeto\\si_vit_ornamental_rocks\\pytorch_grad_cam\\base_cam.py\", line 191, in __del__\n",
      "    self.activations_and_grads.release()\n",
      "AttributeError: 'GradCAM' object has no attribute 'activations_and_grads'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['repvgg_a0',\n",
      " 'repvgg_a1',\n",
      " 'repvgg_a2',\n",
      " 'repvgg_b0',\n",
      " 'repvgg_b1',\n",
      " 'repvgg_b1g4',\n",
      " 'repvgg_b2',\n",
      " 'repvgg_b2g4',\n",
      " 'repvgg_b3',\n",
      " 'repvgg_b3g4',\n",
      " 'repvgg_d2se',\n",
      " 'vgg11',\n",
      " 'vgg11_bn',\n",
      " 'vgg13',\n",
      " 'vgg13_bn',\n",
      " 'vgg16',\n",
      " 'vgg16_bn',\n",
      " 'vgg19',\n",
      " 'vgg19_bn']\n",
      "test model outputï¼ tensor([[ 0.0047,  0.0059,  0.0007, -0.0431]], grad_fn=<AddmmBackward0>)\n",
      "model is ready now!\n",
      "model loaded\n",
      "model : vgg16_RockModel\n",
      "*********************************setting*************************************\n",
      "Namespace(model_idx='vgg16_RockModel', MIL_Stripe=False, drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.0, cls_token_off=False, pos_embedding_off=False, att_module='SimAM', gpu_idx=0, dataroot='sample_datasets/warwick_CLS', model_path='saved_models', draw_root='runs', paint=True, enable_notify=False, enable_tensorboard=False, enable_attention_check=True, enable_visualize_check=False, data_augmentation_mode=2, num_classes=0, edge_size=384, batch_size=1, check_minibatch=5)\n",
      "Epoch: Test\n",
      "----------\n",
      "Epoch: test     test index of 5 minibatch: 1      time used: 10.991987466812134\n",
      "minibatch AVG loss: 0.7159892797470093\n",
      "model: vgg16_RockModel  with edge_size 384 is not supported yet\n",
      "Epoch: test     test index of 5 minibatch: 2      time used: 6.331969499588013\n",
      "minibatch AVG loss: 0.43181865811347964\n",
      "model: vgg16_RockModel  with edge_size 384 is not supported yet\n",
      "\n",
      "Epoch:  test \n",
      "Loss: 0.5427  Acc: 100.0000\n",
      "granite-blackswan precision: 100.0000  recall: 100.0000\n",
      "granite-blackswan sensitivity: 100.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 100.0000\n",
      "granite-blackswan TP: 3.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 0.0\n",
      "marble-shadow precision: 100.0000  recall: 100.0000\n",
      "marble-shadow sensitivity: 100.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 100.0000\n",
      "marble-shadow TP: 3.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 0.0\n",
      "quartzite-oceanblue precision: 100.0000  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-oceanblue TP: 3.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 0.0\n",
      "quartzite-patagonia precision: 100.0000  recall: 100.0000\n",
      "quartzite-patagonia sensitivity: 100.0000  specificity: 100.0000\n",
      "quartzite-patagonia FPR: 0.0000  NPV: 100.0000\n",
      "quartzite-patagonia TP: 3.0\n",
      "quartzite-patagonia TN: 9.0\n",
      "quartzite-patagonia FP: 0.0\n",
      "quartzite-patagonia FN: 0.0\n",
      "\n",
      "\n",
      "Testing complete in 0m 26s\n"
     ]
    }
   ],
   "source": [
    "!python Test.py --model_idx vgg16_RockModel --edge_size 384 --data_augmentation_mode 2 --enable_attention_check --check_minibatch 5 --dataroot sample_datasets/warwick_CLS --model_path saved_models --draw_root runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vgg19 network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python Train.py --model_idx vgg19_RockModel --edge_size 384 --data_augmentation_mode 2 --batch_size 4 --lr 0.00001 --lrf 0.05 --enable_tensorboard --check_minibatch 5 --dataroot sample_datasets/warwick_CLS --model_path saved_models --draw_root runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vgg19 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names: ['granite-blackswan', 'marble-shadow', 'quartzite-oceanblue', 'quartzite-patagonia']\n",
      "['repvgg_a0',\n",
      " 'repvgg_a1',\n",
      " 'repvgg_a2',\n",
      " 'repvgg_b0',\n",
      " 'repvgg_b1',\n",
      " 'repvgg_b1g4',\n",
      " 'repvgg_b2',\n",
      " 'repvgg_b2g4',\n",
      " 'repvgg_b3',\n",
      " 'repvgg_b3g4',\n",
      " 'repvgg_d2se',\n",
      " 'vgg11',\n",
      " 'vgg11_bn',\n",
      " 'vgg13',\n",
      " 'vgg13_bn',\n",
      " 'vgg16',\n",
      " 'vgg16_bn',\n",
      " 'vgg19',\n",
      " 'vgg19_bn']\n",
      "test model outputï¼ tensor([[ 0.0412, -0.0521, -0.0548,  0.0115]], grad_fn=<AddmmBackward0>)\n",
      "model is ready now!\n",
      "model loaded\n",
      "model : vgg19_RockModel\n",
      "*********************************setting*************************************\n",
      "Namespace(model_idx='vgg19_RockModel', MIL_Stripe=False, drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.0, cls_token_off=False, pos_embedding_off=False, att_module='SimAM', gpu_idx=0, dataroot='sample_datasets/warwick_CLS', model_path='saved_models', draw_root='runs', paint=True, enable_notify=False, enable_tensorboard=False, enable_attention_check=True, enable_visualize_check=False, data_augmentation_mode=2, num_classes=0, edge_size=384, batch_size=1, check_minibatch=5)\n",
      "Epoch: Test\n",
      "----------\n",
      "Epoch: test     test index of 5 minibatch: 1      time used: 9.244736909866333\n",
      "minibatch AVG loss: 1.300705909729004\n",
      "model: vgg19_RockModel  with edge_size 384 is not supported yet\n",
      "Epoch: test     test index of 5 minibatch: 2      time used: 5.850266695022583\n",
      "minibatch AVG loss: 1.2504781007766723\n",
      "model: vgg19_RockModel  with edge_size 384 is not supported yet\n",
      "\n",
      "Epoch:  test \n",
      "Loss: 1.2361  Acc: 41.6667\n",
      "granite-blackswan precision: 50.0000  recall: 66.6667\n",
      "granite-blackswan sensitivity: 66.6667  specificity: 77.7778\n",
      "granite-blackswan FPR: 22.2222  NPV: 87.5000\n",
      "granite-blackswan TP: 2.0\n",
      "granite-blackswan TN: 7.0\n",
      "granite-blackswan FP: 2.0\n",
      "granite-blackswan FN: 1.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 75.0000\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 3.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 100.0000\n",
      "quartzite-oceanblue FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 9.0\n",
      "quartzite-oceanblue FP: 0.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 37.5000  recall: 100.0000\n",
      "quartzite-patagonia sensitivity: 100.0000  specificity: 44.4444\n",
      "quartzite-patagonia FPR: 55.5556  NPV: 100.0000\n",
      "quartzite-patagonia TP: 3.0\n",
      "quartzite-patagonia TN: 4.0\n",
      "quartzite-patagonia FP: 5.0\n",
      "quartzite-patagonia FN: 0.0\n",
      "\n",
      "\n",
      "Testing complete in 0m 21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function BaseCAM.__del__ at 0x000002360F76A3B0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\usuariolocal\\OneDrive\\Documentos\\Douglas\\Mestrado\\3 - Curso\\Meu projeto\\si_vit_ornamental_rocks\\pytorch_grad_cam\\base_cam.py\", line 191, in __del__\n",
      "    self.activations_and_grads.release()\n",
      "AttributeError: 'GradCAM' object has no attribute 'activations_and_grads'\n",
      "Exception ignored in: <function BaseCAM.__del__ at 0x000002360F76A3B0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\usuariolocal\\OneDrive\\Documentos\\Douglas\\Mestrado\\3 - Curso\\Meu projeto\\si_vit_ornamental_rocks\\pytorch_grad_cam\\base_cam.py\", line 191, in __del__\n",
      "    self.activations_and_grads.release()\n",
      "AttributeError: 'GradCAM' object has no attribute 'activations_and_grads'\n"
     ]
    }
   ],
   "source": [
    "!python Test.py --model_idx vgg19_RockModel --edge_size 384 --data_augmentation_mode 2 --enable_attention_check --check_minibatch 5 --dataroot sample_datasets/warwick_CLS --model_path saved_models --draw_root runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crossformer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names: ['granite-blackswan', 'marble-shadow', 'quartzite-oceanblue', 'quartzite-patagonia']\n",
      "*********************************setting*************************************\n",
      "Namespace(model_idx='cross_former_RockModel', drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.0, cls_token_off=False, pos_embedding_off=False, att_module='SimAM', backbone_PT_off=False, gpu_idx=-1, dataroot='sample_datasets/warwick_CLS', model_path='saved_models', draw_root='runs', paint=True, enable_notify=False, enable_tensorboard=True, enable_attention_check=False, enable_visualize_check=False, enable_sam=False, augmentation_name=None, data_augmentation_mode=2, linearprobing=False, Pre_Trained_model_path=None, num_classes=0, edge_size=224, num_workers=2, batch_size=4, check_minibatch=5, num_epochs=2, intake_epochs=0, lr=1e-05, lrf=0.05, opt_name='Adam')\n",
      "we dont have more GPU idx here, try to use gpu_idx=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\usuariolocal\\OneDrive\\Documentos\\Douglas\\Mestrado\\3 - Curso\\Meu projeto\\si_vit_ornamental_rocks\\Train.py\", line 807, in <module>\n",
      "    main(args)\n",
      "  File \"c:\\Users\\usuariolocal\\OneDrive\\Documentos\\Douglas\\Mestrado\\3 - Curso\\Meu projeto\\si_vit_ornamental_rocks\\Train.py\", line 624, in main\n",
      "    model = get_model(num_classes, edge_size, model_idx, drop_rate, attn_drop_rate, drop_path_rate,\n",
      "  File \"c:\\Users\\usuariolocal\\OneDrive\\Documentos\\Douglas\\Mestrado\\3 - Curso\\Meu projeto\\si_vit_ornamental_rocks\\Models\\getmodel.py\", line 272, in get_model\n",
      "    backbone.load_state_dict(torch.load(save_model_path)['model'], False)\n",
      "  File \"c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torch\\serialization.py\", line 998, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torch\\serialization.py\", line 445, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torch\\serialization.py\", line 426, in __init__\n",
      "    super().__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '../saved_models/crossformer-b.pth'\n"
     ]
    }
   ],
   "source": [
    "!python Train.py --model_idx cross_former_RockModel --edge_size 224 --data_augmentation_mode 2 --batch_size 4 --lr 0.00001 --lrf 0.05 --enable_tensorboard --check_minibatch 5 --dataroot sample_datasets/warwick_CLS --model_path saved_models --draw_root runs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crossformer test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names: ['granite-blackswan', 'marble-shadow', 'quartzite-oceanblue', 'quartzite-patagonia']\n",
      "test model outputï¼ tensor([[ 0.1493, -0.0378, -0.1599,  0.2368]], grad_fn=<AddmmBackward0>)\n",
      "model is ready now!\n",
      "model loading erro!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "!python Test.py --model_idx cross_former_RockModel --edge_size 224 --data_augmentation_mode 2 --enable_attention_check --check_minibatch 5 --dataroot sample_datasets/warwick_CLS --model_path saved_models --draw_root runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visformer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names: ['granite-blackswan', 'marble-shadow', 'quartzite-oceanblue', 'quartzite-patagonia']\n",
      "*********************************setting*************************************\n",
      "Namespace(model_idx='visformer_RockModel', drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.0, cls_token_off=False, pos_embedding_off=False, att_module='SimAM', backbone_PT_off=False, gpu_idx=-1, dataroot='sample_datasets/warwick_CLS', model_path='saved_models', draw_root='runs', paint=True, enable_notify=False, enable_tensorboard=True, enable_attention_check=False, enable_visualize_check=False, enable_sam=False, augmentation_name=None, data_augmentation_mode=2, linearprobing=False, Pre_Trained_model_path=None, num_classes=0, edge_size=224, num_workers=2, batch_size=4, check_minibatch=5, num_epochs=2, intake_epochs=0, lr=1e-05, lrf=0.05, opt_name='Adam')\n",
      "we dont have more GPU idx here, try to use gpu_idx=0\n",
      "['visformer_small', 'visformer_tiny']\n",
      "test model outputï¼ tensor([[ 0.0187,  0.0043, -0.0024, -0.0241]], grad_fn=<AddmmBackward0>)\n",
      "model is ready now!\n",
      "GPU: 0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]           4,704\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "              ReLU-3         [-1, 32, 112, 112]               0\n",
      "            Conv2d-4          [-1, 192, 28, 28]          98,496\n",
      "       BatchNorm2d-5          [-1, 192, 28, 28]             384\n",
      "        PatchEmbed-6          [-1, 192, 28, 28]               0\n",
      "           Dropout-7          [-1, 192, 28, 28]               0\n",
      "       BatchNorm2d-8          [-1, 192, 28, 28]             384\n",
      "            Conv2d-9          [-1, 384, 28, 28]          73,728\n",
      "             GELU-10          [-1, 384, 28, 28]               0\n",
      "          Dropout-11          [-1, 384, 28, 28]               0\n",
      "           Conv2d-12          [-1, 384, 28, 28]         165,888\n",
      "             GELU-13          [-1, 384, 28, 28]               0\n",
      "           Conv2d-14          [-1, 192, 28, 28]          73,728\n",
      "          Dropout-15          [-1, 192, 28, 28]               0\n",
      "       SpatialMlp-16          [-1, 192, 28, 28]               0\n",
      "         Identity-17          [-1, 192, 28, 28]               0\n",
      "            Block-18          [-1, 192, 28, 28]               0\n",
      "      BatchNorm2d-19          [-1, 192, 28, 28]             384\n",
      "           Conv2d-20          [-1, 384, 28, 28]          73,728\n",
      "             GELU-21          [-1, 384, 28, 28]               0\n",
      "          Dropout-22          [-1, 384, 28, 28]               0\n",
      "           Conv2d-23          [-1, 384, 28, 28]         165,888\n",
      "             GELU-24          [-1, 384, 28, 28]               0\n",
      "           Conv2d-25          [-1, 192, 28, 28]          73,728\n",
      "          Dropout-26          [-1, 192, 28, 28]               0\n",
      "       SpatialMlp-27          [-1, 192, 28, 28]               0\n",
      "         Identity-28          [-1, 192, 28, 28]               0\n",
      "            Block-29          [-1, 192, 28, 28]               0\n",
      "      BatchNorm2d-30          [-1, 192, 28, 28]             384\n",
      "           Conv2d-31          [-1, 384, 28, 28]          73,728\n",
      "             GELU-32          [-1, 384, 28, 28]               0\n",
      "          Dropout-33          [-1, 384, 28, 28]               0\n",
      "           Conv2d-34          [-1, 384, 28, 28]         165,888\n",
      "             GELU-35          [-1, 384, 28, 28]               0\n",
      "           Conv2d-36          [-1, 192, 28, 28]          73,728\n",
      "          Dropout-37          [-1, 192, 28, 28]               0\n",
      "       SpatialMlp-38          [-1, 192, 28, 28]               0\n",
      "         Identity-39          [-1, 192, 28, 28]               0\n",
      "            Block-40          [-1, 192, 28, 28]               0\n",
      "      BatchNorm2d-41          [-1, 192, 28, 28]             384\n",
      "           Conv2d-42          [-1, 384, 28, 28]          73,728\n",
      "             GELU-43          [-1, 384, 28, 28]               0\n",
      "          Dropout-44          [-1, 384, 28, 28]               0\n",
      "           Conv2d-45          [-1, 384, 28, 28]         165,888\n",
      "             GELU-46          [-1, 384, 28, 28]               0\n",
      "           Conv2d-47          [-1, 192, 28, 28]          73,728\n",
      "          Dropout-48          [-1, 192, 28, 28]               0\n",
      "       SpatialMlp-49          [-1, 192, 28, 28]               0\n",
      "         Identity-50          [-1, 192, 28, 28]               0\n",
      "            Block-51          [-1, 192, 28, 28]               0\n",
      "      BatchNorm2d-52          [-1, 192, 28, 28]             384\n",
      "           Conv2d-53          [-1, 384, 28, 28]          73,728\n",
      "             GELU-54          [-1, 384, 28, 28]               0\n",
      "          Dropout-55          [-1, 384, 28, 28]               0\n",
      "           Conv2d-56          [-1, 384, 28, 28]         165,888\n",
      "             GELU-57          [-1, 384, 28, 28]               0\n",
      "           Conv2d-58          [-1, 192, 28, 28]          73,728\n",
      "          Dropout-59          [-1, 192, 28, 28]               0\n",
      "       SpatialMlp-60          [-1, 192, 28, 28]               0\n",
      "         Identity-61          [-1, 192, 28, 28]               0\n",
      "            Block-62          [-1, 192, 28, 28]               0\n",
      "      BatchNorm2d-63          [-1, 192, 28, 28]             384\n",
      "           Conv2d-64          [-1, 384, 28, 28]          73,728\n",
      "             GELU-65          [-1, 384, 28, 28]               0\n",
      "          Dropout-66          [-1, 384, 28, 28]               0\n",
      "           Conv2d-67          [-1, 384, 28, 28]         165,888\n",
      "             GELU-68          [-1, 384, 28, 28]               0\n",
      "           Conv2d-69          [-1, 192, 28, 28]          73,728\n",
      "          Dropout-70          [-1, 192, 28, 28]               0\n",
      "       SpatialMlp-71          [-1, 192, 28, 28]               0\n",
      "         Identity-72          [-1, 192, 28, 28]               0\n",
      "            Block-73          [-1, 192, 28, 28]               0\n",
      "      BatchNorm2d-74          [-1, 192, 28, 28]             384\n",
      "           Conv2d-75          [-1, 384, 28, 28]          73,728\n",
      "             GELU-76          [-1, 384, 28, 28]               0\n",
      "          Dropout-77          [-1, 384, 28, 28]               0\n",
      "           Conv2d-78          [-1, 384, 28, 28]         165,888\n",
      "             GELU-79          [-1, 384, 28, 28]               0\n",
      "           Conv2d-80          [-1, 192, 28, 28]          73,728\n",
      "          Dropout-81          [-1, 192, 28, 28]               0\n",
      "       SpatialMlp-82          [-1, 192, 28, 28]               0\n",
      "         Identity-83          [-1, 192, 28, 28]               0\n",
      "            Block-84          [-1, 192, 28, 28]               0\n",
      "           Conv2d-85          [-1, 384, 14, 14]         295,296\n",
      "      BatchNorm2d-86          [-1, 384, 14, 14]             768\n",
      "       PatchEmbed-87          [-1, 384, 14, 14]               0\n",
      "          Dropout-88          [-1, 384, 14, 14]               0\n",
      "      BatchNorm2d-89          [-1, 384, 14, 14]             768\n",
      "           Conv2d-90         [-1, 1152, 14, 14]         442,368\n",
      "          Dropout-91          [-1, 6, 196, 196]               0\n",
      "           Conv2d-92          [-1, 384, 14, 14]         147,456\n",
      "          Dropout-93          [-1, 384, 14, 14]               0\n",
      "        Attention-94          [-1, 384, 14, 14]               0\n",
      "         Identity-95          [-1, 384, 14, 14]               0\n",
      "      BatchNorm2d-96          [-1, 384, 14, 14]             768\n",
      "           Conv2d-97         [-1, 1536, 14, 14]         589,824\n",
      "             GELU-98         [-1, 1536, 14, 14]               0\n",
      "          Dropout-99         [-1, 1536, 14, 14]               0\n",
      "          Conv2d-100          [-1, 384, 14, 14]         589,824\n",
      "         Dropout-101          [-1, 384, 14, 14]               0\n",
      "      SpatialMlp-102          [-1, 384, 14, 14]               0\n",
      "        Identity-103          [-1, 384, 14, 14]               0\n",
      "           Block-104          [-1, 384, 14, 14]               0\n",
      "     BatchNorm2d-105          [-1, 384, 14, 14]             768\n",
      "          Conv2d-106         [-1, 1152, 14, 14]         442,368\n",
      "         Dropout-107          [-1, 6, 196, 196]               0\n",
      "          Conv2d-108          [-1, 384, 14, 14]         147,456\n",
      "         Dropout-109          [-1, 384, 14, 14]               0\n",
      "       Attention-110          [-1, 384, 14, 14]               0\n",
      "        Identity-111          [-1, 384, 14, 14]               0\n",
      "     BatchNorm2d-112          [-1, 384, 14, 14]             768\n",
      "          Conv2d-113         [-1, 1536, 14, 14]         589,824\n",
      "            GELU-114         [-1, 1536, 14, 14]               0\n",
      "         Dropout-115         [-1, 1536, 14, 14]               0\n",
      "          Conv2d-116          [-1, 384, 14, 14]         589,824\n",
      "         Dropout-117          [-1, 384, 14, 14]               0\n",
      "      SpatialMlp-118          [-1, 384, 14, 14]               0\n",
      "        Identity-119          [-1, 384, 14, 14]               0\n",
      "           Block-120          [-1, 384, 14, 14]               0\n",
      "     BatchNorm2d-121          [-1, 384, 14, 14]             768\n",
      "          Conv2d-122         [-1, 1152, 14, 14]         442,368\n",
      "         Dropout-123          [-1, 6, 196, 196]               0\n",
      "          Conv2d-124          [-1, 384, 14, 14]         147,456\n",
      "         Dropout-125          [-1, 384, 14, 14]               0\n",
      "       Attention-126          [-1, 384, 14, 14]               0\n",
      "        Identity-127          [-1, 384, 14, 14]               0\n",
      "     BatchNorm2d-128          [-1, 384, 14, 14]             768\n",
      "          Conv2d-129         [-1, 1536, 14, 14]         589,824\n",
      "            GELU-130         [-1, 1536, 14, 14]               0\n",
      "         Dropout-131         [-1, 1536, 14, 14]               0\n",
      "          Conv2d-132          [-1, 384, 14, 14]         589,824\n",
      "         Dropout-133          [-1, 384, 14, 14]               0\n",
      "      SpatialMlp-134          [-1, 384, 14, 14]               0\n",
      "        Identity-135          [-1, 384, 14, 14]               0\n",
      "           Block-136          [-1, 384, 14, 14]               0\n",
      "     BatchNorm2d-137          [-1, 384, 14, 14]             768\n",
      "          Conv2d-138         [-1, 1152, 14, 14]         442,368\n",
      "         Dropout-139          [-1, 6, 196, 196]               0\n",
      "          Conv2d-140          [-1, 384, 14, 14]         147,456\n",
      "         Dropout-141          [-1, 384, 14, 14]               0\n",
      "       Attention-142          [-1, 384, 14, 14]               0\n",
      "        Identity-143          [-1, 384, 14, 14]               0\n",
      "     BatchNorm2d-144          [-1, 384, 14, 14]             768\n",
      "          Conv2d-145         [-1, 1536, 14, 14]         589,824\n",
      "            GELU-146         [-1, 1536, 14, 14]               0\n",
      "         Dropout-147         [-1, 1536, 14, 14]               0\n",
      "          Conv2d-148          [-1, 384, 14, 14]         589,824\n",
      "         Dropout-149          [-1, 384, 14, 14]               0\n",
      "      SpatialMlp-150          [-1, 384, 14, 14]               0\n",
      "        Identity-151          [-1, 384, 14, 14]               0\n",
      "           Block-152          [-1, 384, 14, 14]               0\n",
      "          Conv2d-153            [-1, 768, 7, 7]       1,180,416\n",
      "     BatchNorm2d-154            [-1, 768, 7, 7]           1,536\n",
      "      PatchEmbed-155            [-1, 768, 7, 7]               0\n",
      "         Dropout-156            [-1, 768, 7, 7]               0\n",
      "     BatchNorm2d-157            [-1, 768, 7, 7]           1,536\n",
      "          Conv2d-158           [-1, 2304, 7, 7]       1,769,472\n",
      "         Dropout-159            [-1, 6, 49, 49]               0\n",
      "          Conv2d-160            [-1, 768, 7, 7]         589,824\n",
      "         Dropout-161            [-1, 768, 7, 7]               0\n",
      "       Attention-162            [-1, 768, 7, 7]               0\n",
      "        Identity-163            [-1, 768, 7, 7]               0\n",
      "     BatchNorm2d-164            [-1, 768, 7, 7]           1,536\n",
      "          Conv2d-165           [-1, 3072, 7, 7]       2,359,296\n",
      "            GELU-166           [-1, 3072, 7, 7]               0\n",
      "         Dropout-167           [-1, 3072, 7, 7]               0\n",
      "          Conv2d-168            [-1, 768, 7, 7]       2,359,296\n",
      "         Dropout-169            [-1, 768, 7, 7]               0\n",
      "      SpatialMlp-170            [-1, 768, 7, 7]               0\n",
      "        Identity-171            [-1, 768, 7, 7]               0\n",
      "           Block-172            [-1, 768, 7, 7]               0\n",
      "     BatchNorm2d-173            [-1, 768, 7, 7]           1,536\n",
      "          Conv2d-174           [-1, 2304, 7, 7]       1,769,472\n",
      "         Dropout-175            [-1, 6, 49, 49]               0\n",
      "          Conv2d-176            [-1, 768, 7, 7]         589,824\n",
      "         Dropout-177            [-1, 768, 7, 7]               0\n",
      "       Attention-178            [-1, 768, 7, 7]               0\n",
      "        Identity-179            [-1, 768, 7, 7]               0\n",
      "     BatchNorm2d-180            [-1, 768, 7, 7]           1,536\n",
      "          Conv2d-181           [-1, 3072, 7, 7]       2,359,296\n",
      "            GELU-182           [-1, 3072, 7, 7]               0\n",
      "         Dropout-183           [-1, 3072, 7, 7]               0\n",
      "          Conv2d-184            [-1, 768, 7, 7]       2,359,296\n",
      "         Dropout-185            [-1, 768, 7, 7]               0\n",
      "      SpatialMlp-186            [-1, 768, 7, 7]               0\n",
      "        Identity-187            [-1, 768, 7, 7]               0\n",
      "           Block-188            [-1, 768, 7, 7]               0\n",
      "     BatchNorm2d-189            [-1, 768, 7, 7]           1,536\n",
      "          Conv2d-190           [-1, 2304, 7, 7]       1,769,472\n",
      "         Dropout-191            [-1, 6, 49, 49]               0\n",
      "          Conv2d-192            [-1, 768, 7, 7]         589,824\n",
      "         Dropout-193            [-1, 768, 7, 7]               0\n",
      "       Attention-194            [-1, 768, 7, 7]               0\n",
      "        Identity-195            [-1, 768, 7, 7]               0\n",
      "     BatchNorm2d-196            [-1, 768, 7, 7]           1,536\n",
      "          Conv2d-197           [-1, 3072, 7, 7]       2,359,296\n",
      "            GELU-198           [-1, 3072, 7, 7]               0\n",
      "         Dropout-199           [-1, 3072, 7, 7]               0\n",
      "          Conv2d-200            [-1, 768, 7, 7]       2,359,296\n",
      "         Dropout-201            [-1, 768, 7, 7]               0\n",
      "      SpatialMlp-202            [-1, 768, 7, 7]               0\n",
      "        Identity-203            [-1, 768, 7, 7]               0\n",
      "           Block-204            [-1, 768, 7, 7]               0\n",
      "     BatchNorm2d-205            [-1, 768, 7, 7]           1,536\n",
      "          Conv2d-206           [-1, 2304, 7, 7]       1,769,472\n",
      "         Dropout-207            [-1, 6, 49, 49]               0\n",
      "          Conv2d-208            [-1, 768, 7, 7]         589,824\n",
      "         Dropout-209            [-1, 768, 7, 7]               0\n",
      "       Attention-210            [-1, 768, 7, 7]               0\n",
      "        Identity-211            [-1, 768, 7, 7]               0\n",
      "     BatchNorm2d-212            [-1, 768, 7, 7]           1,536\n",
      "          Conv2d-213           [-1, 3072, 7, 7]       2,359,296\n",
      "            GELU-214           [-1, 3072, 7, 7]               0\n",
      "         Dropout-215           [-1, 3072, 7, 7]               0\n",
      "          Conv2d-216            [-1, 768, 7, 7]       2,359,296\n",
      "         Dropout-217            [-1, 768, 7, 7]               0\n",
      "      SpatialMlp-218            [-1, 768, 7, 7]               0\n",
      "        Identity-219            [-1, 768, 7, 7]               0\n",
      "           Block-220            [-1, 768, 7, 7]               0\n",
      "     BatchNorm2d-221            [-1, 768, 7, 7]           1,536\n",
      "AdaptiveAvgPool2d-222            [-1, 768, 1, 1]               0\n",
      "         Flatten-223                  [-1, 768]               0\n",
      "SelectAdaptivePool2d-224                  [-1, 768]               0\n",
      "         Dropout-225                  [-1, 768]               0\n",
      "          Linear-226                    [-1, 4]           3,076\n",
      "================================================================\n",
      "Total params: 39,190,244\n",
      "Trainable params: 39,190,244\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 243.21\n",
      "Params size (MB): 149.50\n",
      "Estimated Total Size (MB): 393.29\n",
      "----------------------------------------------------------------\n",
      "model : visformer_RockModel\n",
      "no valid counterparts augmentation selected\n",
      "Epoch 1/2\n",
      "----------\n",
      "Epoch: 1     train index of 5 minibatch: 1      time used: 13.891564846038818\n",
      "minibatch AVG loss: 1.4974513292312621\n",
      "\n",
      "Epoch: 1  train \n",
      "Loss: 1.4975  Acc: 20.0000\n",
      "granite-blackswan precision: 57.1429  recall: 80.0000\n",
      "granite-blackswan sensitivity: 80.0000  specificity: 80.0000\n",
      "granite-blackswan FPR: 20.0000  NPV: 92.3077\n",
      "granite-blackswan TP: 4.0\n",
      "granite-blackswan TN: 12.0\n",
      "granite-blackswan FP: 3.0\n",
      "granite-blackswan FN: 1.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 60.0000\n",
      "marble-shadow FPR: 40.0000  NPV: 64.2857\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 6.0\n",
      "marble-shadow FN: 5.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 73.3333\n",
      "quartzite-oceanblue FPR: 26.6667  NPV: 68.7500\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 11.0\n",
      "quartzite-oceanblue FP: 4.0\n",
      "quartzite-oceanblue FN: 5.0\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 80.0000\n",
      "quartzite-patagonia FPR: 20.0000  NPV: 70.5882\n",
      "quartzite-patagonia TP: 0.0\n",
      "quartzite-patagonia TN: 12.0\n",
      "quartzite-patagonia FP: 3.0\n",
      "quartzite-patagonia FN: 5.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 1  val \n",
      "Loss: 1.6696  Acc: 16.6667\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 88.8889\n",
      "marble-shadow FPR: 11.1111  NPV: 72.7273\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 8.0\n",
      "marble-shadow FP: 1.0\n",
      "marble-shadow FN: 3.0\n",
      "quartzite-oceanblue precision: 20.0000  recall: 66.6667\n",
      "quartzite-oceanblue sensitivity: 66.6667  specificity: 11.1111\n",
      "quartzite-oceanblue FPR: 88.8889  NPV: 50.0000\n",
      "quartzite-oceanblue TP: 2.0\n",
      "quartzite-oceanblue TN: 1.0\n",
      "quartzite-oceanblue FP: 8.0\n",
      "quartzite-oceanblue FN: 1.0\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 88.8889\n",
      "quartzite-patagonia FPR: 11.1111  NPV: 72.7273\n",
      "quartzite-patagonia TP: 0.0\n",
      "quartzite-patagonia TN: 8.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 3.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch 2/2\n",
      "----------\n",
      "Epoch: 2     train index of 5 minibatch: 1      time used: 13.943374633789062\n",
      "minibatch AVG loss: 1.376777458190918\n",
      "\n",
      "Epoch: 2  train \n",
      "Loss: 1.3768  Acc: 15.0000\n",
      "granite-blackswan precision: 33.3333  recall: 40.0000\n",
      "granite-blackswan sensitivity: 40.0000  specificity: 73.3333\n",
      "granite-blackswan FPR: 26.6667  NPV: 78.5714\n",
      "granite-blackswan TP: 2.0\n",
      "granite-blackswan TN: 11.0\n",
      "granite-blackswan FP: 4.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 60.0000\n",
      "marble-shadow FPR: 40.0000  NPV: 64.2857\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 6.0\n",
      "marble-shadow FN: 5.0\n",
      "quartzite-oceanblue precision: 33.3333  recall: 20.0000\n",
      "quartzite-oceanblue sensitivity: 20.0000  specificity: 86.6667\n",
      "quartzite-oceanblue FPR: 13.3333  NPV: 76.4706\n",
      "quartzite-oceanblue TP: 1.0\n",
      "quartzite-oceanblue TN: 13.0\n",
      "quartzite-oceanblue FP: 2.0\n",
      "quartzite-oceanblue FN: 4.0\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 66.6667\n",
      "quartzite-patagonia FPR: 33.3333  NPV: 66.6667\n",
      "quartzite-patagonia TP: 0.0\n",
      "quartzite-patagonia TN: 10.0\n",
      "quartzite-patagonia FP: 5.0\n",
      "quartzite-patagonia FN: 5.0\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 2  val \n",
      "Loss: 1.5538  Acc: 25.0000\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 75.0000\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 9.0\n",
      "marble-shadow FP: 0.0\n",
      "marble-shadow FN: 3.0\n",
      "quartzite-oceanblue precision: 27.2727  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 11.1111\n",
      "quartzite-oceanblue FPR: 88.8889  NPV: 100.0000\n",
      "quartzite-oceanblue TP: 3.0\n",
      "quartzite-oceanblue TN: 1.0\n",
      "quartzite-oceanblue FP: 8.0\n",
      "quartzite-oceanblue FN: 0.0\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 88.8889\n",
      "quartzite-patagonia FPR: 11.1111  NPV: 72.7273\n",
      "quartzite-patagonia TP: 0.0\n",
      "quartzite-patagonia TN: 8.0\n",
      "quartzite-patagonia FP: 1.0\n",
      "quartzite-patagonia FN: 3.0\n",
      "\n",
      "\n",
      "\n",
      "Training complete in 0m 42s\n",
      "Best epoch idx:  2\n",
      "Best epoch train Acc: 15.000000\n",
      "Best epoch val Acc: 25.000000\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 100.0000\n",
      "marble-shadow FPR: 0.0000  NPV: 75.0000\n",
      "quartzite-oceanblue precision: 27.2727  recall: 100.0000\n",
      "quartzite-oceanblue sensitivity: 100.0000  specificity: 11.1111\n",
      "quartzite-oceanblue FPR: 88.8889  NPV: 100.0000\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 88.8889\n",
      "quartzite-patagonia FPR: 11.1111  NPV: 72.7273\n",
      "model trained by GPU (idx:0) has been saved at  saved_models\\CLS_visformer_RockModel.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\usuariolocal\\.cache\\huggingface\\hub\\models--timm--visformer_small.in1k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "!python Train.py --model_idx visformer_RockModel --edge_size 224 --data_augmentation_mode 2 --batch_size 4 --lr 0.00001 --lrf 0.05 --enable_tensorboard --check_minibatch 5 --dataroot sample_datasets/warwick_CLS --model_path saved_models --draw_root runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visformer test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names: ['granite-blackswan', 'marble-shadow', 'quartzite-oceanblue', 'quartzite-patagonia']\n",
      "['visformer_small', 'visformer_tiny']\n",
      "test model outputï¼ tensor([[ 8.2155e-09,  5.3265e-10, -5.8781e-09, -2.1975e-08]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "model is ready now!\n",
      "model loaded\n",
      "model : visformer_RockModel\n",
      "*********************************setting*************************************\n",
      "Namespace(model_idx='visformer_RockModel', MIL_Stripe=False, drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.0, cls_token_off=False, pos_embedding_off=False, att_module='SimAM', gpu_idx=0, dataroot='sample_datasets/warwick_CLS', model_path='saved_models', draw_root='runs', paint=True, enable_notify=False, enable_tensorboard=False, enable_attention_check=True, enable_visualize_check=False, data_augmentation_mode=2, num_classes=0, edge_size=224, batch_size=1, check_minibatch=5)\n",
      "Epoch: Test\n",
      "----------\n",
      "Epoch: test     test index of 5 minibatch: 1      time used: 4.415442943572998\n",
      "minibatch AVG loss: 2.1201409816741945\n",
      "ERRO in model_idx\n",
      "model: visformer_RockModel  with edge_size 224 is not supported yet\n",
      "Epoch: test     test index of 5 minibatch: 2      time used: 0.653301477432251\n",
      "minibatch AVG loss: 1.5307165384292603\n",
      "ERRO in model_idx\n",
      "model: visformer_RockModel  with edge_size 224 is not supported yet\n",
      "\n",
      "Epoch:  test \n",
      "Loss: 1.7831  Acc: 0.0000\n",
      "granite-blackswan precision: 0.0000  recall: 0.0000\n",
      "granite-blackswan sensitivity: 0.0000  specificity: 100.0000\n",
      "granite-blackswan FPR: 0.0000  NPV: 75.0000\n",
      "granite-blackswan TP: 0.0\n",
      "granite-blackswan TN: 9.0\n",
      "granite-blackswan FP: 0.0\n",
      "granite-blackswan FN: 3.0\n",
      "marble-shadow precision: 0.0000  recall: 0.0000\n",
      "marble-shadow sensitivity: 0.0000  specificity: 77.7778\n",
      "marble-shadow FPR: 22.2222  NPV: 70.0000\n",
      "marble-shadow TP: 0.0\n",
      "marble-shadow TN: 7.0\n",
      "marble-shadow FP: 2.0\n",
      "marble-shadow FN: 3.0\n",
      "quartzite-oceanblue precision: 0.0000  recall: 0.0000\n",
      "quartzite-oceanblue sensitivity: 0.0000  specificity: 22.2222\n",
      "quartzite-oceanblue FPR: 77.7778  NPV: 40.0000\n",
      "quartzite-oceanblue TP: 0.0\n",
      "quartzite-oceanblue TN: 2.0\n",
      "quartzite-oceanblue FP: 7.0\n",
      "quartzite-oceanblue FN: 3.0\n",
      "quartzite-patagonia precision: 0.0000  recall: 0.0000\n",
      "quartzite-patagonia sensitivity: 0.0000  specificity: 66.6667\n",
      "quartzite-patagonia FPR: 33.3333  NPV: 66.6667\n",
      "quartzite-patagonia TP: 0.0\n",
      "quartzite-patagonia TN: 6.0\n",
      "quartzite-patagonia FP: 3.0\n",
      "quartzite-patagonia FN: 3.0\n",
      "\n",
      "\n",
      "Testing complete in 0m 6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\usuariolocal\\OneDrive\\Documentos\\Douglas\\Mestrado\\3 - Curso\\Meu projeto\\si_vit_ornamental_rocks\\utils\\visual_usage.py:35: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.pause(0.001)  # pause a bit so that plots are updated\n",
      "c:\\Users\\usuariolocal\\OneDrive\\Documentos\\Douglas\\Mestrado\\3 - Curso\\Meu projeto\\si_vit_ornamental_rocks\\utils\\visual_usage.py:302: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.pause(0.001)  # pause a bit so that plots are updated\n",
      "c:\\Users\\usuariolocal\\.conda\\envs\\testemestrdouglas\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "!python Test.py --model_idx visformer_RockModel --edge_size 224 --data_augmentation_mode 2 --enable_attention_check --check_minibatch 5 --dataroot sample_datasets/warwick_CLS --model_path saved_models --draw_root runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testemestrdouglas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
